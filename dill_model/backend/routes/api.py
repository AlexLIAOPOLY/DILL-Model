from flask import Blueprint, request, jsonify
from ..models import DillModel, get_model_by_name
from ..utils import validate_input, validate_enhanced_input, validate_car_input, format_response, NumpyEncoder
import json
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from io import BytesIO
import base64
from ..models import EnhancedDillModel
import traceback, datetime
import time

# å…¨å±€æ—¥å¿—å­˜å‚¨
calculation_logs = []

# å…¨å±€æœ€è¿‘è®¡ç®—ç»“æœå­˜å‚¨
latest_calculation_result = {
    'timestamp': None,
    'parameters': None,
    'results': None,
    'model_type': None
}

def add_log_entry(log_type, model_type, message, timestamp=None, dimension=None, details=None):
    """æ·»åŠ å¢å¼ºçš„æ—¥å¿—æ¡ç›®"""
    if timestamp is None:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    log_entry = {
        'timestamp': timestamp,
        'type': log_type,  # 'info', 'progress', 'success', 'warning', 'error'
        'model': model_type,  # 'dill', 'enhanced_dill', 'car', 'system'
        'message': message,
        'dimension': dimension,  # '1d', '2d', '3d' æˆ– None
        'details': details or ''  # è¯¦ç»†ä¿¡æ¯
    }
    
    calculation_logs.append(log_entry)
    
    # ä¿æŒæ—¥å¿—æ¡ç›®æ•°é‡åœ¨åˆç†èŒƒå›´å†…ï¼ˆæœ€å¤š1000æ¡ï¼‰
    if len(calculation_logs) > 1000:
        calculation_logs.pop(0)

def add_dimension_log(log_type, model_type, message, dimension, details=None):
    """æ·»åŠ å¸¦ç»´åº¦ä¿¡æ¯çš„æ—¥å¿—æ¡ç›®"""
    add_log_entry(log_type, model_type, f"[{dimension.upper()}] {message}", dimension=dimension, details=details)

def add_progress_log(model_type, message, progress_percent=None, dimension=None):
    """æ·»åŠ è¿›åº¦æ—¥å¿—"""
    if progress_percent is not None:
        message = f"{message} ({progress_percent}%)"
    add_log_entry('progress', model_type, message, dimension=dimension)

def add_success_log(model_type, message, dimension=None, details=None):
    """æ·»åŠ æˆåŠŸæ—¥å¿—"""
    add_log_entry('success', model_type, message, dimension=dimension, details=details)

def add_warning_log(model_type, message, dimension=None, details=None):
    """æ·»åŠ è­¦å‘Šæ—¥å¿—"""
    add_log_entry('warning', model_type, message, dimension=dimension, details=details)

def add_error_log(model_type, message, dimension=None, details=None):
    """æ·»åŠ é”™è¯¯æ—¥å¿—"""
    add_log_entry('error', model_type, message, dimension=dimension, details=details)

def clear_logs():
    """æ¸…ç©ºæ—¥å¿—"""
    global calculation_logs
    calculation_logs = []

# åˆ›å»ºAPIè“å›¾
api_bp = Blueprint('api', __name__, url_prefix='/api')

# å®ä¾‹åŒ–Dillæ¨¡å‹
dill_model = DillModel()

@api_bp.route('/calculate', methods=['POST'])
def calculate():
    """
    è®¡ç®—æ¨¡å‹å¹¶è¿”å›å›¾åƒ
    æ–°å¢å‚æ•°: model_type, sine_type (æ”¯æŒ'1d', 'multi', '3d')
    """
    try:
        data = request.get_json()
        print('æ”¶åˆ°å‰ç«¯å‚æ•°:', data)  # è°ƒè¯•ç”¨
        
        # === ğŸ” è°ƒè¯•è‡ªå®šä¹‰å…‰å¼ºæ•°æ® ===
        custom_intensity_data = data.get('custom_intensity_data', None)
        print(f"ğŸ” APIè°ƒè¯• - è‡ªå®šä¹‰å…‰å¼ºæ•°æ®æ£€æŸ¥:")
        print(f"   - custom_intensity_dataå­˜åœ¨: {custom_intensity_data is not None}")
        if custom_intensity_data:
            print(f"   - æ•°æ®ç±»å‹: {type(custom_intensity_data)}")
            print(f"   - æ•°æ®å†…å®¹: {custom_intensity_data}")
            if 'x' in custom_intensity_data and 'intensity' in custom_intensity_data:
                print(f"   - Xåæ ‡ç‚¹æ•°: {len(custom_intensity_data['x'])}")
                print(f"   - å…‰å¼ºç‚¹æ•°: {len(custom_intensity_data['intensity'])}")
                print(f"   - XèŒƒå›´: [{min(custom_intensity_data['x']):.3f}, {max(custom_intensity_data['x']):.3f}]")
                print(f"   - å…‰å¼ºèŒƒå›´: [{min(custom_intensity_data['intensity']):.6f}, {max(custom_intensity_data['intensity']):.6f}]")
        # === è°ƒè¯•ç»“æŸ ===
        
        model_type = data.get('model_type', 'dill')
        model = get_model_by_name(model_type)
        
        # æ ¹æ®æ¨¡å‹ç±»å‹éªŒè¯å‚æ•°
        if model_type == 'dill':
            sine_type = data.get('sine_type', '1d')  # å…ˆè·å–sine_type
            is_valid, message = validate_input(data)
            if not is_valid:
                print(f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}, å‚æ•°: {data}")
                add_error_log('dill', f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}", dimension=sine_type)
                return jsonify(format_response(False, message=message)), 400
            # æå–å‚æ•°
            I_avg = float(data['I_avg'])
            V = float(data['V'])
            t_exp = float(data['t_exp'])
            C = float(data['C'])
            
            # æå–ç†æƒ³æ›å…‰æ¨¡å‹çš„æ–°å‚æ•°
            angle_a = float(data.get('angle_a', 11.7))
            exposure_threshold = float(data.get('exposure_threshold', 20))
            wavelength = float(data.get('wavelength', 405))
            contrast_ctr = float(data.get('contrast_ctr', 1))
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è‡ªå®šä¹‰å…‰å¼ºåˆ†å¸ƒ
            custom_intensity_data = data.get('custom_intensity_data', None)
            
            # ğŸ”¸ è°ƒè¯•æ³¢é•¿å‚æ•°
            print(f"ğŸŒˆ æ³¢é•¿å‚æ•°è°ƒè¯•: wavelength = {wavelength} nm (æ¥æº: {data.get('wavelength', 'é»˜è®¤å€¼')})")
            add_progress_log('dill', f"æ³¢é•¿å‚æ•°è®¾ç½®: Î» = {wavelength} nm", dimension=sine_type)
            
            if sine_type == 'multi':
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                phi_expr = data.get('phi_expr', '0')
                # è·å–yèŒƒå›´å‚æ•°
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                y_points = int(data.get('y_points', 100))
                
                # æ–°å¢æ ¡éªŒ: ç¡®ä¿ y_min < y_max ä¸” y_points > 1
                if y_min >= y_max:
                    return jsonify(format_response(False, message="Yè½´èŒƒå›´æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼")), 400
                if y_points <= 1:
                    return jsonify(format_response(False, message="Yè½´ç‚¹æ•°å¿…é¡»å¤§äº1æ‰èƒ½è¿›è¡ŒäºŒç»´è®¡ç®—")), 400
                
                # å¦‚æœæ ¡éªŒé€šè¿‡ï¼Œåˆ™ç›´æ¥è®¡ç®—y_range
                y_range = np.linspace(y_min, y_max, y_points).tolist()
                plot_data = model.generate_plots(I_avg, V, None, t_exp, C, sine_type=sine_type, 
                                               Kx=Kx, Ky=Ky, phi_expr=phi_expr, y_range=y_range,
                                               custom_intensity_data=custom_intensity_data)
            elif sine_type == '2d_exposure_pattern':
                # å¤„ç†2Dæ›å…‰å›¾æ¡ˆå‚æ•° (åŸºäºMATLAB latent_image2d.mé€»è¾‘)
                add_progress_log('dill', "å¼€å§‹2Dæ›å…‰å›¾æ¡ˆè®¡ç®—", dimension='2d')
                
                # è·å–2Dæ›å…‰å›¾æ¡ˆå‚æ•°
                x_min_2d = float(data.get('x_min_2d', -1000))
                x_max_2d = float(data.get('x_max_2d', 1000))
                y_min_2d = float(data.get('y_min_2d', -1000))
                y_max_2d = float(data.get('y_max_2d', 1000))
                step_size_2d = float(data.get('step_size_2d', 5))
                
                # æ£€æŸ¥æ›å…‰è®¡é‡è®¡ç®—æ–¹å¼
                exposure_calculation_method = data.get('exposure_calculation_method', 'standard')
                
                if exposure_calculation_method == 'cumulative':
                    # ç´¯ç§¯æ¨¡å¼ä¸‹çš„2Dæ›å…‰å›¾æ¡ˆ
                    segment_duration = float(data.get('segment_duration', 1))
                    segment_count = int(data.get('segment_count', 5))
                    segment_intensities = data.get('segment_intensities', [])
                    
                    # è®¡ç®—æ€»æ›å…‰æ—¶é—´
                    total_exposure_time = segment_duration * segment_count
                    
                    plots = model.calculate_2d_exposure_pattern(
                        I_avg=I_avg,  # æ·»åŠ I_avgå‚æ•°
                        C=C, 
                        angle_a_deg=angle_a,
                        exposure_time=total_exposure_time,  # ä½¿ç”¨æ€»æ›å…‰æ—¶é—´
                        contrast_ctr=contrast_ctr,
                        threshold_cd=exposure_threshold,
                        wavelength_nm=wavelength,
                        x_min=x_min_2d, x_max=x_max_2d,
                        y_min=y_min_2d, y_max=y_max_2d,
                        step_size=step_size_2d,
                        exposure_calculation_method='cumulative',
                        segment_intensities=segment_intensities,
                        custom_intensity_data=custom_intensity_data
                    )
                    
                    add_success_log('dill', f"2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å®Œæˆ (ç´¯ç§¯æ¨¡å¼, æ€»æ—¶é—´: {total_exposure_time}s)", dimension='2d')
                else:
                    # æ ‡å‡†æ¨¡å¼ä¸‹çš„2Dæ›å…‰å›¾æ¡ˆ
                    plots = model.calculate_2d_exposure_pattern(
                        I_avg=I_avg,  # æ·»åŠ I_avgå‚æ•°
                        C=C, 
                        angle_a_deg=angle_a,
                        exposure_time=t_exp,  # ä½¿ç”¨å•ä¸ªæ›å…‰æ—¶é—´
                        contrast_ctr=contrast_ctr,
                        threshold_cd=exposure_threshold,
                        wavelength_nm=wavelength,
                        x_min=x_min_2d, x_max=x_max_2d,
                        y_min=y_min_2d, y_max=y_max_2d,
                        step_size=step_size_2d,
                        custom_intensity_data=custom_intensity_data
                    )
                    
                    add_success_log('dill', f"2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å®Œæˆ (æ›å…‰æ—¶é—´: {t_exp}s)", dimension='2d')
                
            elif sine_type == '3d':
                # å¤„ç†ä¸‰ç»´æ­£å¼¦æ³¢å‚æ•°
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                Kz = float(data.get('Kz', 0))
                phi_expr = data.get('phi_expr', '0')
                # è·å–ä¸‰ç»´èŒƒå›´å‚æ•°
                x_min = float(data.get('x_min', 0))
                x_max = float(data.get('x_max', 10))
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                z_min = float(data.get('z_min', 0))
                z_max = float(data.get('z_max', 10))
                
                # é»˜è®¤ä½¿ç”¨50ä¸ªç‚¹
                y_range = np.linspace(y_min, y_max, 50).tolist() if y_min < y_max else None
                z_range = np.linspace(z_min, z_max, 50).tolist() if z_min < z_max else None
                
                plots = model.generate_plots(I_avg, V, None, t_exp, C, sine_type=sine_type,
                                           Kx=Kx, Ky=Ky, Kz=Kz, phi_expr=phi_expr,
                                           y_range=y_range, z_range=z_range,
                                           custom_intensity_data=custom_intensity_data)
            else:
                K = float(data['K'])
                
                # æ£€æŸ¥æ›å…‰è®¡é‡è®¡ç®—æ–¹å¼
                exposure_calculation_method = data.get('exposure_calculation_method', 'standard')
                
                # å¤„ç†å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼
                if exposure_calculation_method == 'cumulative':
                    # è·å–å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯å‚æ•°
                    segment_duration = float(data.get('segment_duration', 1))
                    segment_count = int(data.get('segment_count', 5))
                    segment_intensities = data.get('segment_intensities', [])
                    
                    # å‚æ•°éªŒè¯
                    if segment_count <= 0:
                        return jsonify(format_response(False, message="æ®µæ•°å¿…é¡»ä¸ºæ­£æ•´æ•°")), 400
                    if segment_duration <= 0:
                        return jsonify(format_response(False, message="å•æ®µæ—¶é—´é•¿åº¦å¿…é¡»ä¸ºæ­£æ•°")), 400
                    if not segment_intensities or len(segment_intensities) == 0:
                        return jsonify(format_response(False, message="å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼éœ€è¦æä¾›å…‰å¼ºå€¼åˆ—è¡¨")), 400
                    
                    # è®°å½•æ—¥å¿—
                    add_progress_log('dill', f"ä½¿ç”¨å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼ (æ®µæ•°: {segment_count}, å•æ®µæ—¶é—´: {segment_duration}s)", dimension='1d')
                    
                    # æ‰©å±•è°ƒç”¨generate_plotså‡½æ•°æ—¶çš„å‚æ•°
                    plots = model.generate_plots(I_avg, V, K, t_exp, C, sine_type=sine_type, 
                                               angle_a=angle_a, exposure_threshold=exposure_threshold, 
                                               contrast_ctr=contrast_ctr, wavelength=wavelength,
                                               custom_intensity_data=custom_intensity_data,
                                               exposure_calculation_method='cumulative',
                                               segment_duration=segment_duration,
                                               segment_count=segment_count, 
                                               segment_intensities=segment_intensities)
                    
                    add_success_log('dill', f"å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼è®¡ç®—å®Œæˆ (æ€»æ—¶é—´: {segment_duration * segment_count}s)", dimension='1d')
                    
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ›å…‰æ—¶é—´çª—å£
                elif data.get('enable_exposure_time_window', False):
                    custom_exposure_times = data.get('custom_exposure_times', None)
                    
                    if custom_exposure_times is not None and len(custom_exposure_times) > 0:
                        # å¯ç”¨æ›å…‰æ—¶é—´çª—å£ï¼šä½¿ç”¨è‡ªå®šä¹‰æ›å…‰æ—¶é—´ç”Ÿæˆæ•°æ®
                        add_progress_log('dill', f"å¯ç”¨æ›å…‰æ—¶é—´çª—å£ (è‡ªå®šä¹‰æ—¶é—´: {custom_exposure_times})", dimension='1d')
                        plots = model.generate_plots(I_avg, V, K, t_exp, C, sine_type=sine_type, 
                                                   angle_a=angle_a, exposure_threshold=exposure_threshold, 
                                                   contrast_ctr=contrast_ctr, wavelength=wavelength, 
                                                   custom_exposure_times=custom_exposure_times,
                                                   custom_intensity_data=custom_intensity_data)
                        add_success_log('dill', f"æ›å…‰æ—¶é—´çª—å£æ•°æ®ç”Ÿæˆå®Œæˆ ({len(custom_exposure_times)}ç»„æ—¶é—´)", dimension='1d')
                    else:
                        # æœªæä¾›æœ‰æ•ˆçš„è‡ªå®šä¹‰æ—¶é—´
                        add_error_log('dill', f"å¯ç”¨æ›å…‰æ—¶é—´çª—å£ä½†æœªæä¾›æœ‰æ•ˆçš„è‡ªå®šä¹‰æ—¶é—´", dimension='1d')
                        return jsonify(format_response(False, message="å¯ç”¨æ›å…‰æ—¶é—´çª—å£éœ€è¦æä¾›æœ‰æ•ˆçš„è‡ªå®šä¹‰æ—¶é—´")), 400
                else:
                    # æ ‡å‡†æ¨¡å¼ï¼šç”ŸæˆåŸºäºç”¨æˆ·å½“å‰è¾“å…¥t_expçš„å•ä¸€æ—¶é—´æ•°æ®
                    add_progress_log('dill', f"ä½¿ç”¨æ ‡å‡†æ›å…‰æ¨¡å¼ (t_exp: {t_exp}s)", dimension='1d')
                    plots = model.generate_plots(I_avg, V, K, t_exp, C, sine_type=sine_type, 
                                            angle_a=angle_a, exposure_threshold=exposure_threshold, 
                                            contrast_ctr=contrast_ctr, wavelength=wavelength,
                                            custom_intensity_data=custom_intensity_data)
                    add_success_log('dill', f"æ ‡å‡†æ›å…‰æ¨¡å¼è®¡ç®—å®Œæˆ (t_exp: {t_exp}s)", dimension='1d')
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨1DåŠ¨ç”»
                enable_1d_animation = data.get('enable_1d_animation', False)
                if enable_1d_animation:
                    # è·å–1DåŠ¨ç”»å‚æ•° - ä¿®å¤å‚æ•°åä¸åŒ¹é…é—®é¢˜
                    t_exp_start_1d = float(data.get('t_start', 0.1))  # ä¿®å¤ï¼šä» t_exp_start_1d æ”¹ä¸º t_start
                    t_exp_end_1d = float(data.get('t_end', 50.0))     # ä¿®å¤ï¼šä» t_exp_end_1d æ”¹ä¸º t_end
                    time_steps_1d = int(data.get('time_steps', 100))  # ä¿®å¤ï¼šä» time_steps_1d æ”¹ä¸º time_steps
                    
                    add_progress_log('dill', f"å¯ç”¨1Dæ—¶é—´åŠ¨ç”» (æ›å…‰æ—¶é—´: {t_exp_start_1d}s - {t_exp_end_1d}s, {time_steps_1d}æ­¥)", dimension='1d')
                    
                    # ç”Ÿæˆ1DåŠ¨ç”»æ•°æ®å¹¶åˆå¹¶åˆ°é™æ€æ•°æ®ä¸­
                    animation_data = model.generate_1d_animation_data(I_avg, V, K, t_exp_start_1d, t_exp_end_1d, time_steps_1d, C, angle_a, exposure_threshold, contrast_ctr, wavelength)
                    
                    # ç›´æ¥åˆå¹¶åŠ¨ç”»æ•°æ®ï¼ˆåŠ¨ç”»æ•°æ®å·²ä¸å†åŒ…å«ä¼šè¦†ç›–é™æ€æ•°æ®çš„å­—æ®µï¼‰
                    plots.update(animation_data)
                    add_success_log('dill', f"1DåŠ¨ç”»æ•°æ®ç”Ÿæˆå®Œæˆ ({time_steps_1d}å¸§)", dimension='1d')
        elif model_type == 'enhanced_dill':
            is_valid, message = validate_enhanced_input(data)
            if not is_valid:
                print(f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}, å‚æ•°: {data}")
                add_error_log('enhanced_dill', f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}", dimension=sine_type)
                return jsonify(format_response(False, message=message)), 400
            z_h = float(data['z_h'])
            T = float(data['T'])
            t_B = float(data['t_B'])
            I0 = float(data.get('I0', 1.0))
            M0 = float(data.get('M0', 1.0))
            t_exp = float(data['t_exp'])
            sine_type = data.get('sine_type', '1d')
            
            if sine_type == 'multi':
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                phi_expr = data.get('phi_expr', '0')
                V = float(data.get('V', 0))
                plots = model.generate_plots(z_h, T, t_B, I0, M0, t_exp, 
                                          sine_type=sine_type, Kx=Kx, Ky=Ky, phi_expr=phi_expr, V=V)
            elif sine_type == '3d':
                # å¤„ç†ä¸‰ç»´æ­£å¼¦æ³¢å‚æ•°
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                Kz = float(data.get('Kz', 0))
                phi_expr = data.get('phi_expr', '0')
                
                # è·å–ä¸‰ç»´èŒƒå›´å‚æ•°
                x_min = float(data.get('x_min', 0))
                x_max = float(data.get('x_max', 10))
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                z_min = float(data.get('z_min', 0))
                z_max = float(data.get('z_max', 10))
                
                # é»˜è®¤ä½¿ç”¨50ä¸ªç‚¹
                y_range = np.linspace(y_min, y_max, 50).tolist() if y_min < y_max else None
                z_range = np.linspace(z_min, z_max, 50).tolist() if z_min < z_max else None
                
                plots = model.generate_plots(z_h, T, t_B, I0, M0, t_exp, 
                                          sine_type=sine_type, Kx=Kx, Ky=Ky, Kz=Kz,
                                          phi_expr=phi_expr, V=V, y_range=y_range, z_range=z_range)
            else:
                plots = model.generate_plots(z_h, T, t_B, I0, M0, t_exp, sine_type=sine_type)
        elif model_type == 'car':
            is_valid, message = validate_car_input(data)
            if not is_valid:
                print(f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}, å‚æ•°: {data}")
                add_error_log('car', f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}", dimension=sine_type)
                return jsonify(format_response(False, message=message)), 400
            I_avg = float(data['I_avg'])
            V = float(data['V'])
            t_exp = float(data['t_exp'])
            acid_gen_efficiency = float(data['acid_gen_efficiency'])
            diffusion_length = float(data['diffusion_length'])
            reaction_rate = float(data['reaction_rate'])
            amplification = float(data['amplification'])
            contrast = float(data['contrast'])
            sine_type = data.get('sine_type', '1d')
            
            if sine_type == 'multi':
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                phi_expr = data.get('phi_expr', '0')
                # ä¸ºCARæ¨¡å‹æ·»åŠ y_rangeå‚æ•°å¤„ç†
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                y_points = int(data.get('y_points', 100))
                
                if y_min >= y_max:
                    return jsonify(format_response(False, message_zh="Yè½´èŒƒå›´æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼", message_en="Y-axis range min must be less than max")), 400
                if y_points <= 1:
                    return jsonify(format_response(False, message_zh="Yè½´ç‚¹æ•°å¿…é¡»å¤§äº1æ‰èƒ½è¿›è¡ŒäºŒç»´è®¡ç®—", message_en="Number of Y-axis points must be greater than 1 for 2D calculation")), 400
                
                y_range = np.linspace(y_min, y_max, y_points).tolist()
                plot_data = model.generate_plots(I_avg, V, None, t_exp, acid_gen_efficiency, 
                                         diffusion_length, reaction_rate, amplification, contrast, 
                                         sine_type=sine_type, Kx=Kx, Ky=Ky, phi_expr=phi_expr, y_range=y_range)
            elif sine_type == '3d':
                # å¤„ç†ä¸‰ç»´æ­£å¼¦æ³¢å‚æ•°
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                Kz = float(data.get('Kz', 0))
                phi_expr = data.get('phi_expr', '0')
                
                # è·å–ä¸‰ç»´èŒƒå›´å‚æ•°
                x_min = float(data.get('x_min', 0))
                x_max = float(data.get('x_max', 10))
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                z_min = float(data.get('z_min', 0))
                z_max = float(data.get('z_max', 10))
                
                # æ‰“å°è¯¦ç»†å‚æ•°ç”¨äºè°ƒè¯•
                print(f"è®¡ç®—3Dè–„èƒ¶æ¨¡å‹ï¼Œå‚æ•°ï¼šKx={Kx}, Ky={Ky}, Kz={Kz}, phi_expr={phi_expr}")
                print(f"èŒƒå›´å‚æ•°ï¼šx_min={x_min}, x_max={x_max}, y_min={y_min}, y_max={y_max}, z_min={z_min}, z_max={z_max}")
                
                y_range = np.linspace(y_min, y_max, 50).tolist() if y_min < y_max else None
                z_range = np.linspace(z_min, z_max, 50).tolist() if z_min < z_max else None
                
                # æ‰“å°ç”Ÿæˆçš„èŒƒå›´ä¿¡æ¯
                print(f"ç”Ÿæˆçš„èŒƒå›´ï¼šy_rangeé•¿åº¦={len(y_range) if y_range else 0}, z_rangeé•¿åº¦={len(z_range) if z_range else 0}")
                
                try:
                    plots = model.generate_plots(I_avg, V, None, t_exp, acid_gen_efficiency, 
                                               diffusion_length, reaction_rate, amplification, contrast,
                                               sine_type=sine_type, Kx=Kx, Ky=Ky, Kz=Kz, phi_expr=phi_expr,
                                               y_range=y_range, z_range=z_range)
                    # æ‰“å°è¿”å›æ•°æ®çš„ç»“æ„
                    print(f"è¿”å›æ•°æ®å­—æ®µï¼š{list(plots.keys())}")
                    if 'exposure_dose' in plots:
                        if isinstance(plots['exposure_dose'], list):
                            print(f"exposure_doseæ˜¯åˆ—è¡¨ï¼Œé•¿åº¦={len(plots['exposure_dose'])}")
                            if len(plots['exposure_dose']) > 0 and isinstance(plots['exposure_dose'][0], list):
                                print(f"exposure_doseæ˜¯äºŒç»´åˆ—è¡¨ï¼Œå½¢çŠ¶=[{len(plots['exposure_dose'])}, {len(plots['exposure_dose'][0]) if len(plots['exposure_dose']) > 0 else 0}]")
                            else:
                                print(f"exposure_doseæ˜¯ä¸€ç»´åˆ—è¡¨")
                except Exception as e:
                    print(f"ç”Ÿæˆ3Dæ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}")
                    # è®°å½•é”™è¯¯å †æ ˆä»¥ä¾¿è°ƒè¯•
                    traceback.print_exc()
                    raise
            else:
                K = float(data['K'])
                plots = model.generate_plots(I_avg, V, K, t_exp, acid_gen_efficiency, 
                                         diffusion_length, reaction_rate, amplification, contrast, 
                                         sine_type=sine_type)
        else:
            return jsonify(format_response(False, message="æœªçŸ¥æ¨¡å‹ç±»å‹")), 400
        return jsonify(format_response(True, data=plots)), 200
    except Exception as e:
        # è®°å½•å¼‚å¸¸å‚æ•°å’Œé”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
        with open('dill_backend.log', 'a', encoding='utf-8') as f:
            f.write(f"[{datetime.datetime.now()}]\n")
            f.write(f"è¯·æ±‚å‚æ•°: {data if 'data' in locals() else 'æ— '}\n")
            f.write(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}\n")
            f.write(f"å¼‚å¸¸ä¿¡æ¯: {str(e)}\n")
            f.write(f"å †æ ˆä¿¡æ¯: {traceback.format_exc()}\n\n")
        return jsonify({'success': False, 'message_zh': f"è®¡ç®—é”™è¯¯: {str(e)}", 'message_en': f"Calculation error: {str(e)}", 'data': None}), 500

@api_bp.route('/calculate_data', methods=['POST'])
def calculate_data():
    """
    è®¡ç®—æ¨¡å‹å¹¶è¿”å›åŸå§‹æ•°æ®ï¼ˆç”¨äºäº¤äº’å¼å›¾è¡¨ï¼‰
    æ–°å¢å‚æ•°: model_type, sine_type (æ”¯æŒ'1d', 'multi', '3d')
    """
    import time
    
    try:
        data = request.get_json()
        print('æ”¶åˆ°å‰ç«¯å‚æ•°:', data)  # è°ƒè¯•ç”¨
        
        # === ğŸ” è°ƒè¯•è‡ªå®šä¹‰å…‰å¼ºæ•°æ® ===
        custom_intensity_data = data.get('custom_intensity_data', None)
        print(f"ğŸ” APIè°ƒè¯• - è‡ªå®šä¹‰å…‰å¼ºæ•°æ®æ£€æŸ¥:")
        print(f"   - custom_intensity_dataå­˜åœ¨: {custom_intensity_data is not None}")
        if custom_intensity_data:
            print(f"   - æ•°æ®ç±»å‹: {type(custom_intensity_data)}")
            print(f"   - æ•°æ®å†…å®¹: {custom_intensity_data}")
            if 'x' in custom_intensity_data and 'intensity' in custom_intensity_data:
                print(f"   - Xåæ ‡ç‚¹æ•°: {len(custom_intensity_data['x'])}")
                print(f"   - å…‰å¼ºç‚¹æ•°: {len(custom_intensity_data['intensity'])}")
                print(f"   - XèŒƒå›´: [{min(custom_intensity_data['x']):.3f}, {max(custom_intensity_data['x']):.3f}]")
                print(f"   - å…‰å¼ºèŒƒå›´: [{min(custom_intensity_data['intensity']):.6f}, {max(custom_intensity_data['intensity']):.6f}]")
        # === è°ƒè¯•ç»“æŸ ===
        
        model_type = data.get('model_type', 'dill')
        model = get_model_by_name(model_type)
        sine_type = data.get('sine_type', '1d')
        
        # å¼€å§‹è®¡ç®—æ—¶é—´ç»Ÿè®¡
        start_time = time.time()
        
        plot_data = None # Initialize plot_data

        # æ ¹æ®æ¨¡å‹ç±»å‹éªŒè¯å‚æ•°
        if model_type == 'dill':
            is_valid, message = validate_input(data)
            if not is_valid:
                print(f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}, å‚æ•°: {data}")
                add_error_log('dill', f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}", dimension=sine_type)
                return jsonify(format_response(False, message=message)), 400
            
            I_avg = float(data['I_avg'])
            V = float(data['V'])
            t_exp = float(data['t_exp'])
            C = float(data['C'])
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨4DåŠ¨ç”»
            enable_4d_animation = data.get('enable_4d_animation', False)
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨1DåŠ¨ç”»
            enable_1d_animation = data.get('enable_1d_animation', False)
            t_start = float(data.get('t_start', 0)) if enable_4d_animation else 0
            t_end = float(data.get('t_end', 5)) if enable_4d_animation else 5
            time_steps = int(data.get('time_steps', 20)) if enable_4d_animation else 20
            
            if enable_4d_animation:
                add_log_entry('info', 'dill', f"å¯ç”¨4DåŠ¨ç”»: t_start={t_start}s, t_end={t_end}s, time_steps={time_steps}", dimension=sine_type)
            
            # æ·»åŠ è¯¦ç»†çš„å‚æ•°æ—¥å¿—
            if sine_type == 'multi':
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                phi_expr = data.get('phi_expr', '0')
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                y_points = int(data.get('y_points', 100))
                
                print(f"Dillæ¨¡å‹å‚æ•° (2Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V}, t_exp={t_exp}, C={C}")
                print(f"  äºŒç»´å‚æ•°: Kx={Kx}, Ky={Ky}, phi_expr='{phi_expr}'")
                print(f"  Yè½´èŒƒå›´: [{y_min}, {y_max}], ç‚¹æ•°: {y_points}")
                print(f"[Dill-2D] å¼€å§‹è®¡ç®—äºŒç»´ç©ºé—´åˆ†å¸ƒï¼Œç½‘æ ¼å¤§å°: 1000Ã—{y_points}")
                
                # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                add_log_entry('info', 'dill', f"Dill-2Dæ¨¡å‹å‚æ•° (2Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V}, t_exp={t_exp}, C={C}", dimension='2d')
                add_log_entry('info', 'dill', f"äºŒç»´å‚æ•°: Kx={Kx}, Ky={Ky}, phi_expr='{phi_expr}'", dimension='2d')
                add_log_entry('info', 'dill', f"Yè½´èŒƒå›´: [{y_min}, {y_max}], ç‚¹æ•°: {y_points}", dimension='2d')
                add_log_entry('progress', 'dill', f"å¼€å§‹è®¡ç®—äºŒç»´ç©ºé—´åˆ†å¸ƒï¼Œç½‘æ ¼å¤§å°: 1000Ã—{y_points}", dimension='2d')
                
                if y_min >= y_max:
                    add_error_log('dill', "Yè½´èŒƒå›´é…ç½®é”™è¯¯ï¼šæœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼", dimension='2d')
                    return jsonify(format_response(False, message_zh="Yè½´èŒƒå›´æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼", message_en="Y-axis range min must be less than max")), 400
                if y_points <= 1:
                    add_error_log('dill', "Yè½´ç‚¹æ•°é…ç½®é”™è¯¯ï¼šå¿…é¡»å¤§äº1", dimension='2d')
                    return jsonify(format_response(False, message_zh="Yè½´ç‚¹æ•°å¿…é¡»å¤§äº1æ‰èƒ½è¿›è¡ŒäºŒç»´è®¡ç®—", message_en="Number of Y-axis points must be greater than 1 for 2D calculation")), 400
                
                y_range = np.linspace(y_min, y_max, y_points).tolist()
                
                calc_start = time.time()
                try:
                    plot_data = model.generate_data(I_avg, V, None, t_exp, C, sine_type=sine_type, 
                                                    Kx=Kx, Ky=Ky, phi_expr=phi_expr, y_range=y_range,
                                                    enable_4d_animation=enable_4d_animation,
                                                    t_start=t_start, t_end=t_end, time_steps=time_steps)
                    calc_time = time.time() - calc_start
                    
                    if enable_4d_animation:
                        add_log_entry('success', 'dill', f"âœ… Dill-2D-4DåŠ¨ç”»è®¡ç®—å®Œæˆ! å…±{time_steps}å¸§", dimension='2d')
                        add_log_entry('info', 'dill', f"â±ï¸ è®¡ç®—è€—æ—¶: {calc_time:.3f}s", dimension='2d')
                    else:
                        add_log_entry('success', 'dill', f"âœ… äºŒç»´è®¡ç®—å®Œæˆ!", dimension='2d')
                        add_log_entry('info', 'dill', f"â±ï¸ è®¡ç®—è€—æ—¶: {calc_time:.3f}s", dimension='2d')
                    
                except Exception as e:
                    calc_time = time.time() - calc_start
                    print(f"[Dill-2D] âŒ äºŒç»´è®¡ç®—å‡ºé”™: {str(e)}")
                    print(f"[Dill-2D] â±ï¸  è®¡ç®—è€—æ—¶: {calc_time:.3f}s")
                    add_error_log('dill', f"äºŒç»´è®¡ç®—å¤±è´¥: {str(e)}", dimension='2d')
                    add_log_entry('error', 'dill', f"âŒ äºŒç»´è®¡ç®—å‡ºé”™: {str(e)}", dimension='2d')
                    add_log_entry('info', 'dill', f"â±ï¸ è®¡ç®—è€—æ—¶: {calc_time:.3f}s", dimension='2d')
                    raise
                    
            elif sine_type == '2d_exposure_pattern':
                print(f"ğŸ¯ DEBUG: è¿›å…¥2Dæ›å…‰å›¾æ¡ˆåˆ†æ”¯(calculate_data)ï¼Œsine_type = '{sine_type}'")
                # å¤„ç†2Dæ›å…‰å›¾æ¡ˆå‚æ•° (åŸºäºMATLAB latent_image2d.mé€»è¾‘)
                add_progress_log('dill', "å¼€å§‹2Dæ›å…‰å›¾æ¡ˆè®¡ç®—", dimension='2d')
                
                # è·å–2Dæ›å…‰å›¾æ¡ˆå‚æ•°
                angle_a = float(data.get('angle_a', 11.7))
                exposure_threshold = float(data.get('exposure_threshold', 25))
                contrast_ctr = float(data.get('V', 0.9))  # Vå‚æ•°å°±æ˜¯å¯¹æ¯”åº¦
                wavelength = float(data.get('wavelength', 405))
                
                x_min_2d = float(data.get('x_min_2d', -1000))
                x_max_2d = float(data.get('x_max_2d', 1000))
                y_min_2d = float(data.get('y_min_2d', -1000))
                y_max_2d = float(data.get('y_max_2d', 1000))
                step_size_2d = float(data.get('step_size_2d', 5))
                
                # æ£€æŸ¥æ›å…‰è®¡é‡è®¡ç®—æ–¹å¼
                exposure_calculation_method = data.get('exposure_calculation_method', 'standard')
                print(f"ğŸ” 2Dæ›å…‰å›¾æ¡ˆæ›å…‰è®¡ç®—æ–¹å¼: {exposure_calculation_method}")
                
                calc_start = time.time()
                try:
                    if exposure_calculation_method == 'cumulative':
                        # ç´¯ç§¯æ¨¡å¼ä¸‹çš„2Dæ›å…‰å›¾æ¡ˆ
                        segment_duration = float(data.get('segment_duration', 1))
                        segment_count = int(data.get('segment_count', 5))
                        segment_intensities = data.get('segment_intensities', [])
                        total_exposure_time = segment_duration * segment_count
                        
                        print(f"Dillæ¨¡å‹å‚æ•° (2Dæ›å…‰å›¾æ¡ˆ-ç´¯ç§¯): I_avg={I_avg}, V={V}, æ€»æ—¶é—´={total_exposure_time}, C={C}")
                        print(f"  2Dæ›å…‰å‚æ•°: angle_a={angle_a}, threshold={exposure_threshold}, contrast={contrast_ctr}")
                        print(f"  ç´¯ç§¯å‚æ•°: æ®µæ•°={segment_count}, å•æ®µæ—¶é—´={segment_duration}s, æ€»æ—¶é—´={total_exposure_time}s")
                        print(f"  XèŒƒå›´: [{x_min_2d}, {x_max_2d}], YèŒƒå›´: [{y_min_2d}, {y_max_2d}], æ­¥é•¿: {step_size_2d}")
                        
                        # è®¡ç®—2Dæ›å…‰å›¾æ¡ˆ - ä½¿ç”¨æ€»æ›å…‰æ—¶é—´
                        plot_data = model.calculate_2d_exposure_pattern(
                            I_avg=I_avg,  # æ·»åŠ I_avgå‚æ•°
                            C=C, 
                            angle_a_deg=angle_a,
                            exposure_time=total_exposure_time,  # ä½¿ç”¨æ€»æ›å…‰æ—¶é—´
                            contrast_ctr=contrast_ctr,
                            threshold_cd=exposure_threshold,
                            wavelength_nm=wavelength,
                            x_min=x_min_2d, x_max=x_max_2d,
                            y_min=y_min_2d, y_max=y_max_2d,
                            step_size=step_size_2d,
                            exposure_calculation_method='cumulative',
                            segment_intensities=segment_intensities,
                            custom_intensity_data=custom_intensity_data
                        )
                        
                        calc_time = time.time() - calc_start
                        print(f"[Dill-2Dæ›å…‰] ğŸ¯ 2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å®Œæˆç»Ÿè®¡ (ç´¯ç§¯æ¨¡å¼):")
                        print(f"  âœ… è®¡ç®—æˆåŠŸ")
                        print(f"  â±ï¸  è®¡ç®—æ—¶é—´: {calc_time:.3f}s")
                        print(f"  ğŸ’¾ æ•°æ®å­—æ®µ: {list(plot_data.keys())}")
                        print(f"  ğŸ“Š æ€»æ›å…‰æ—¶é—´: {total_exposure_time}s")
                        
                        add_success_log('dill', f"2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å®Œæˆ (ç´¯ç§¯æ¨¡å¼, æ€»æ—¶é—´={total_exposure_time}s), ç”¨æ—¶{calc_time:.3f}s", dimension='2d')
                        
                    else:
                        # æ ‡å‡†æ¨¡å¼ä¸‹çš„2Dæ›å…‰å›¾æ¡ˆ
                        print(f"Dillæ¨¡å‹å‚æ•° (2Dæ›å…‰å›¾æ¡ˆ-æ ‡å‡†): I_avg={I_avg}, V={V}, t_exp={t_exp}, C={C}")
                        print(f"  2Dæ›å…‰å‚æ•°: angle_a={angle_a}, threshold={exposure_threshold}, contrast={contrast_ctr}")
                        print(f"  è‡ªå®šä¹‰å‘é‡: {custom_intensity_data is not None}")
                        print(f"  æ›å…‰æ—¶é—´: {t_exp}s")
                        print(f"  XèŒƒå›´: [{x_min_2d}, {x_max_2d}], YèŒƒå›´: [{y_min_2d}, {y_max_2d}], æ­¥é•¿: {step_size_2d}")
                        
                        # è®¡ç®—2Dæ›å…‰å›¾æ¡ˆ - ä½¿ç”¨å•ä¸ªæ›å…‰æ—¶é—´
                        plot_data = model.calculate_2d_exposure_pattern(
                            I_avg=I_avg,  # æ·»åŠ I_avgå‚æ•°
                            C=C, 
                            angle_a_deg=angle_a,
                            exposure_time=t_exp,  # ä½¿ç”¨å•ä¸ªæ›å…‰æ—¶é—´
                            contrast_ctr=contrast_ctr,
                            threshold_cd=exposure_threshold,
                            wavelength_nm=wavelength,
                            x_min=x_min_2d, x_max=x_max_2d,
                            y_min=y_min_2d, y_max=y_max_2d,
                            step_size=step_size_2d,
                            custom_intensity_data=custom_intensity_data
                        )
                        
                        calc_time = time.time() - calc_start
                        print(f"[Dill-2Dæ›å…‰] ğŸ¯ 2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å®Œæˆç»Ÿè®¡:")
                        print(f"  âœ… è®¡ç®—æˆåŠŸ")
                        print(f"  â±ï¸  è®¡ç®—æ—¶é—´: {calc_time:.3f}s")
                        print(f"  ğŸ’¾ æ•°æ®å­—æ®µ: {list(plot_data.keys())}")
                        print(f"  ğŸ“Š æ›å…‰æ—¶é—´: {t_exp}")
                        
                        add_success_log('dill', f"2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å®Œæˆ (t={t_exp}), ç”¨æ—¶{calc_time:.3f}s", dimension='2d')
                    
                except Exception as e:
                    calc_time = time.time() - calc_start
                    print(f"[Dill-2Dæ›å…‰] âŒ 2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å‡ºé”™: {str(e)}")
                    print(f"[Dill-2Dæ›å…‰] â±ï¸  è®¡ç®—è€—æ—¶: {calc_time:.3f}s")
                    add_error_log('dill', f"2Dæ›å…‰å›¾æ¡ˆè®¡ç®—å¤±è´¥: {str(e)}", dimension='2d')
                    raise
                    
            elif sine_type == '3d':
                Kx = float(data.get('Kx', 0))
                Ky = float(data.get('Ky', 0))
                Kz = float(data.get('Kz', 0))
                phi_expr = data.get('phi_expr', '0')
                x_min = float(data.get('x_min', 0))
                x_max = float(data.get('x_max', 10))
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                z_min = float(data.get('z_min', 0))
                z_max = float(data.get('z_max', 10))
                
                # ç”Ÿæˆy_rangeå’Œz_range
                y_range = np.linspace(y_min, y_max, 50).tolist() if y_min < y_max else None
                z_range = np.linspace(z_min, z_max, 50).tolist() if z_min < z_max else None
                
                print(f"Dillæ¨¡å‹å‚æ•° (3Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V}, t_exp={t_exp}, C={C}")
                print(f"  ä¸‰ç»´å‚æ•°: Kx={Kx}, Ky={Ky}, Kz={Kz}, phi_expr='{phi_expr}'")
                print(f"  Xè½´èŒƒå›´: [{x_min}, {x_max}]")
                print(f"  Yè½´èŒƒå›´: [{y_min}, {y_max}]")
                print(f"  Zè½´èŒƒå›´: [{z_min}, {z_max}]")
                print(f"[Dill-3D] å¼€å§‹è®¡ç®—ä¸‰ç»´ç©ºé—´åˆ†å¸ƒï¼Œé¢„è®¡ç½‘æ ¼å¤§å°: 50Ã—50Ã—50")
                
                # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                add_log_entry('info', 'dill', f"Dill-3Dæ¨¡å‹å‚æ•° (3Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V}, t_exp={t_exp}, C={C}", dimension='3d')
                add_log_entry('info', 'dill', f"ä¸‰ç»´å‚æ•°: Kx={Kx}, Ky={Ky}, Kz={Kz}, phi_expr='{phi_expr}'", dimension='3d')
                add_log_entry('info', 'dill', f"Xè½´èŒƒå›´: [{x_min}, {x_max}]", dimension='3d')
                add_log_entry('info', 'dill', f"Yè½´èŒƒå›´: [{y_min}, {y_max}]", dimension='3d')
                add_log_entry('info', 'dill', f"Zè½´èŒƒå›´: [{z_min}, {z_max}]", dimension='3d')
                add_log_entry('progress', 'dill', f"å¼€å§‹è®¡ç®—ä¸‰ç»´ç©ºé—´åˆ†å¸ƒï¼Œé¢„è®¡ç½‘æ ¼å¤§å°: 50Ã—50Ã—50", dimension='3d')
                
                calc_start = time.time()
                try:
                    # ç¡®ä¿z_rangeæ­£ç¡®ä¼ é€’ç»™æ¨¡å‹
                    plot_data = model.generate_data(I_avg, V, None, t_exp, C, sine_type=sine_type,
                                                 Kx=Kx, Ky=Ky, Kz=Kz, phi_expr=phi_expr,
                                                 y_range=y_range, z_range=z_range,
                                                 enable_4d_animation=enable_4d_animation,
                                                 t_start=t_start, t_end=t_end, time_steps=time_steps,
                                                 x_min=x_min, x_max=x_max)
                    calc_time = time.time() - calc_start
                    
                    print(f"[Dill-3D] ğŸ¯ ä¸‰ç»´è®¡ç®—å®Œæˆç»Ÿè®¡:")
                    print(f"  âœ… è®¡ç®—æˆåŠŸ")
                    print(f"  â±ï¸  è®¡ç®—æ—¶é—´: {calc_time:.3f}s")
                    print(f"  ğŸ’¾ æ•°æ®å­—æ®µ: {list(plot_data.keys())}")
                    
                    # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                    add_log_entry('success', 'dill', f"ğŸ¯ ä¸‰ç»´è®¡ç®—å®Œæˆç»Ÿè®¡", dimension='3d')
                    add_log_entry('info', 'dill', f"âœ… è®¡ç®—æˆåŠŸ", dimension='3d')
                    add_log_entry('info', 'dill', f"â±ï¸ è®¡ç®—æ—¶é—´: {calc_time:.3f}s", dimension='3d')
                    add_log_entry('info', 'dill', f"ğŸ’¾ æ•°æ®å­—æ®µ: {list(plot_data.keys())}", dimension='3d')
                    
                    if 'exposure_dose' in plot_data:
                        exp_data = np.array(plot_data['exposure_dose'])
                        thick_data = np.array(plot_data['thickness'])
                        print(f"  ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{exp_data.min():.3f}, {exp_data.max():.3f}] mJ/cmÂ²")
                        print(f"  ğŸ“ åšåº¦èŒƒå›´: [{thick_data.min():.4f}, {thick_data.max():.4f}] (å½’ä¸€åŒ–)")
                        print(f"  ğŸ“ Dillæ¨¡å‹3Dç‰¹å¾åˆ†æ:")
                        print(f"     æ•°æ®ç»´åº¦: {exp_data.shape if exp_data.ndim > 1 else '1D'}")
                        print(f"     ç©ºé—´é¢‘ç‡: Kx={Kx}, Ky={Ky}, Kz={Kz}")
                        print(f"     å…‰æ•é€Ÿç‡å¸¸æ•°C: {C:.4f} cmÂ²/mJ")
                        
                        # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                        add_log_entry('info', 'dill', f"ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{exp_data.min():.3f}, {exp_data.max():.3f}] mJ/cmÂ²", dimension='3d')
                        add_log_entry('info', 'dill', f"ğŸ“ åšåº¦èŒƒå›´: [{thick_data.min():.4f}, {thick_data.max():.4f}] (å½’ä¸€åŒ–)", dimension='3d')
                        add_log_entry('info', 'dill', f"ğŸ“ Dillæ¨¡å‹3Dç‰¹å¾åˆ†æ", dimension='3d')
                        add_log_entry('info', 'dill', f"   æ•°æ®ç»´åº¦: {exp_data.shape if exp_data.ndim > 1 else '1D'}", dimension='3d')
                        add_log_entry('info', 'dill', f"   ç©ºé—´é¢‘ç‡: Kx={Kx}, Ky={Ky}, Kz={Kz}", dimension='3d')
                        add_log_entry('info', 'dill', f"   å…‰æ•é€Ÿç‡å¸¸æ•°C: {C:.4f} cmÂ²/mJ", dimension='3d')
                    
                    add_success_log('dill', f"ä¸‰ç»´è®¡ç®—å®Œæˆï¼Œç”¨æ—¶{calc_time:.3f}s", dimension='3d')
                    
                except Exception as e:
                    calc_time = time.time() - calc_start
                    print(f"[Dill-3D] âŒ ä¸‰ç»´è®¡ç®—å‡ºé”™: {str(e)}")
                    print(f"[Dill-3D] â±ï¸  è®¡ç®—è€—æ—¶: {calc_time:.3f}s")
                    add_error_log('dill', f"ä¸‰ç»´è®¡ç®—å¤±è´¥: {str(e)}", dimension='3d')
                    add_log_entry('error', 'dill', f"âŒ ä¸‰ç»´è®¡ç®—å‡ºé”™: {str(e)}", dimension='3d')
                    add_log_entry('info', 'dill', f"â±ï¸ è®¡ç®—è€—æ—¶: {calc_time:.3f}s", dimension='3d')
                    raise
                    
            else: # 1D Dill
                print(f"ğŸ¯ DEBUG: è¿›å…¥1D Dillåˆ†æ”¯ï¼Œsine_type = '{sine_type}'")
                K = float(data['K'])
                
                # æ£€æŸ¥å¯ç”¨çš„åŠŸèƒ½
                enable_1d_v_evaluation = data.get('enable_1d_v_evaluation', False)
                
                # âœ… æ·»åŠ è‡ªå®šä¹‰æ›å…‰æ—¶é—´çª—å£é€»è¾‘ - ä¸calculateç«¯ç‚¹ä¿æŒä¸€è‡´
                angle_a = float(data.get('angle_a', 11.7))
                exposure_threshold = float(data.get('exposure_threshold', 20))
                contrast_ctr = float(data.get('contrast_ctr', 1))
                wavelength = float(data.get('wavelength', 405))
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è‡ªå®šä¹‰å…‰å¼ºåˆ†å¸ƒ
                custom_intensity_data = data.get('custom_intensity_data', None)
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ›å…‰æ—¶é—´çª—å£
                enable_exposure_time_window = data.get('enable_exposure_time_window', False)
                custom_exposure_times = data.get('custom_exposure_times', None)
                
                print(f"ğŸ”¥ calculate_dataç«¯ç‚¹: enable_exposure_time_window = {enable_exposure_time_window}")
                print(f"ğŸ”¥ calculate_dataç«¯ç‚¹: custom_exposure_times = {custom_exposure_times}")
                
                # é¦–å…ˆç”ŸæˆåŸºäºç”¨æˆ·å½“å‰å‚æ•°çš„é™æ€æ•°æ®ï¼ˆè¿™æ˜¯æ‰€æœ‰æ¨¡å¼çš„åŸºç¡€ï¼‰
                print(f"Dillæ¨¡å‹å‚æ•°: I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp}, C={C}")
                print(f"[Dill-1D] ç”Ÿæˆé™æ€æ•°æ®ä½œä¸ºåŸºç¡€")
                
                calc_start = time.time()
                
                # æ£€æŸ¥æ›å…‰è®¡é‡è®¡ç®—æ–¹å¼ - è¿™é‡Œæ˜¯çœŸæ­£çš„è®¡ç®—è°ƒç”¨ç‚¹
                exposure_calculation_method = data.get('exposure_calculation_method', 'standard')
                print(f"ğŸ” çœŸå®è°ƒç”¨ç‚¹è°ƒè¯•: exposure_calculation_method = '{exposure_calculation_method}'")
                
                # å¤„ç†å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼
                if exposure_calculation_method == 'cumulative':
                    # è·å–å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯å‚æ•°
                    segment_duration = float(data.get('segment_duration', 1))
                    segment_count = int(data.get('segment_count', 5))
                    segment_intensities = data.get('segment_intensities', [])
                    total_exposure_dose = data.get('total_exposure_dose', segment_count * segment_duration)
                    
                    print(f"ğŸ”¥ çœŸå®è°ƒç”¨ç‚¹: è¿›å…¥å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼")
                    print(f"ğŸ”¥ å‚æ•°: segment_count={segment_count}, segment_duration={segment_duration}")
                    print(f"ğŸ”¥ å‚æ•°: segment_intensities={segment_intensities}, total_dose={total_exposure_dose}")
                    
                    # ä½¿ç”¨å¤šæ®µæ›å…‰æ—¶é—´ç´¯ç§¯æ¨¡å¼ç”Ÿæˆæ•°æ®
                    plot_data = model.generate_data(I_avg, V, K, t_exp, C, sine_type=sine_type,
                                                   angle_a=angle_a, exposure_threshold=exposure_threshold, 
                                                   contrast_ctr=contrast_ctr, wavelength=wavelength,
                                                   custom_intensity_data=custom_intensity_data,
                                                   exposure_calculation_method='cumulative',
                                                   segment_duration=segment_duration,
                                                   segment_count=segment_count,
                                                   segment_intensities=segment_intensities)
                # æ ¹æ®æ›å…‰æ—¶é—´çª—å£å¼€å…³çŠ¶æ€é€‰æ‹©è®¡ç®—æ¨¡å¼
                elif enable_exposure_time_window and custom_exposure_times is not None and len(custom_exposure_times) > 0:
                    print(f"ğŸ¯ calculate_dataç«¯ç‚¹: å¯ç”¨æ›å…‰æ—¶é—´çª—å£ï¼Œä½¿ç”¨è‡ªå®šä¹‰æ›å…‰æ—¶é—´ {custom_exposure_times}")
                    # å¯ç”¨æ›å…‰æ—¶é—´çª—å£ï¼šä½¿ç”¨è‡ªå®šä¹‰æ›å…‰æ—¶é—´ç”Ÿæˆæ•°æ®
                    plot_data = model.generate_data(I_avg, V, K, t_exp, C, sine_type=sine_type, 
                                                   angle_a=angle_a, exposure_threshold=exposure_threshold, 
                                                   contrast_ctr=contrast_ctr, wavelength=wavelength, custom_exposure_times=custom_exposure_times,
                                                   custom_intensity_data=custom_intensity_data)
                else:
                    print(f"ğŸ¯ calculate_dataç«¯ç‚¹: ä½¿ç”¨æ ‡å‡†æ›å…‰æ¨¡å¼ï¼Œå•ä¸€æ›å…‰æ—¶é—´ {t_exp}s")
                    # æ ‡å‡†æ¨¡å¼ï¼šä½¿ç”¨å•ä¸€æ›å…‰æ—¶é—´ç”Ÿæˆæ•°æ®
                    plot_data = model.generate_data(I_avg, V, K, t_exp, C, sine_type=sine_type,
                                                   angle_a=angle_a, exposure_threshold=exposure_threshold, 
                                                   contrast_ctr=contrast_ctr, wavelength=wavelength,
                                                   custom_intensity_data=custom_intensity_data)
                
                static_calc_time = time.time() - calc_start
                total_calc_time = static_calc_time
                
                # å¤„ç†1DåŠ¨ç”»åŠŸèƒ½
                if enable_1d_animation:
                    # å¤„ç†1DåŠ¨ç”»å‚æ•°
                    t_start = float(data.get('t_start', 0.1))
                    t_end = float(data.get('t_end', 5.0))
                    time_steps = int(data.get('time_steps', 500))
                    
                    print(f"[Dill-1D-Animation] å¯ç”¨1Dæ—¶é—´åŠ¨ç”»ï¼Œæ—¶é—´èŒƒå›´: {t_start}s - {t_end}s, {time_steps}æ­¥")
                    add_progress_log('dill', f"å¯ç”¨1Dæ—¶é—´åŠ¨ç”» (æ—¶é—´èŒƒå›´: {t_start}s - {t_end}s, {time_steps}æ­¥)", dimension='1d')
                    
                    # ç”ŸæˆåŠ¨ç”»æ•°æ®
                    print(f"[Dill-1D-Animation] ç”ŸæˆåŠ¨ç”»æ•°æ® ({t_start}s - {t_end}s, {time_steps}å¸§)")
                    anim_calc_start = time.time()
                    animation_data = model.generate_1d_animation_data(I_avg, V, K, t_start, t_end, time_steps, C, angle_a, exposure_threshold, contrast_ctr)
                    anim_calc_time = time.time() - anim_calc_start
                    total_calc_time += anim_calc_time
                    
                    # æ·»åŠ åŠ¨ç”»æ•°æ®åˆ°plot_data
                    plot_data['enable_1d_animation'] = True
                    plot_data['animation_frames'] = []
                    
                    # å¤„ç†åŠ¨ç”»å¸§æ•°æ®
                    if 'frames' in animation_data:
                        for frame in animation_data['frames']:
                            frame_data = {
                                'time': frame['t_exp'],
                                't': frame['t_exp'],  # æ·»åŠ tå­—æ®µ
                                'x': frame['x_coords'],
                                'x_coords': frame['x_coords'],  # æ·»åŠ x_coordså­—æ®µ
                                # ä¿®å¤ï¼šæ­£ç¡®è®¿é—®exposure_dataï¼Œæ”¯æŒæ–°æ—§ä¸¤ç§æ•°æ®æ ¼å¼
                                'exposure_dose': frame.get('exposure_dose', frame.get('exposure_data', {}).get('y', [])),
                                # ä¿®å¤ï¼šæ­£ç¡®è®¿é—®thickness_dataï¼Œæ”¯æŒæ–°æ—§ä¸¤ç§æ•°æ®æ ¼å¼
                                'thickness': frame.get('thickness', frame.get('thickness_data', {}).get('y', [])),
                                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼ é€’å¤šæ¡æ›å…‰æ—¶é—´çº¿æ•°æ®
                                'etch_depths_data': frame.get('etch_depths_data', []),
                                'exposure_times': frame.get('exposure_times', []),
                                'is_ideal_exposure_model': frame.get('is_ideal_exposure_model', False)
                            }
                            plot_data['animation_frames'].append(frame_data)
                    
                    print(f"[Dill-1D-Animation] âœ… åŠ¨ç”»æ•°æ®ç”Ÿæˆå®Œæˆ: {len(plot_data.get('animation_frames', []))}å¸§ï¼Œç”¨æ—¶{anim_calc_time:.3f}s")
                    add_log_entry('success', 'dill', f"âœ… 1DåŠ¨ç”»æ•°æ®ç”Ÿæˆå®Œæˆ", dimension='1d')
                    add_success_log('dill', f"1DåŠ¨ç”»æ•°æ®ç”Ÿæˆå®Œæˆ ({time_steps}å¸§), ç”¨æ—¶{anim_calc_time:.3f}s", dimension='1d')
                
                # å¤„ç†1D Vè¯„ä¼°åŠŸèƒ½
                if enable_1d_v_evaluation:
                    # å¤„ç†1D Vè¯„ä¼°å‚æ•°
                    v_start = float(data.get('v_start', 0.1))
                    v_end = float(data.get('v_end', 1.0))
                    v_time_steps = int(data.get('time_steps', 500))  # Vè¯„ä¼°ä½¿ç”¨ç›¸åŒçš„æ­¥æ•°å‚æ•°
                    
                    print(f"[Dill-1D-V-Eval] å¯ç”¨1D Vï¼ˆå¯¹æ¯”åº¦ï¼‰è¯„ä¼°ï¼ŒVèŒƒå›´: {v_start} - {v_end}, {v_time_steps}æ­¥")
                    add_progress_log('dill', f"å¯ç”¨1D Vï¼ˆå¯¹æ¯”åº¦ï¼‰è¯„ä¼° (VèŒƒå›´: {v_start} - {v_end}, {v_time_steps}æ­¥)", dimension='1d')
                    
                    # ğŸ”¥ é‡è¦ä¿®å¤ï¼šä¿å­˜å½“å‰çš„é™æ€æ•°æ®ï¼Œé˜²æ­¢è¢«Vè¯„ä¼°æ•°æ®è¦†ç›–
                    static_data_backup = {
                        'x': plot_data.get('x', []).copy() if plot_data.get('x') else [],
                        'x_coords': plot_data.get('x_coords', []).copy() if plot_data.get('x_coords') else [],
                        'exposure_dose': plot_data.get('exposure_dose', []).copy() if plot_data.get('exposure_dose') else [],
                        'thickness': plot_data.get('thickness', []).copy() if plot_data.get('thickness') else [],
                        'sine_type': plot_data.get('sine_type', '1d'),
                        'is_ideal_exposure_model': plot_data.get('is_ideal_exposure_model', False),
                        'intensity_distribution': plot_data.get('intensity_distribution', []).copy() if plot_data.get('intensity_distribution') else [],
                        'etch_depths_data': plot_data.get('etch_depths_data', []).copy() if plot_data.get('etch_depths_data') else []
                    }
                    
                    print(f"[Dill-1D-V-Eval] âœ… å·²å¤‡ä»½é™æ€æ•°æ®ï¼Œç¡®ä¿Vè¯„ä¼°ä¸å½±å“é™æ€å›¾è¡¨")
                    print(f"[Dill-1D-V-Eval] é™æ€æ•°æ®å¤‡ä»½ï¼šxé•¿åº¦={len(static_data_backup['x'])}, exposureé•¿åº¦={len(static_data_backup['exposure_dose'])}, thicknessé•¿åº¦={len(static_data_backup['thickness'])}")
                    
                    # ç”ŸæˆVè¯„ä¼°æ•°æ® - ä½¿ç”¨ç†æƒ³æ›å…‰æ¨¡å‹
                    print(f"[Dill-1D-V-Eval] ä½¿ç”¨ç†æƒ³æ›å…‰æ¨¡å‹ç”ŸæˆVè¯„ä¼°æ•°æ® (V: {v_start} - {v_end}, {v_time_steps}å¸§)")
                    print(f"[Dill-1D-V-Eval] ç†æƒ³æ›å…‰æ¨¡å‹å‚æ•°: angle_a={angle_a}Â°, exposure_threshold={exposure_threshold}, wavelength={wavelength}nm")
                    v_calc_start = time.time()
                    v_evaluation_data = model.generate_1d_v_animation_data(I_avg, v_start, v_end, v_time_steps, K, t_exp, C, 
                                                                          angle_a=angle_a, exposure_threshold=exposure_threshold, wavelength=wavelength)
                    v_calc_time = time.time() - v_calc_start
                    total_calc_time += v_calc_time
                    
                    # æ·»åŠ Vè¯„ä¼°æ•°æ®åˆ°plot_dataï¼Œä½†ä¸è¦†ç›–é™æ€æ•°æ®
                    plot_data['enable_1d_v_evaluation'] = True
                    plot_data['v_evaluation_frames'] = []
                    
                    # å¤„ç†Vè¯„ä¼°å¸§æ•°æ®
                    if 'frames' in v_evaluation_data:
                        for frame in v_evaluation_data['frames']:
                            frame_data = {
                                'v_value': frame['v_value'],
                                'x': frame['x_coords'],
                                # ä¿®å¤ï¼šæ­£ç¡®è®¿é—®exposure_dataï¼Œæ”¯æŒæ–°æ—§ä¸¤ç§æ•°æ®æ ¼å¼
                                'exposure_dose': frame.get('exposure_dose', frame.get('exposure_data', [])),
                                # ä¿®å¤ï¼šæ­£ç¡®è®¿é—®thickness_dataï¼Œæ”¯æŒæ–°æ—§ä¸¤ç§æ•°æ®æ ¼å¼
                                'thickness': frame.get('thickness', frame.get('thickness_data', []))
                            }
                            plot_data['v_evaluation_frames'].append(frame_data)
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ¢å¤é™æ€æ•°æ®ï¼Œç¡®ä¿å‰ç«¯èƒ½åŒæ—¶è·å¾—é™æ€æ•°æ®å’ŒVè¯„ä¼°æ•°æ®
                    plot_data.update(static_data_backup)
                    
                    print(f"[Dill-1D-V-Eval] âœ… Vè¯„ä¼°æ•°æ®ç”Ÿæˆå®Œæˆ: {len(plot_data.get('v_evaluation_frames', []))}å¸§ï¼Œç”¨æ—¶{v_calc_time:.3f}s")
                    print(f"[Dill-1D-V-Eval] âœ… é™æ€æ•°æ®å·²æ¢å¤ï¼Œç¡®ä¿å‰ç«¯é™æ€å›¾è¡¨æ­£å¸¸æ˜¾ç¤º")
                    print(f"[Dill-1D-V-Eval] æœ€ç»ˆæ•°æ®éªŒè¯ï¼šé™æ€æ•°æ®xé•¿åº¦={len(plot_data.get('x', []))}, Vè¯„ä¼°å¸§æ•°={len(plot_data.get('v_evaluation_frames', []))}")
                    add_log_entry('success', 'dill', f"âœ… 1D Vè¯„ä¼°æ•°æ®ç”Ÿæˆå®Œæˆ", dimension='1d')
                    add_success_log('dill', f"1D Vè¯„ä¼°æ•°æ®ç”Ÿæˆå®Œæˆ ({v_time_steps}å¸§), ç”¨æ—¶{v_calc_time:.3f}s", dimension='1d')
                
                # å¦‚æœä¸¤ä¸ªåŠŸèƒ½éƒ½æ²¡æœ‰å¯ç”¨ï¼Œè¾“å‡ºé™æ€æ¨¡å¼ä¿¡æ¯
                if not enable_1d_animation and not enable_1d_v_evaluation:
                    print(f"[Dill-1D] é™æ€æ¨¡å¼ï¼Œå¼€å§‹è®¡ç®—ä¸€ç»´ç©ºé—´åˆ†å¸ƒï¼Œå…±1000ä¸ªä½ç½®")
                    add_log_entry('info', 'dill', f"Dill-1Dæ¨¡å‹å‚æ•° (1Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp}, C={C}", dimension='1d')
                    add_log_entry('progress', 'dill', f"å¼€å§‹è®¡ç®—ä¸€ç»´ç©ºé—´åˆ†å¸ƒï¼Œå…±1000ä¸ªä½ç½®", dimension='1d')
                
                calc_time = total_calc_time
                
                # æ£€æŸ¥æ˜¯å¦ä¸º1DåŠ¨ç”»æ¨¡å¼æˆ–Vè¯„ä¼°æ¨¡å¼ - éœ€è¦åŒºåˆ«å¤„ç†æ•°æ®ç»“æ„
                if enable_1d_animation and plot_data and 'animation_frames' in plot_data:
                    # 1DåŠ¨ç”»æ¨¡å¼ - æ•°æ®åœ¨animation_framesä¸­ï¼Œä¸éœ€è¦è¿›åº¦ç»Ÿè®¡
                    print(f"[Dill-1D-Animation] âœ… åŠ¨ç”»æ•°æ®å¤„ç†å®Œæˆï¼Œè·³è¿‡ç»Ÿè®¡åˆ†æ")
                    add_log_entry('success', 'dill', f"âœ… 1DåŠ¨ç”»æ•°æ®å¤„ç†å®Œæˆ", dimension='1d')
                elif data.get('enable_1d_v_evaluation', False) and plot_data and 'v_evaluation_frames' in plot_data:
                    # 1D Vè¯„ä¼°æ¨¡å¼ - æ•°æ®åœ¨v_evaluation_framesä¸­ï¼Œä¸éœ€è¦è¿›åº¦ç»Ÿè®¡
                    print(f"[Dill-1D-V-Eval] âœ… Vè¯„ä¼°æ•°æ®å¤„ç†å®Œæˆï¼Œè·³è¿‡ç»Ÿè®¡åˆ†æ")
                    add_log_entry('success', 'dill', f"âœ… 1D Vè¯„ä¼°æ•°æ®å¤„ç†å®Œæˆ", dimension='1d')
                elif plot_data and 'exposure_dose' in plot_data:
                    # é™æ€1Dæ¨¡å¼ - æ­£å¸¸å¤„ç†ç»Ÿè®¡æ•°æ®
                    exposure_array = np.array(plot_data['exposure_dose'])
                    thickness_array = np.array(plot_data['thickness'])
                    x_array = np.array(plot_data['x'])
                    
                    # æ¨¡æ‹Ÿè®¡ç®—è¿›åº¦è¾“å‡ºï¼ˆå› ä¸ºè®¡ç®—å¾ˆå¿«ï¼Œè¿™é‡Œç®€åŒ–æ˜¾ç¤ºï¼‰
                    # ç¡®ä¿æ•°ç»„é•¿åº¦è¶³å¤Ÿï¼Œé¿å…ç´¢å¼•è¶Šç•Œ
                    array_length = len(x_array)
                    
                    # åŠ¨æ€è®¡ç®—è¿›åº¦ç´¢å¼•ï¼Œç¡®ä¿ä¸è¶…è¿‡æ•°ç»„è¾¹ç•Œ
                    idx_20_percent = min(199, array_length - 1)
                    idx_50_percent = min(499, array_length - 1) 
                    idx_80_percent = min(799, array_length - 1)
                    
                    # å®‰å…¨çš„è¿›åº¦è¾“å‡º
                    print(f"[Dill-1D] è¿›åº¦: {idx_20_percent+1}/{array_length}, pos={x_array[idx_20_percent]:.3f}, exposure={exposure_array[idx_20_percent]:.3f}, thickness={thickness_array[idx_20_percent]:.4f}")
                    print(f"[Dill-1D] è¿›åº¦: {idx_50_percent+1}/{array_length}, pos={x_array[idx_50_percent]:.3f}, exposure={exposure_array[idx_50_percent]:.3f}, thickness={thickness_array[idx_50_percent]:.4f}")
                    print(f"[Dill-1D] è¿›åº¦: {idx_80_percent+1}/{array_length}, pos={x_array[idx_80_percent]:.3f}, exposure={exposure_array[idx_80_percent]:.3f}, thickness={thickness_array[idx_80_percent]:.4f}")
                    
                    # æ·»åŠ å®‰å…¨çš„è¿›åº¦ä¿¡æ¯åˆ°æ—¥å¿—ç³»ç»Ÿ
                    add_log_entry('progress', 'dill', f"è¿›åº¦: {idx_20_percent+1}/{array_length}, pos={x_array[idx_20_percent]:.3f}, exposure={exposure_array[idx_20_percent]:.3f}, thickness={thickness_array[idx_20_percent]:.4f}", dimension='1d')
                    add_log_entry('progress', 'dill', f"è¿›åº¦: {idx_50_percent+1}/{array_length}, pos={x_array[idx_50_percent]:.3f}, exposure={exposure_array[idx_50_percent]:.3f}, thickness={thickness_array[idx_50_percent]:.4f}", dimension='1d')
                    add_log_entry('progress', 'dill', f"è¿›åº¦: {idx_80_percent+1}/{array_length}, pos={x_array[idx_80_percent]:.3f}, exposure={exposure_array[idx_80_percent]:.3f}, thickness={thickness_array[idx_80_percent]:.4f}", dimension='1d')
                    
                    print(f"[Dill-1D] ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                    print(f"  âœ… æˆåŠŸè®¡ç®—: 1000/1000 (100.0%)")
                    print(f"  âŒ å¤±è´¥è®¡ç®—: 0/1000 (0.0%)")
                    print(f"  â±ï¸  å¹³å‡è®¡ç®—æ—¶é—´: {calc_time/1000:.6f}s/ç‚¹")
                    print(f"  ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{exposure_array.min():.3f}, {exposure_array.max():.3f}] mJ/cmÂ²")
                    print(f"  ğŸ“ åšåº¦èŒƒå›´: [{thickness_array.min():.4f}, {thickness_array.max():.4f}] (å½’ä¸€åŒ–)")
                    print(f"  ğŸ’¾ æ•°æ®è´¨é‡: ä¼˜ç§€")
                    print(f"  ğŸ“Š ç»Ÿè®¡ç‰¹å¾:")
                    print(f"     æ›å…‰å‰‚é‡: å‡å€¼={exposure_array.mean():.3f}, æ ‡å‡†å·®={exposure_array.std():.3f}")
                    print(f"     åšåº¦åˆ†å¸ƒ: å‡å€¼={thickness_array.mean():.4f}, æ ‡å‡†å·®={thickness_array.std():.4f}")
                    
                    # æ·»åŠ è¯¦ç»†ç»Ÿè®¡åˆ°æ—¥å¿—ç³»ç»Ÿ
                    add_log_entry('success', 'dill', f"ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡", dimension='1d')
                    add_log_entry('info', 'dill', f"âœ… æˆåŠŸè®¡ç®—: 1000/1000 (100.0%)", dimension='1d')
                    add_log_entry('info', 'dill', f"âŒ å¤±è´¥è®¡ç®—: 0/1000 (0.0%)", dimension='1d')
                    add_log_entry('info', 'dill', f"â±ï¸ å¹³å‡è®¡ç®—æ—¶é—´: {calc_time/1000:.6f}s/ç‚¹", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{exposure_array.min():.3f}, {exposure_array.max():.3f}] mJ/cmÂ²", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ“ åšåº¦èŒƒå›´: [{thickness_array.min():.4f}, {thickness_array.max():.4f}] (å½’ä¸€åŒ–)", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ’¾ æ•°æ®è´¨é‡: ä¼˜ç§€", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ“Š æ›å…‰å‰‚é‡ç»Ÿè®¡: å‡å€¼={exposure_array.mean():.3f}, æ ‡å‡†å·®={exposure_array.std():.3f}", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ“Š åšåº¦åˆ†å¸ƒç»Ÿè®¡: å‡å€¼={thickness_array.mean():.4f}, æ ‡å‡†å·®={thickness_array.std():.4f}", dimension='1d')
                    
                    # è®¡ç®—å¯¹æ¯”åº¦
                    cv_exposure = exposure_array.std() / exposure_array.mean() if exposure_array.mean() > 0 else 0
                    cv_thickness = thickness_array.std() / thickness_array.mean() if thickness_array.mean() > 0 else 0
                    
                    print(f"  ğŸ“ˆ é«˜å¯¹æ¯”åº¦æ£€æµ‹: æ›å…‰å‰‚é‡å˜åŒ–{'æ˜¾è‘—' if cv_exposure > 0.3 else 'é€‚ä¸­' if cv_exposure > 0.1 else 'è¾ƒå°'} (CV={cv_exposure:.3f})")
                    print(f"  ğŸ­ å¼ºè°ƒåˆ¶æ£€æµ‹: åšåº¦å˜åŒ–{'æ˜¾è‘—' if cv_thickness > 0.3 else 'é€‚ä¸­' if cv_thickness > 0.1 else 'è¾ƒå°'} (CV={cv_thickness:.3f})")
                    print(f"  ğŸ“ Dillæ¨¡å‹ç‰¹å¾åˆ†æ:")
                    print(f"     å¯¹æ¯”åº¦å› å­: {cv_exposure:.3f}")
                    print(f"     åˆ†è¾¨ç‡ä¼°è®¡: {2*np.pi/K:.3f} Î¼m" if K > 0 else "æ— é™å¤§")
                    print(f"     å…‰æ•é€Ÿç‡å¸¸æ•°C: {C:.4f} cmÂ²/mJ")
                    
                    # æ·»åŠ åˆ†æç»“æœåˆ°æ—¥å¿—ç³»ç»Ÿ
                    contrast_level = 'æ˜¾è‘—' if cv_exposure > 0.3 else 'é€‚ä¸­' if cv_exposure > 0.1 else 'è¾ƒå°'
                    modulation_level = 'æ˜¾è‘—' if cv_thickness > 0.3 else 'é€‚ä¸­' if cv_thickness > 0.1 else 'è¾ƒå°'
                    add_log_entry('info', 'dill', f"ğŸ“ˆ é«˜å¯¹æ¯”åº¦æ£€æµ‹: æ›å…‰å‰‚é‡å˜åŒ–{contrast_level} (CV={cv_exposure:.3f})", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ­ å¼ºè°ƒåˆ¶æ£€æµ‹: åšåº¦å˜åŒ–{modulation_level} (CV={cv_thickness:.3f})", dimension='1d')
                    add_log_entry('info', 'dill', f"ğŸ“ Dillæ¨¡å‹ç‰¹å¾åˆ†æ", dimension='1d')
                    add_log_entry('info', 'dill', f"   å¯¹æ¯”åº¦å› å­: {cv_exposure:.3f}", dimension='1d')
                    resolution = f"{2*np.pi/K:.3f} Î¼m" if K > 0 else "æ— é™å¤§"
                    add_log_entry('info', 'dill', f"   åˆ†è¾¨ç‡ä¼°è®¡: {resolution}", dimension='1d')
                    add_log_entry('info', 'dill', f"   å…‰æ•é€Ÿç‡å¸¸æ•°C: {C:.4f} cmÂ²/mJ", dimension='1d')
                
                if enable_1d_animation:
                    add_success_log('dill', f"1DåŠ¨ç”»æ•°æ®ç”Ÿæˆå®Œæˆï¼Œ{len(plot_data.get('animation_frames', []))}å¸§", dimension='1d')
                elif data.get('enable_1d_v_evaluation', False):
                    add_success_log('dill', f"1D Vè¯„ä¼°æ•°æ®ç”Ÿæˆå®Œæˆï¼Œ{len(plot_data.get('v_evaluation_frames', []))}å¸§", dimension='1d')
                else:
                    add_success_log('dill', f"ä¸€ç»´è®¡ç®—å®Œæˆï¼Œ1000ç‚¹ï¼Œç”¨æ—¶{calc_time:.3f}s", dimension='1d')

        elif model_type == 'car':
            is_valid, message = validate_car_input(data)
            if not is_valid: 
                add_error_log('car', f"å‚æ•°æ ¡éªŒå¤±è´¥: {message}", dimension=sine_type)
                return jsonify(format_response(False, message=message)), 400
                
            I_avg, V_car, t_exp_car = float(data['I_avg']), float(data['V']), float(data['t_exp'])
            acid_gen_eff, diff_len, react_rate, amp, contr = float(data['acid_gen_efficiency']), float(data['diffusion_length']), float(data['reaction_rate']), float(data['amplification']), float(data['contrast'])
            
            if sine_type == 'multi':
                Kx, Ky, phi_expr = float(data.get('Kx',0)), float(data.get('Ky',0)), data.get('phi_expr','0')
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                y_points = int(data.get('y_points', 100))
                
                print(f"CARæ¨¡å‹å‚æ•° (2Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V_car}, t_exp={t_exp_car}")
                print(f"  åŒ–å­¦æ”¾å¤§å‚æ•°: Î·={acid_gen_eff}, l_diff={diff_len}, k={react_rate}, A={amp}, contrast={contr}")
                print(f"  äºŒç»´å‚æ•°: Kx={Kx}, Ky={Ky}, phi_expr='{phi_expr}'")
                print(f"  Yè½´èŒƒå›´: [{y_min}, {y_max}], ç‚¹æ•°: {y_points}")
                print(f"[CAR-2D] å¼€å§‹è®¡ç®—åŒ–å­¦æ”¾å¤§äºŒç»´ç©ºé—´åˆ†å¸ƒï¼Œç½‘æ ¼å¤§å°: 1000Ã—{y_points}")
                
                # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                add_log_entry('info', 'car', f"CAR-2Dæ¨¡å‹å‚æ•° (2Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V_car}, t_exp={t_exp_car}", dimension='2d')
                add_log_entry('info', 'car', f"åŒ–å­¦æ”¾å¤§å‚æ•°: Î·={acid_gen_eff}, l_diff={diff_len}, k={react_rate}, A={amp}, contrast={contr}", dimension='2d')
                add_log_entry('info', 'car', f"äºŒç»´å‚æ•°: Kx={Kx}, Ky={Ky}, phi_expr='{phi_expr}'", dimension='2d')
                add_log_entry('info', 'car', f"Yè½´èŒƒå›´: [{y_min}, {y_max}], ç‚¹æ•°: {y_points}", dimension='2d')
                add_log_entry('progress', 'car', f"å¼€å§‹è®¡ç®—åŒ–å­¦æ”¾å¤§äºŒç»´ç©ºé—´åˆ†å¸ƒï¼Œç½‘æ ¼å¤§å°: 1000Ã—{y_points}", dimension='2d')
                
                if y_min >= y_max:
                    add_error_log('car', "Yè½´èŒƒå›´é…ç½®é”™è¯¯", dimension='2d')
                    return jsonify(format_response(False, message_zh="Yè½´èŒƒå›´æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼", message_en="Y-axis range min must be less than max")), 400
                if y_points <= 1:
                    add_error_log('car', "Yè½´ç‚¹æ•°é…ç½®é”™è¯¯", dimension='2d')
                    return jsonify(format_response(False, message_zh="Yè½´ç‚¹æ•°å¿…é¡»å¤§äº1æ‰èƒ½è¿›è¡ŒäºŒç»´è®¡ç®—", message_en="Number of Y-axis points must be greater than 1 for 2D calculation")), 400
                
                y_range = np.linspace(y_min, y_max, y_points).tolist()
                
                calc_start = time.time()
                plot_data = model.generate_data(I_avg, V_car, None, t_exp_car, acid_gen_eff, diff_len, react_rate, amp, contr, sine_type=sine_type, Kx=Kx, Ky=Ky, phi_expr=phi_expr, y_range=y_range)
                calc_time = time.time() - calc_start
                
                if plot_data and 'z_acid_concentration' in plot_data:
                    acid_array = np.array(plot_data['z_acid_concentration'])
                    deprotect_array = np.array(plot_data['z_deprotection'])
                    
                    print(f"[CAR-2D] ğŸ¯ äºŒç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆç»Ÿè®¡:")
                    print(f"  âœ… ç½‘æ ¼å¤§å°: {acid_array.shape}")
                    print(f"  â±ï¸  è®¡ç®—æ—¶é—´: {calc_time:.3f}s")
                    print(f"  ğŸ§ª å…‰é…¸æµ“åº¦èŒƒå›´: [{acid_array.min():.3f}, {acid_array.max():.3f}] ç›¸å¯¹å•ä½")
                    print(f"  ğŸ”¬ è„±ä¿æŠ¤åº¦èŒƒå›´: [{deprotect_array.min():.4f}, {deprotect_array.max():.4f}] (å½’ä¸€åŒ–)")
                    print(f"  âš—ï¸  CARæ¨¡å‹åŒ–å­¦æ”¾å¤§åˆ†æ:")
                    print(f"     å…‰é…¸äº§ç”Ÿæ•ˆç‡: {acid_gen_eff}")
                    print(f"     æ‰©æ•£é•¿åº¦: {diff_len} Î¼m")
                    print(f"     ååº”é€Ÿç‡: {react_rate}")
                    print(f"     æ”¾å¤§å› å­: {amp}")
                    print(f"     ç©ºé—´é¢‘ç‡: Kx={Kx}, Ky={Ky}")
                    
                    # æ·»åŠ è¯¦ç»†ç»Ÿè®¡åˆ°æ—¥å¿—ç³»ç»Ÿ
                    add_log_entry('success', 'car', f"ğŸ¯ äºŒç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆç»Ÿè®¡", dimension='2d')
                    add_log_entry('info', 'car', f"âœ… ç½‘æ ¼å¤§å°: {acid_array.shape}", dimension='2d')
                    add_log_entry('info', 'car', f"â±ï¸ è®¡ç®—æ—¶é—´: {calc_time:.3f}s", dimension='2d')
                    add_log_entry('info', 'car', f"ğŸ§ª å…‰é…¸æµ“åº¦èŒƒå›´: [{acid_array.min():.3f}, {acid_array.max():.3f}] ç›¸å¯¹å•ä½", dimension='2d')
                    add_log_entry('info', 'car', f"ğŸ”¬ è„±ä¿æŠ¤åº¦èŒƒå›´: [{deprotect_array.min():.4f}, {deprotect_array.max():.4f}] (å½’ä¸€åŒ–)", dimension='2d')
                    add_log_entry('info', 'car', f"âš—ï¸ CARæ¨¡å‹åŒ–å­¦æ”¾å¤§åˆ†æ", dimension='2d')
                    add_log_entry('info', 'car', f"   å…‰é…¸äº§ç”Ÿæ•ˆç‡: {acid_gen_eff}", dimension='2d')
                    add_log_entry('info', 'car', f"   æ‰©æ•£é•¿åº¦: {diff_len} Î¼m", dimension='2d')
                    add_log_entry('info', 'car', f"   ååº”é€Ÿç‡: {react_rate}", dimension='2d')
                    add_log_entry('info', 'car', f"   æ”¾å¤§å› å­: {amp}", dimension='2d')
                    add_log_entry('info', 'car', f"   ç©ºé—´é¢‘ç‡: Kx={Kx}, Ky={Ky}", dimension='2d')
                
                add_success_log('car', f"äºŒç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆï¼Œæ”¾å¤§å› å­{amp}ï¼Œç”¨æ—¶{calc_time:.3f}s", dimension='2d')
                
            elif sine_type == '3d':
                Kx, Ky, Kz, phi_expr = float(data.get('Kx',0)), float(data.get('Ky',0)), float(data.get('Kz',0)), data.get('phi_expr','0')
                y_min = float(data.get('y_min', 0))
                y_max = float(data.get('y_max', 10))
                z_min = float(data.get('z_min', 0))
                z_max = float(data.get('z_max', 10))
                
                print(f"CARæ¨¡å‹å‚æ•° (3Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V_car}, t_exp={t_exp_car}")
                print(f"  åŒ–å­¦æ”¾å¤§å‚æ•°: Î·={acid_gen_eff}, l_diff={diff_len}, k={react_rate}, A={amp}, contrast={contr}")
                print(f"  ä¸‰ç»´å‚æ•°: Kx={Kx}, Ky={Ky}, Kz={Kz}, phi_expr='{phi_expr}'")
                print(f"  Yè½´èŒƒå›´: [{y_min}, {y_max}]")
                print(f"  Zè½´èŒƒå›´: [{z_min}, {z_max}]")
                print(f"[CAR-3D] å¼€å§‹è®¡ç®—åŒ–å­¦æ”¾å¤§ä¸‰ç»´ç©ºé—´åˆ†å¸ƒï¼Œé¢„è®¡ç½‘æ ¼å¤§å°: 50Ã—50Ã—50")
                
                # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                add_log_entry('info', 'car', f"CAR-3Dæ¨¡å‹å‚æ•° (3Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V_car}, t_exp={t_exp_car}", dimension='3d')
                add_log_entry('info', 'car', f"åŒ–å­¦æ”¾å¤§å‚æ•°: Î·={acid_gen_eff}, l_diff={diff_len}, k={react_rate}, A={amp}, contrast={contr}", dimension='3d')
                add_log_entry('info', 'car', f"ä¸‰ç»´å‚æ•°: Kx={Kx}, Ky={Ky}, Kz={Kz}, phi_expr='{phi_expr}'", dimension='3d')
                add_log_entry('info', 'car', f"Yè½´èŒƒå›´: [{y_min}, {y_max}]", dimension='3d')
                add_log_entry('info', 'car', f"Zè½´èŒƒå›´: [{z_min}, {z_max}]", dimension='3d')
                add_log_entry('progress', 'car', f"å¼€å§‹è®¡ç®—åŒ–å­¦æ”¾å¤§ä¸‰ç»´ç©ºé—´åˆ†å¸ƒï¼Œé¢„è®¡ç½‘æ ¼å¤§å°: 50Ã—50Ã—50", dimension='3d')
                
                y_range = np.linspace(y_min, y_max, 50).tolist() if y_min < y_max else None
                z_range = np.linspace(z_min, z_max, 50).tolist() if z_min < z_max else None
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨4DåŠ¨ç”»
                enable_4d_animation = data.get('enable_4d_animation', False)
                if enable_4d_animation:
                    t_start = float(data.get('t_start', 0))
                    t_end = float(data.get('t_end', 5))
                    time_steps = int(data.get('time_steps', 20))
                    
                    print(f"[CAR-3D] å¯ç”¨4DåŠ¨ç”»: t_start={t_start}, t_end={t_end}, time_steps={time_steps}")
                    add_log_entry('info', 'car', f"å¯ç”¨4DåŠ¨ç”»: t_start={t_start}, t_end={t_end}, time_steps={time_steps}", dimension='4d')
                
                calc_start = time.time()
                plot_data = model.generate_data(I_avg, V_car, None, t_exp_car, acid_gen_eff, diff_len, react_rate, amp, contr, 
                                             sine_type=sine_type, Kx=Kx, Ky=Ky, Kz=Kz, phi_expr=phi_expr, 
                                             y_range=y_range, z_range=z_range, 
                                             enable_4d_animation=enable_4d_animation,
                                             t_start=t_start if enable_4d_animation else 0,
                                             t_end=t_end if enable_4d_animation else 5,
                                             time_steps=time_steps if enable_4d_animation else 20)
                calc_time = time.time() - calc_start
                
                print(f"[CAR-3D] ğŸ¯ ä¸‰ç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆç»Ÿè®¡:")
                print(f"  âœ… è®¡ç®—æˆåŠŸ")
                print(f"  â±ï¸  è®¡ç®—æ—¶é—´: {calc_time:.3f}s")
                print(f"  âš—ï¸  CARæ¨¡å‹3DåŒ–å­¦æ”¾å¤§åˆ†æ:")
                print(f"     å…‰é…¸äº§ç”Ÿæ•ˆç‡: {acid_gen_eff}")
                print(f"     æ‰©æ•£é•¿åº¦: {diff_len} Î¼m")
                print(f"     ä¸‰ç»´ç©ºé—´é¢‘ç‡: Kx={Kx}, Ky={Ky}, Kz={Kz}")
                print(f"     åŒ–å­¦æ”¾å¤§å› å­: {amp}")
                
                # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                add_log_entry('success', 'car', f"ğŸ¯ ä¸‰ç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆç»Ÿè®¡", dimension='3d')
                add_log_entry('info', 'car', f"âœ… è®¡ç®—æˆåŠŸ", dimension='3d')
                add_log_entry('info', 'car', f"â±ï¸ è®¡ç®—æ—¶é—´: {calc_time:.3f}s", dimension='3d')
                add_log_entry('info', 'car', f"âš—ï¸ CARæ¨¡å‹3DåŒ–å­¦æ”¾å¤§åˆ†æ", dimension='3d')
                add_log_entry('info', 'car', f"   å…‰é…¸äº§ç”Ÿæ•ˆç‡: {acid_gen_eff}", dimension='3d')
                add_log_entry('info', 'car', f"   æ‰©æ•£é•¿åº¦: {diff_len} Î¼m", dimension='3d')
                add_log_entry('info', 'car', f"   ä¸‰ç»´ç©ºé—´é¢‘ç‡: Kx={Kx}, Ky={Ky}, Kz={Kz}", dimension='3d')
                add_log_entry('info', 'car', f"   åŒ–å­¦æ”¾å¤§å› å­: {amp}", dimension='3d')
                
                add_success_log('car', f"ä¸‰ç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆï¼Œæ”¾å¤§å› å­{amp}ï¼Œç”¨æ—¶{calc_time:.3f}s", dimension='3d')
                
            else: # 1D CAR
                K_car = float(data.get('K', 2.0))
                
                print(f"CARæ¨¡å‹å‚æ•° (1Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V_car}, K={K_car}, t_exp={t_exp_car}")
                print(f"  åŒ–å­¦æ”¾å¤§å‚æ•°: Î·={acid_gen_eff}, l_diff={diff_len}, k={react_rate}, A={amp}, contrast={contr}")
                print(f"[CAR-1D] å¼€å§‹è®¡ç®—åŒ–å­¦æ”¾å¤§ä¸€ç»´ç©ºé—´åˆ†å¸ƒï¼Œå…±1000ä¸ªä½ç½®")
                
                # æ·»åŠ åˆ°æ—¥å¿—ç³»ç»Ÿ
                add_log_entry('info', 'car', f"CAR-1Dæ¨¡å‹å‚æ•° (1Dæ­£å¼¦æ³¢): I_avg={I_avg}, V={V_car}, K={K_car}, t_exp={t_exp_car}", dimension='1d')
                add_log_entry('info', 'car', f"åŒ–å­¦æ”¾å¤§å‚æ•°: Î·={acid_gen_eff}, l_diff={diff_len}, k={react_rate}, A={amp}, contrast={contr}", dimension='1d')
                add_log_entry('progress', 'car', f"å¼€å§‹è®¡ç®—åŒ–å­¦æ”¾å¤§ä¸€ç»´ç©ºé—´åˆ†å¸ƒï¼Œå…±1000ä¸ªä½ç½®", dimension='1d')
                
                calc_start = time.time()
                plot_data = model.generate_data(I_avg, V_car, K_car, t_exp_car, acid_gen_eff, diff_len, react_rate, amp, contr, sine_type=sine_type)
                calc_time = time.time() - calc_start
                
                if plot_data and 'acid_concentration' in plot_data:
                    acid_array = np.array(plot_data['acid_concentration'])
                    deprotect_array = np.array(plot_data['deprotection'])
                    x_array = np.array(plot_data['positions'])
                    
                    # ç¡®ä¿æ•°ç»„é•¿åº¦è¶³å¤Ÿï¼Œé¿å…ç´¢å¼•è¶Šç•Œ
                    array_length = len(x_array)
                    
                    # åŠ¨æ€è®¡ç®—è¿›åº¦ç´¢å¼•ï¼Œç¡®ä¿ä¸è¶…è¿‡æ•°ç»„è¾¹ç•Œ
                    idx_20_percent = min(199, array_length - 1)
                    idx_50_percent = min(499, array_length - 1) 
                    idx_80_percent = min(799, array_length - 1)
                    
                    # å®‰å…¨çš„è¿›åº¦è¾“å‡º
                    print(f"[CAR-1D] è¿›åº¦: {idx_20_percent+1}/{array_length}, pos={x_array[idx_20_percent]:.3f}, acid={acid_array[idx_20_percent]:.3f}, deprotection={deprotect_array[idx_20_percent]:.4f}")
                    print(f"[CAR-1D] è¿›åº¦: {idx_50_percent+1}/{array_length}, pos={x_array[idx_50_percent]:.3f}, acid={acid_array[idx_50_percent]:.3f}, deprotection={deprotect_array[idx_50_percent]:.4f}")
                    print(f"[CAR-1D] è¿›åº¦: {idx_80_percent+1}/{array_length}, pos={x_array[idx_80_percent]:.3f}, acid={acid_array[idx_80_percent]:.3f}, deprotection={deprotect_array[idx_80_percent]:.4f}")
                    
                    # æ·»åŠ å®‰å…¨çš„è¿›åº¦ä¿¡æ¯åˆ°æ—¥å¿—ç³»ç»Ÿ
                    add_log_entry('progress', 'car', f"è¿›åº¦: {idx_20_percent+1}/{array_length}, pos={x_array[idx_20_percent]:.3f}, acid={acid_array[idx_20_percent]:.3f}, deprotection={deprotect_array[idx_20_percent]:.4f}", dimension='1d')
                    add_log_entry('progress', 'car', f"è¿›åº¦: {idx_50_percent+1}/{array_length}, pos={x_array[idx_50_percent]:.3f}, acid={acid_array[idx_50_percent]:.3f}, deprotection={deprotect_array[idx_50_percent]:.4f}", dimension='1d')
                    add_log_entry('progress', 'car', f"è¿›åº¦: {idx_80_percent+1}/{array_length}, pos={x_array[idx_80_percent]:.3f}, acid={acid_array[idx_80_percent]:.3f}, deprotection={deprotect_array[idx_80_percent]:.4f}", dimension='1d')
                    
                    print(f"[CAR-1D] ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                    print(f"  âœ… æˆåŠŸè®¡ç®—: 1000/1000 (100.0%)")
                    print(f"  âŒ å¤±è´¥è®¡ç®—: 0/1000 (0.0%)")
                    print(f"  â±ï¸  å¹³å‡è®¡ç®—æ—¶é—´: {calc_time/1000:.6f}s/ç‚¹")
                    print(f"  ğŸ§ª å…‰é…¸æµ“åº¦èŒƒå›´: [{acid_array.min():.3f}, {acid_array.max():.3f}] ç›¸å¯¹å•ä½")
                    print(f"  ğŸ”¬ è„±ä¿æŠ¤åº¦èŒƒå›´: [{deprotect_array.min():.4f}, {deprotect_array.max():.4f}] (å½’ä¸€åŒ–)")
                    print(f"  ğŸ’¾ æ•°æ®è´¨é‡: ä¼˜ç§€")
                    print(f"  ğŸ“Š ç»Ÿè®¡ç‰¹å¾:")
                    print(f"     å…‰é…¸æµ“åº¦: å‡å€¼={acid_array.mean():.3f}, æ ‡å‡†å·®={acid_array.std():.3f}")
                    print(f"     è„±ä¿æŠ¤åº¦: å‡å€¼={deprotect_array.mean():.4f}, æ ‡å‡†å·®={deprotect_array.std():.4f}")
                    print(f"  âš—ï¸  CARæ¨¡å‹åŒ–å­¦æ”¾å¤§åˆ†æ:")
                    print(f"     å…‰é…¸äº§ç”Ÿæ•ˆç‡: {acid_gen_eff}")
                    print(f"     æ‰©æ•£é•¿åº¦: {diff_len} Î¼m")
                    print(f"     ååº”é€Ÿç‡å¸¸æ•°: {react_rate}")
                    print(f"     åŒ–å­¦æ”¾å¤§å› å­: {amp}")
                    print(f"     å¯¹æ¯”åº¦: {contr}")
                    
                    # æ·»åŠ è¯¦ç»†ç»Ÿè®¡åˆ°æ—¥å¿—ç³»ç»Ÿ
                    add_log_entry('success', 'car', f"ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡", dimension='1d')
                    add_log_entry('info', 'car', f"âœ… æˆåŠŸè®¡ç®—: 1000/1000 (100.0%)", dimension='1d')
                    add_log_entry('info', 'car', f"âŒ å¤±è´¥è®¡ç®—: 0/1000 (0.0%)", dimension='1d')
                    add_log_entry('info', 'car', f"â±ï¸ å¹³å‡è®¡ç®—æ—¶é—´: {calc_time/1000:.6f}s/ç‚¹", dimension='1d')
                    add_log_entry('info', 'car', f"ğŸ§ª å…‰é…¸æµ“åº¦èŒƒå›´: [{acid_array.min():.3f}, {acid_array.max():.3f}] ç›¸å¯¹å•ä½", dimension='1d')
                    add_log_entry('info', 'car', f"ğŸ”¬ è„±ä¿æŠ¤åº¦èŒƒå›´: [{deprotect_array.min():.4f}, {deprotect_array.max():.4f}] (å½’ä¸€åŒ–)", dimension='1d')
                    add_log_entry('info', 'car', f"ğŸ’¾ æ•°æ®è´¨é‡: ä¼˜ç§€", dimension='1d')
                    add_log_entry('info', 'car', f"ğŸ“Š å…‰é…¸æµ“åº¦ç»Ÿè®¡: å‡å€¼={acid_array.mean():.3f}, æ ‡å‡†å·®={acid_array.std():.3f}", dimension='1d')
                    add_log_entry('info', 'car', f"ğŸ“Š è„±ä¿æŠ¤åº¦ç»Ÿè®¡: å‡å€¼={deprotect_array.mean():.4f}, æ ‡å‡†å·®={deprotect_array.std():.4f}", dimension='1d')
                    add_log_entry('info', 'car', f"âš—ï¸ CARæ¨¡å‹åŒ–å­¦æ”¾å¤§åˆ†æ", dimension='1d')
                    add_log_entry('info', 'car', f"   å…‰é…¸äº§ç”Ÿæ•ˆç‡: {acid_gen_eff}", dimension='1d')
                    add_log_entry('info', 'car', f"   æ‰©æ•£é•¿åº¦: {diff_len} Î¼m", dimension='1d')
                    add_log_entry('info', 'car', f"   ååº”é€Ÿç‡å¸¸æ•°: {react_rate}", dimension='1d')
                    add_log_entry('info', 'car', f"   åŒ–å­¦æ”¾å¤§å› å­: {amp}", dimension='1d')
                    add_log_entry('info', 'car', f"   å¯¹æ¯”åº¦: {contr}", dimension='1d')
                
                add_success_log('car', f"ä¸€ç»´åŒ–å­¦æ”¾å¤§è®¡ç®—å®Œæˆï¼Œæ”¾å¤§å› å­{amp}ï¼Œç”¨æ—¶{calc_time:.3f}s", dimension='1d')
        else:
            add_error_log('system', f"æœªçŸ¥æ¨¡å‹ç±»å‹: {model_type}", dimension=sine_type)
            return jsonify(format_response(False, message="æœªçŸ¥æ¨¡å‹ç±»å‹")), 400
        
        # æ€»è®¡ç®—æ—¶é—´
        total_time = time.time() - start_time
        print(f"[{model_type.upper()}-{sine_type.upper()}] ğŸ æ€»è®¡ç®—æ—¶é—´: {total_time:.3f}s")
        
        # æ·»åŠ æ€»è®¡ç®—æ—¶é—´åˆ°æ—¥å¿—ç³»ç»Ÿ
        dimension_map = {'1d': '1d', 'multi': '2d', '3d': '3d', 'single': '1d'}
        dimension = dimension_map.get(sine_type, sine_type)
        add_log_entry('success', model_type, f"ğŸ æ€»è®¡ç®—æ—¶é—´: {total_time:.3f}s", dimension=dimension)
        
        # Enhanced Dillæ¨¡å‹2Dæ•°æ®éªŒè¯å’Œç»Ÿè®¡
        if model_type == 'enhanced_dill' and sine_type == 'multi' and plot_data:
            print(f"[Enhanced-Dill-2D] ğŸ“Š æ•°æ®å®Œæ•´æ€§éªŒè¯:")
            
            # æ£€æŸ¥å…¼å®¹æ€§å­—æ®µ
            has_z_exposure_dose = 'z_exposure_dose' in plot_data and plot_data['z_exposure_dose']
            has_z_thickness = 'z_thickness' in plot_data and plot_data['z_thickness']
            
            # æ£€æŸ¥æ‰©å±•å­—æ®µ
            has_yz_data = 'yz_exposure' in plot_data and 'yz_thickness' in plot_data
            has_xy_data = 'xy_exposure' in plot_data and 'xy_thickness' in plot_data
            
            print(f"  âœ… å…¼å®¹æ€§æ•°æ®: z_exposure_dose={has_z_exposure_dose}, z_thickness={has_z_thickness}")
            print(f"  âœ… YZå¹³é¢æ•°æ®: yz_exposure={has_yz_data}")
            print(f"  âœ… XYå¹³é¢æ•°æ®: xy_exposure={has_xy_data}")
            print(f"  âœ… å…ƒæ•°æ®: is_2d={plot_data.get('is_2d', False)}")
            
            # æ·»åŠ éªŒè¯ç»“æœåˆ°æ—¥å¿—
            add_log_entry('info', 'enhanced_dill', f"ğŸ“Š æ•°æ®å®Œæ•´æ€§éªŒè¯", dimension='2d')
            add_log_entry('info', 'enhanced_dill', f"  å…¼å®¹æ€§æ•°æ®: z_exposure_dose={has_z_exposure_dose}, z_thickness={has_z_thickness}", dimension='2d')
            add_log_entry('info', 'enhanced_dill', f"  YZå¹³é¢æ•°æ®: yz_exposure={has_yz_data}", dimension='2d')
            add_log_entry('info', 'enhanced_dill', f"  XYå¹³é¢æ•°æ®: xy_exposure={has_xy_data}", dimension='2d')
            add_log_entry('info', 'enhanced_dill', f"  å…ƒæ•°æ®: is_2d={plot_data.get('is_2d', False)}", dimension='2d')
            
            if has_z_exposure_dose and has_z_thickness:
                add_log_entry('success', 'enhanced_dill', f"âœ… Enhanced Dill 2Dæ•°æ®å‡†å¤‡å®Œæˆï¼Œå‰ç«¯æ˜¾ç¤ºå·²å°±ç»ª", dimension='2d')
            else:
                add_log_entry('warning', 'enhanced_dill', f"âš ï¸ Enhanced Dill 2Då…¼å®¹æ€§æ•°æ®ä¸å®Œæ•´", dimension='2d')
        
        # ä¿å­˜æœ€è¿‘çš„è®¡ç®—ç»“æœï¼Œä¾›éªŒè¯é¡µé¢ä½¿ç”¨
        global latest_calculation_result
        latest_calculation_result.update({
            'timestamp': datetime.datetime.now().isoformat(),
            'parameters': data,  # ä¿å­˜è¾“å…¥å‚æ•°
            'results': plot_data,  # ä¿å­˜è®¡ç®—ç»“æœ
            'model_type': data.get('model_type', 'unknown')
        })
        print(f"âœ… å·²ä¿å­˜æœ€è¿‘è®¡ç®—ç»“æœåˆ°å…¨å±€å­˜å‚¨ï¼Œæ¨¡å‹ç±»å‹: {data.get('model_type')}")
        
        return jsonify(format_response(True, data=plot_data)), 200
    except Exception as e:
        # è®°å½•å¼‚å¸¸å‚æ•°å’Œé”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
        with open('dill_backend.log', 'a', encoding='utf-8') as f:
            f.write(f"[{datetime.datetime.now()}]\n")
            f.write(f"è¯·æ±‚å‚æ•°: {data if 'data' in locals() else 'æ— '}\n")
            f.write(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}\n")
            f.write(f"å¼‚å¸¸ä¿¡æ¯: {str(e)}\n")
            f.write(f"å †æ ˆä¿¡æ¯: {traceback.format_exc()}\n\n")
        
        model_type = data.get('model_type', 'unknown') if 'data' in locals() else 'unknown'
        sine_type = data.get('sine_type', 'unknown') if 'data' in locals() else 'unknown'
        add_error_log(model_type, f"è®¡ç®—å¼‚å¸¸: {str(e)}", dimension=sine_type)
        
        return jsonify(format_response(False, message=f"æ•°æ®è®¡ç®—é”™è¯¯: {str(e)}")), 500

@api_bp.route('/compare', methods=['POST'])
def compare():
    """
    æ¯”è¾ƒå¤šç»„å‚æ•°çš„è®¡ç®—ç»“æœ
    
    æ¥æ”¶å‚æ•°:
        parameter_sets: åŒ…å«å¤šç»„å‚æ•°çš„æ•°ç»„ï¼Œæ”¯æŒè–„èƒ¶/åšèƒ¶/CARæ¨¡å‹å‚æ•°
        
    è¿”å›:
        JSONæ ¼å¼çš„å“åº”ï¼ŒåŒ…å«æ¯”è¾ƒå›¾åƒ
    """
    try:
        # è·å–JSONæ•°æ®
        data = request.get_json()
        
        # éªŒè¯è¾“å…¥
        if 'parameter_sets' not in data or not isinstance(data['parameter_sets'], list):
            return jsonify(format_response(False, message="ç¼ºå°‘parameter_setsæ•°ç»„")), 400
        
        if len(data['parameter_sets']) < 1:
            return jsonify(format_response(False, message="è‡³å°‘éœ€è¦ä¸€ç»„å‚æ•°")), 400
            
        parameter_sets = data['parameter_sets']
        
        # éªŒè¯æ¯ç»„å‚æ•°
        for i, params in enumerate(parameter_sets):
            # è¯†åˆ«å‚æ•°ç»„ç±»å‹ï¼ˆè–„èƒ¶/åšèƒ¶/CARï¼‰
            if any(k in params for k in ['acid_gen_efficiency', 'diffusion_length', 'reaction_rate']):
                # CARæ¨¡å‹å‚æ•°ç»„
                from backend.utils.helpers import validate_car_input
                is_valid, message = validate_car_input(params)
            elif any(k in params for k in ['z_h', 'I0', 'M0']):
                # åšèƒ¶æ¨¡å‹å‚æ•°ç»„
                from backend.utils.helpers import validate_enhanced_input
                is_valid, message = validate_enhanced_input(params)
            else:
                # è–„èƒ¶æ¨¡å‹å‚æ•°ç»„
                is_valid, message = validate_input(params)
                
            if not is_valid:
                return jsonify(format_response(False, message=f"å‚æ•°ç»„ {i+1}: {message}")), 400
        
        # ç”Ÿæˆæ¯”è¾ƒå›¾åƒ
        comparison_plots = generate_comparison_plots_with_enhanced(parameter_sets)
        
        # è¿”å›ç»“æœ
        return jsonify(format_response(True, data=comparison_plots)), 200
    
    except Exception as e:
        # è®°å½•å¼‚å¸¸å‚æ•°å’Œé”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
        with open('dill_backend.log', 'a', encoding='utf-8') as f:
            f.write(f"[{datetime.datetime.now()}]\n")
            f.write(f"è¯·æ±‚å‚æ•°: {data if 'data' in locals() else 'æ— '}\n")
            f.write(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}\n")
            f.write(f"å¼‚å¸¸ä¿¡æ¯: {str(e)}\n")
            f.write(f"å †æ ˆä¿¡æ¯: {traceback.format_exc()}\n\n")
        return jsonify(format_response(False, message=f"æ¯”è¾ƒè®¡ç®—é”™è¯¯: {str(e)}")), 500

@api_bp.route('/compare_data', methods=['POST'])
def compare_data():
    """
    æ¯”è¾ƒå¤šç»„å‚æ•°çš„è®¡ç®—ç»“æœï¼Œè¿”å›åŸå§‹æ•°æ®ï¼ˆç”¨äºäº¤äº’å¼å›¾è¡¨ï¼‰
    """
    try:
        data = request.get_json()
        if 'parameter_sets' not in data or not isinstance(data['parameter_sets'], list):
            return jsonify(format_response(False, message="ç¼ºå°‘parameter_setsæ•°ç»„")), 400
        if len(data['parameter_sets']) < 1:
            return jsonify(format_response(False, message="è‡³å°‘éœ€è¦ä¸€ç»„å‚æ•°")), 400
            
        parameter_sets = data['parameter_sets']
        x = np.linspace(0, 10, 1000).tolist()
        exposure_doses = []
        thicknesses = []
        
        # åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„æ¨¡å‹å®ä¾‹
        dill_model = None
        enhanced_model = None
        car_model = None
        
        for i, params in enumerate(parameter_sets):
            set_id = params.get('setId', str(i+1))
            custom_name = params.get('customName', f'å‚æ•°ç»„ {set_id}')
            
            # åˆ¤æ–­æ¨¡å‹ç±»å‹çš„é€»è¾‘
            model_type = params.get('model_type', 'dill')
            
            if model_type == 'enhanced_dill' or any(k in params for k in ['z_h', 'I0', 'M0']):
                # Enhanced Dillæ¨¡å‹
                if enhanced_model is None:
                    from ..models import EnhancedDillModel
                    enhanced_model = EnhancedDillModel()
                
                # è·å–Enhanced Dillå‚æ•°
                z_h = float(params.get('z_h', 10))  # èƒ¶åšåº¦
                T = float(params.get('T', 100))     # å‰çƒ˜æ¸©åº¦
                t_B = float(params.get('t_B', 10))  # å‰çƒ˜æ—¶é—´
                I0 = float(params.get('I0', 1.0))   # åˆå§‹å…‰å¼º
                M0 = float(params.get('M0', 1.0))   # åˆå§‹PACæµ“åº¦
                t_exp = float(params.get('t_exp', 5))  # æ›å…‰æ—¶é—´
                K = float(params.get('K', 2))       # ç©ºé—´é¢‘ç‡
                V = float(params.get('V', 0.8))     # å¹²æ¶‰æ¡çº¹å¯è§åº¦
                
                print(f"Enhanced Dill-1Dæ¨¡å‹å‚æ•° - å‚æ•°ç»„{set_id}: z_h={z_h}, T={T}, t_B={t_B}, I0={I0}, M0={M0}, t_exp={t_exp}, K={K}, V={V}")
                add_log_entry('info', 'enhanced_dill', f"å‚æ•°ç»„{set_id}: z_h={z_h}, T={T}, t_B={t_B}, I0={I0}, M0={M0}, t_exp={t_exp}, K={K}, V={V}")
                
                # ä½¿ç”¨çœŸæ­£çš„Enhanced Dillæ¨¡å‹PDEæ±‚è§£å™¨
                exposure_dose_data = []
                thickness_data = []
                
                print(f"[Enhanced Dill] å¼€å§‹è®¡ç®—1Dç©ºé—´åˆ†å¸ƒï¼Œå…±{len(x)}ä¸ªä½ç½®")
                add_log_entry('info', 'enhanced_dill', f"å¼€å§‹è®¡ç®—1Dç©ºé—´åˆ†å¸ƒï¼Œå…±{len(x)}ä¸ªä½ç½®")
                
                total_compute_time = 0
                successful_calcs = 0
                fallback_calcs = 0
                
                for i, pos in enumerate(x):
                    try:
                        # ä½¿ç”¨è‡ªé€‚åº”PDEæ±‚è§£å™¨ï¼Œè‡ªåŠ¨ä¼˜åŒ–è®¡ç®—æ•ˆç‡
                        z, I_final, M_final, exposure_dose_profile, compute_time = enhanced_model.adaptive_solve_enhanced_dill_pde(
                            z_h=z_h, T=T, t_B=t_B, I0=I0, M0=M0, t_exp=t_exp,
                            x_position=pos,   # ä¼ é€’xä½ç½®ç»™è¾¹ç•Œæ¡ä»¶
                            K=K, V=V, phi_expr=None,
                            max_points=150,   # æœ€å¤§ç½‘æ ¼ç‚¹æ•°
                            tolerance=1e-4    # æ”¶æ•›å®¹å·®
                        )
                        
                        # è®¡ç®—è¡¨é¢æ›å…‰å‰‚é‡å’Œåšåº¦
                        surface_exposure = exposure_dose_profile[0]
                        surface_thickness = M_final[0]
                        
                        exposure_dose_data.append(float(surface_exposure))
                        thickness_data.append(float(surface_thickness))
                        
                        total_compute_time += compute_time
                        successful_calcs += 1
                        
                        if i % 200 == 0:  # æ¯200ä¸ªç‚¹æ‰“å°ä¸€æ¬¡è¿›åº¦
                            avg_time = total_compute_time / successful_calcs if successful_calcs > 0 else 0
                            print(f"[Enhanced Dill] è¿›åº¦: {i+1}/{len(x)}, pos={pos:.3f}, exposure={surface_exposure:.3f}, thickness={surface_thickness:.4f}, å¹³å‡è®¡ç®—æ—¶é—´={avg_time:.4f}s")
                            add_log_entry('progress', 'enhanced_dill', f"è¿›åº¦: {i+1}/{len(x)}, pos={pos:.3f}, exposure={surface_exposure:.3f}, thickness={surface_thickness:.4f}, å¹³å‡è®¡ç®—æ—¶é—´={avg_time:.4f}s")
                            
                    except Exception as e:
                        print(f"[Enhanced Dill] ä½ç½®{pos}è®¡ç®—å‡ºé”™: {e}")
                        # ä½¿ç”¨å¤‡ç”¨ç®€åŒ–è®¡ç®—
                        try:
                            A_val, B_val, C_val = enhanced_model.get_abc(z_h, T, t_B)
                            local_I0 = I0 * (1 + V * np.cos(K * pos))
                            simple_exposure = local_I0 * t_exp
                            simple_thickness = np.exp(-C_val * simple_exposure)
                            exposure_dose_data.append(float(simple_exposure))
                            thickness_data.append(float(simple_thickness))
                            fallback_calcs += 1
                        except Exception as e2:
                            print(f"[Enhanced Dill] å¤‡ç”¨è®¡ç®—ä¹Ÿå¤±è´¥: {e2}")
                            # ä½¿ç”¨é»˜è®¤å€¼
                            exposure_dose_data.append(float(I0 * t_exp))
                            thickness_data.append(float(0.5))
                            fallback_calcs += 1
                
                # è®¡ç®—å’ŒæŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯
                avg_compute_time = total_compute_time / successful_calcs if successful_calcs > 0 else 0
                total_time = total_compute_time + fallback_calcs * 0.001  # ä¼°ç®—å¤‡ç”¨è®¡ç®—æ—¶é—´
                
                print(f"[Enhanced Dill] ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                add_log_entry('stats', 'enhanced_dill', f"ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                print(f"  âœ… æˆåŠŸè®¡ç®—: {successful_calcs}/{len(x)} ({successful_calcs/len(x)*100:.1f}%)")
                add_log_entry('stats', 'enhanced_dill', f"âœ… æˆåŠŸè®¡ç®—: {successful_calcs}/{len(x)} ({successful_calcs/len(x)*100:.1f}%)")
                print(f"  âš ï¸  å¤‡ç”¨è®¡ç®—: {fallback_calcs}/{len(x)} ({fallback_calcs/len(x)*100:.1f}%)")
                add_log_entry('stats', 'enhanced_dill', f"âš ï¸ å¤‡ç”¨è®¡ç®—: {fallback_calcs}/{len(x)} ({fallback_calcs/len(x)*100:.1f}%)")
                print(f"  â±ï¸  å¹³å‡è®¡ç®—æ—¶é—´: {avg_compute_time:.4f}s/ç‚¹")
                add_log_entry('stats', 'enhanced_dill', f"â±ï¸ å¹³å‡è®¡ç®—æ—¶é—´: {avg_compute_time:.4f}s/ç‚¹")
                print(f"  ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{min(exposure_dose_data):.3f}, {max(exposure_dose_data):.3f}] mJ/cmÂ²")
                add_log_entry('stats', 'enhanced_dill', f"ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{min(exposure_dose_data):.3f}, {max(exposure_dose_data):.3f}] mJ/cmÂ²")
                print(f"  ğŸ“ åšåº¦èŒƒå›´: [{min(thickness_data):.4f}, {max(thickness_data):.4f}] (å½’ä¸€åŒ–)")
                add_log_entry('stats', 'enhanced_dill', f"ğŸ“ åšåº¦èŒƒå›´: [{min(thickness_data):.4f}, {max(thickness_data):.4f}] (å½’ä¸€åŒ–)")
                print(f"  ğŸ’¾ æ•°æ®è´¨é‡: {'ä¼˜ç§€' if fallback_calcs/len(x) < 0.1 else 'è‰¯å¥½' if fallback_calcs/len(x) < 0.3 else 'éœ€è¦ä¼˜åŒ–'}")
                add_log_entry('stats', 'enhanced_dill', f"ğŸ’¾ æ•°æ®è´¨é‡: {'ä¼˜ç§€' if fallback_calcs/len(x) < 0.1 else 'è‰¯å¥½' if fallback_calcs/len(x) < 0.3 else 'éœ€è¦ä¼˜åŒ–'}")
                
                # æ£€æŸ¥æ•°æ®è´¨é‡
                if fallback_calcs > len(x) * 0.2:
                    print(f"  âš ï¸  è­¦å‘Š: è¶…è¿‡20%çš„è®¡ç®—ä½¿ç”¨äº†å¤‡ç”¨æ–¹æ³•ï¼Œå¯èƒ½å½±å“ç²¾åº¦")
                    
                # ç‰©ç†åˆç†æ€§æ£€æŸ¥
                exp_mean = np.mean(exposure_dose_data)
                exp_std = np.std(exposure_dose_data)
                thick_mean = np.mean(thickness_data)
                thick_std = np.std(thickness_data)
                
                print(f"  ğŸ“Š ç»Ÿè®¡ç‰¹å¾:")
                print(f"     æ›å…‰å‰‚é‡: å‡å€¼={exp_mean:.3f}, æ ‡å‡†å·®={exp_std:.3f}")
                print(f"     åšåº¦åˆ†å¸ƒ: å‡å€¼={thick_mean:.4f}, æ ‡å‡†å·®={thick_std:.4f}")
                
                if exp_std / exp_mean > 0.5:
                    print(f"  ğŸ“ˆ é«˜å¯¹æ¯”åº¦æ£€æµ‹: æ›å…‰å‰‚é‡å˜åŒ–æ˜¾è‘— (CV={exp_std/exp_mean:.3f})")
                if thick_std / thick_mean > 0.3:
                    print(f"  ğŸ­ å¼ºè°ƒåˆ¶æ£€æµ‹: åšåº¦å˜åŒ–æ˜¾è‘— (CV={thick_std/thick_mean:.3f})")
                
                # Enhanced Dillæ¨¡å‹ç‰¹æœ‰çš„åšèƒ¶åˆ†æ
                print(f"  ğŸ”¬ Enhanced Dillæ¨¡å‹åšèƒ¶åˆ†æ:")
                print(f"     èƒ¶åšz_h: {z_h:.1f} Î¼m")
                print(f"     å‰çƒ˜æ¸©åº¦T: {T:.0f} â„ƒ")
                print(f"     å‰çƒ˜æ—¶é—´t_B: {t_B:.0f} min")
                
                # ä¼°ç®—ABCå‚æ•°èŒƒå›´ï¼ˆåŸºäºå‚æ•°æ‹Ÿåˆå…¬å¼ï¼‰
                A_est = 0.1 + 0.01 * z_h + 0.001 * T
                B_est = 0.05 + 0.005 * z_h + 0.0005 * T
                C_est = 0.02 + 0.002 * z_h + 0.0001 * T
                print(f"     ä¼°ç®—ABCå‚æ•°: Aâ‰ˆ{A_est:.4f}, Bâ‰ˆ{B_est:.4f}, Câ‰ˆ{C_est:.4f}")
                
                # åšèƒ¶ç‰¹æ€§è¯„ä¼°
                thickness_factor = z_h / 10.0  # ä»¥10Î¼mä¸ºåŸºå‡†
                thermal_factor = (T - 100) / 50.0  # ä»¥100â„ƒä¸ºåŸºå‡†
                time_factor = t_B / 10.0  # ä»¥10minä¸ºåŸºå‡†
                
                print(f"     åšèƒ¶ç‰¹æ€§è¯„ä¼°:")
                if thickness_factor > 1.5:
                    print(f"       ğŸ“ è¶…åšèƒ¶å±‚({z_h}Î¼m): å…‰å¼ºè¡°å‡æ˜¾è‘—ï¼Œéœ€å¢å¼ºæ›å…‰")
                elif thickness_factor > 1.0:
                    print(f"       ğŸ“ åšèƒ¶å±‚({z_h}Î¼m): é€‚ä¸­çš„æ·±åº¦ç©¿é€æ€§")
                else:
                    print(f"       ğŸ“ è–„èƒ¶å±‚({z_h}Î¼m): å¯è€ƒè™‘ä½¿ç”¨æ ‡å‡†Dillæ¨¡å‹")
                
                if thermal_factor > 0.2:
                    print(f"       ğŸŒ¡ï¸  é«˜æ¸©å‰çƒ˜({T}â„ƒ): æœ‰åˆ©äºå…‰é…¸æ‰©æ•£")
                elif thermal_factor < -0.2:
                    print(f"       ğŸŒ¡ï¸  ä½æ¸©å‰çƒ˜({T}â„ƒ): æ‰©æ•£å—é™ï¼Œå¯¹æ¯”åº¦å¢å¼º")
                
                # å…‰å­¦ç©¿é€æ·±åº¦ä¼°ç®—
                penetration_depth = 1.0 / (A_est + B_est) if (A_est + B_est) > 0 else z_h
                print(f"     å…‰å­¦ç©¿é€æ·±åº¦: {penetration_depth:.2f} Î¼m")
                
                if penetration_depth < z_h * 0.5:
                    print(f"  âš ï¸  ç©¿é€ä¸è¶³: åº•éƒ¨å¯èƒ½æ›å…‰ä¸è¶³")
                elif penetration_depth > z_h * 1.5:
                    print(f"  âœ¨ ç©¿é€å……åˆ†: æ•´å±‚å…‰åˆ»èƒ¶å‡åŒ€æ›å…‰")

                print(f"[Enhanced Dill] ğŸ æ€»è®¡ç®—æ—¶é—´: {total_time:.3f}s")
                
                exposure_doses.append({
                    'data': exposure_dose_data,
                    'name': custom_name,
                    'setId': set_id
                })
                thicknesses.append({
                    'data': thickness_data,
                    'name': custom_name,
                    'setId': set_id
                })
                
            elif model_type == 'car' or any(k in params for k in ['acid_gen_efficiency', 'diffusion_length', 'reaction_rate']):
                # CARæ¨¡å‹
                if car_model is None:
                    from backend.models import CARModel
                    car_model = CARModel()
                
                I_avg = float(params.get('I_avg', 10))
                V = float(params.get('V', 0.8))
                K = float(params.get('K', 2.0))
                t_exp = float(params.get('t_exp', 5))
                acid_gen_efficiency = float(params.get('acid_gen_efficiency', 0.5))
                diffusion_length = float(params.get('diffusion_length', 3))
                reaction_rate = float(params.get('reaction_rate', 0.3))
                amplification = float(params.get('amplification', 10))
                contrast = float(params.get('contrast', 3))
                
                print(f"CAR-1Dæ¨¡å‹å‚æ•° - å‚æ•°ç»„{set_id}: I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp}")
                add_log_entry('info', 'car', f"å‚æ•°ç»„{set_id}: I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp}")
                print(f"CARå‚æ•°: acid_gen_eff={acid_gen_efficiency}, diff_len={diffusion_length}, reaction_rate={reaction_rate}, amp={amplification}, contrast={contrast}")
                add_log_entry('info', 'car', f"CARå‚æ•°: acid_gen_eff={acid_gen_efficiency}, diff_len={diffusion_length}, reaction_rate={reaction_rate}, amp={amplification}, contrast={contrast}")
                
                print(f"[CAR] å¼€å§‹è®¡ç®—1Dç©ºé—´åˆ†å¸ƒï¼Œå…±{len(x)}ä¸ªä½ç½®")
                add_log_entry('info', 'car', f"å¼€å§‹è®¡ç®—1Dç©ºé—´åˆ†å¸ƒï¼Œå…±{len(x)}ä¸ªä½ç½®")
                
                # ä½¿ç”¨CARæ¨¡å‹ç±»çš„è¯¦ç»†è®¡ç®—æ–¹æ³•
                print(f"[CAR] å¼€å§‹è°ƒç”¨CARæ¨¡å‹å®Œæ•´è®¡ç®—æµç¨‹ï¼Œå…±{len(x)}ä¸ªä½ç½®")
                add_log_entry('info', 'car', f"å¼€å§‹è°ƒç”¨CARæ¨¡å‹å®Œæ•´è®¡ç®—æµç¨‹ï¼Œå…±{len(x)}ä¸ªä½ç½®")
                
                import time
                start_time = time.time()
                
                # è°ƒç”¨CARæ¨¡å‹çš„è¯¦ç»†è®¡ç®—æ–¹æ³•ï¼Œè§¦å‘å®Œæ•´çš„æ—¥å¿—è®°å½•
                car_data = car_model.calculate_car_distribution(
                    x, I_avg, V, K, t_exp, acid_gen_efficiency, 
                    diffusion_length, reaction_rate, amplification, contrast
                )
                
                exposure_dose_data = car_data['exposure_dose'].tolist() if hasattr(car_data['exposure_dose'], 'tolist') else car_data['exposure_dose']
                thickness_data = car_data['thickness'].tolist() if hasattr(car_data['thickness'], 'tolist') else car_data['thickness']
                
                total_time = time.time() - start_time
                successful_calcs = len(exposure_dose_data)
                failed_calcs = 0
                avg_compute_time = total_time / len(x)
                
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                exp_mean = np.mean(exposure_dose_data)
                exp_std = np.std(exposure_dose_data)
                thick_mean = np.mean(thickness_data)
                thick_std = np.std(thickness_data)
                
                print(f"[CAR] ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                print(f"  âœ… æˆåŠŸè®¡ç®—: {successful_calcs}/{len(x)} ({successful_calcs/len(x)*100:.1f}%)")
                print(f"  âŒ å¤±è´¥è®¡ç®—: {failed_calcs}/{len(x)} ({failed_calcs/len(x)*100:.1f}%)")
                print(f"  â±ï¸  å¹³å‡è®¡ç®—æ—¶é—´: {avg_compute_time:.4f}s/ç‚¹")
                print(f"  ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{min(exposure_dose_data):.3f}, {max(exposure_dose_data):.3f}] mJ/cmÂ²")
                print(f"  ğŸ“ åšåº¦èŒƒå›´: [{min(thickness_data):.4f}, {max(thickness_data):.4f}] (å½’ä¸€åŒ–)")
                print(f"  ğŸ’¾ æ•°æ®è´¨é‡: {'ä¼˜ç§€' if failed_calcs/len(x) < 0.05 else 'è‰¯å¥½' if failed_calcs/len(x) < 0.1 else 'éœ€è¦ä¼˜åŒ–'}")
                
                print(f"  ğŸ“Š ç»Ÿè®¡ç‰¹å¾:")
                print(f"     æ›å…‰å‰‚é‡: å‡å€¼={exp_mean:.3f}, æ ‡å‡†å·®={exp_std:.3f}")
                print(f"     åšåº¦åˆ†å¸ƒ: å‡å€¼={thick_mean:.4f}, æ ‡å‡†å·®={thick_std:.4f}")
                
                if exp_std / exp_mean > 0.3:
                    print(f"  ğŸ“ˆ é«˜å¯¹æ¯”åº¦æ£€æµ‹: æ›å…‰å‰‚é‡å˜åŒ–æ˜¾è‘— (CV={exp_std/exp_mean:.3f})")
                if thick_std / thick_mean > 0.2:
                    print(f"  ğŸ­ å¼ºè°ƒåˆ¶æ£€æµ‹: åšåº¦å˜åŒ–æ˜¾è‘— (CV={thick_std/thick_mean:.3f})")
                
                # CARæ¨¡å‹ç‰¹æœ‰çš„åŒ–å­¦æ”¾å¤§åˆ†æ
                print(f"  ğŸ§ª CARæ¨¡å‹åŒ–å­¦æ”¾å¤§åˆ†æ:")
                print(f"     å…‰é…¸äº§ç”Ÿæ•ˆç‡Î·: {acid_gen_efficiency:.3f}")
                print(f"     æ‰©æ•£é•¿åº¦: {diffusion_length:.2f} nm")
                print(f"     ååº”é€Ÿç‡å¸¸æ•°k: {reaction_rate:.3f}")
                print(f"     æ”¾å¤§å› å­A: {amplification:.1f}x")
                print(f"     å¯¹æ¯”åº¦å› å­Î³: {contrast:.1f}")
                
                # åŒ–å­¦æ”¾å¤§æ•ˆèƒ½è¯„ä¼°
                chemical_amplification_factor = amplification * reaction_rate
                print(f"     åŒ–å­¦æ”¾å¤§æ•ˆèƒ½: {chemical_amplification_factor:.2f}")
                
                if chemical_amplification_factor > 3.0:
                    print(f"  ğŸš€ é«˜æ•ˆåŒ–å­¦æ”¾å¤§: æ”¾å¤§æ•ˆèƒ½ä¼˜ç§€ (>{chemical_amplification_factor:.1f})")
                elif chemical_amplification_factor > 1.5:
                    print(f"  âš¡ ä¸­ç­‰åŒ–å­¦æ”¾å¤§: æ”¾å¤§æ•ˆèƒ½è‰¯å¥½ ({chemical_amplification_factor:.1f})")
                else:
                    print(f"  âš ï¸  ä½æ•ˆåŒ–å­¦æ”¾å¤§: å»ºè®®è°ƒæ•´å‚æ•° ({chemical_amplification_factor:.1f})")
                    
                print(f"[CAR] ğŸ æ€»è®¡ç®—æ—¶é—´: {total_time:.3f}s")
                
                exposure_doses.append({
                    'data': exposure_dose_data,
                    'name': custom_name,
                    'setId': set_id
                })
                thicknesses.append({
                    'data': thickness_data,
                    'name': custom_name,
                    'setId': set_id
                })
                
            else:
                # Dillæ¨¡å‹
                if dill_model is None:
                    from backend.models import DillModel
                    dill_model = DillModel()
                
                I_avg = float(params.get('I_avg', 10))
                V = float(params.get('V', 0.8))
                K = float(params.get('K', 2.0))
                t_exp = float(params.get('t_exp', 5))
                C = float(params.get('C', 0.02))
                
                print(f"Dill-1Dæ¨¡å‹å‚æ•° - å‚æ•°ç»„{set_id}: I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp}, C={C}")
                add_log_entry('info', 'dill', f"å‚æ•°ç»„{set_id}: I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp}, C={C}")
                
                # ä½¿ç”¨è¯¦ç»†è¿›åº¦è®¡ç®—Dillæ¨¡å‹æ•°æ®
                print(f"[Dill] å¼€å§‹è®¡ç®—1Dç©ºé—´åˆ†å¸ƒï¼Œå…±{len(x)}ä¸ªä½ç½®")
                add_log_entry('info', 'dill', f"å¼€å§‹è®¡ç®—1Dç©ºé—´åˆ†å¸ƒï¼Œå…±{len(x)}ä¸ªä½ç½®")
                
                import time
                start_time = time.time()
                exposure_dose_data = []
                thickness_data = []
                
                successful_calcs = 0
                failed_calcs = 0
                
                for i, pos in enumerate(x):
                    try:
                        # è®¡ç®—å…‰å¼ºåˆ†å¸ƒ
                        intensity = I_avg * (1 + V * np.cos(K * pos))
                        
                        # è®¡ç®—æ›å…‰å‰‚é‡
                        exposure_dose = intensity * t_exp
                        
                        # è®¡ç®—å…‰åˆ»èƒ¶åšåº¦ï¼ˆDillæ¨¡å‹ï¼‰
                        # M(x,z) = e^(-C * D(x,z))
                        thickness = np.exp(-C * exposure_dose)
                        
                        exposure_dose_data.append(float(exposure_dose))
                        thickness_data.append(float(thickness))
                        successful_calcs += 1
                        
                        if i % 200 == 0:  # æ¯200ä¸ªç‚¹æ‰“å°ä¸€æ¬¡è¿›åº¦
                            elapsed_time = time.time() - start_time
                            avg_time = elapsed_time / (i + 1) if i > 0 else 0
                            print(f"[Dill] è¿›åº¦: {i+1}/{len(x)}, pos={pos:.3f}, exposure={exposure_dose:.3f}, thickness={thickness:.4f}, å¹³å‡æ—¶é—´={avg_time:.4f}s")
                            add_log_entry('progress', 'dill', f"è¿›åº¦: {i+1}/{len(x)}, pos={pos:.3f}, exposure={exposure_dose:.3f}, thickness={thickness:.4f}, å¹³å‡æ—¶é—´={avg_time:.4f}s")
                            
                    except Exception as e:
                        print(f"[Dill] ä½ç½®{pos}è®¡ç®—å‡ºé”™: {e}")
                        # ä½¿ç”¨é»˜è®¤å€¼
                        exposure_dose_data.append(float(I_avg * t_exp))
                        thickness_data.append(float(np.exp(-C * I_avg * t_exp)))
                        failed_calcs += 1
                
                total_time = time.time() - start_time
                avg_compute_time = total_time / len(x)
                
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                exp_mean = np.mean(exposure_dose_data)
                exp_std = np.std(exposure_dose_data)
                thick_mean = np.mean(thickness_data)
                thick_std = np.std(thickness_data)
                
                print(f"[Dill] ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                add_log_entry('stats', 'dill', f"ğŸ¯ è®¡ç®—å®Œæˆç»Ÿè®¡:")
                print(f"  âœ… æˆåŠŸè®¡ç®—: {successful_calcs}/{len(x)} ({successful_calcs/len(x)*100:.1f}%)")
                add_log_entry('stats', 'dill', f"âœ… æˆåŠŸè®¡ç®—: {successful_calcs}/{len(x)} ({successful_calcs/len(x)*100:.1f}%)")
                print(f"  âŒ å¤±è´¥è®¡ç®—: {failed_calcs}/{len(x)} ({failed_calcs/len(x)*100:.1f}%)")
                add_log_entry('stats', 'dill', f"âŒ å¤±è´¥è®¡ç®—: {failed_calcs}/{len(x)} ({failed_calcs/len(x)*100:.1f}%)")
                print(f"  â±ï¸  å¹³å‡è®¡ç®—æ—¶é—´: {avg_compute_time:.4f}s/ç‚¹")
                add_log_entry('stats', 'dill', f"â±ï¸ å¹³å‡è®¡ç®—æ—¶é—´: {avg_compute_time:.4f}s/ç‚¹")
                print(f"  ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{min(exposure_dose_data):.3f}, {max(exposure_dose_data):.3f}] mJ/cmÂ²")
                add_log_entry('stats', 'dill', f"ğŸ”¢ æ›å…‰å‰‚é‡èŒƒå›´: [{min(exposure_dose_data):.3f}, {max(exposure_dose_data):.3f}] mJ/cmÂ²")
                print(f"  ğŸ“ åšåº¦èŒƒå›´: [{min(thickness_data):.4f}, {max(thickness_data):.4f}] (å½’ä¸€åŒ–)")
                add_log_entry('stats', 'dill', f"ğŸ“ åšåº¦èŒƒå›´: [{min(thickness_data):.4f}, {max(thickness_data):.4f}] (å½’ä¸€åŒ–)")
                print(f"  ğŸ’¾ æ•°æ®è´¨é‡: {'ä¼˜ç§€' if failed_calcs/len(x) < 0.01 else 'è‰¯å¥½' if failed_calcs/len(x) < 0.05 else 'éœ€è¦ä¼˜åŒ–'}")
                add_log_entry('stats', 'dill', f"ğŸ’¾ æ•°æ®è´¨é‡: {'ä¼˜ç§€' if failed_calcs/len(x) < 0.01 else 'è‰¯å¥½' if failed_calcs/len(x) < 0.05 else 'éœ€è¦ä¼˜åŒ–'}")
                
                print(f"  ğŸ“Š ç»Ÿè®¡ç‰¹å¾:")
                print(f"     æ›å…‰å‰‚é‡: å‡å€¼={exp_mean:.3f}, æ ‡å‡†å·®={exp_std:.3f}")
                print(f"     åšåº¦åˆ†å¸ƒ: å‡å€¼={thick_mean:.4f}, æ ‡å‡†å·®={thick_std:.4f}")
                
                if exp_std / exp_mean > 0.2:
                    print(f"  ğŸ“ˆ é«˜å¯¹æ¯”åº¦æ£€æµ‹: æ›å…‰å‰‚é‡å˜åŒ–æ˜¾è‘— (CV={exp_std/exp_mean:.3f})")
                if thick_std / thick_mean > 0.1:
                    print(f"  ğŸ­ å¼ºè°ƒåˆ¶æ£€æµ‹: åšåº¦å˜åŒ–æ˜¾è‘— (CV={thick_std/thick_mean:.3f})")
                    
                # Dillæ¨¡å‹ç‰¹æœ‰çš„å‚æ•°åˆ†æ
                contrast_factor = exp_std / exp_mean if exp_mean > 0 else 0
                resolution_estimate = 1.0 / (K * V) if K > 0 and V > 0 else 0
                print(f"  ğŸ“ Dillæ¨¡å‹ç‰¹å¾åˆ†æ:")
                print(f"     å¯¹æ¯”åº¦å› å­: {contrast_factor:.3f}")
                print(f"     åˆ†è¾¨ç‡ä¼°è®¡: {resolution_estimate:.3f} Î¼m")
                print(f"     å…‰æ•é€Ÿç‡å¸¸æ•°C: {C:.4f} cmÂ²/mJ")
                
                print(f"[Dill] ğŸ æ€»è®¡ç®—æ—¶é—´: {total_time:.3f}s")
                
                exposure_doses.append({
                    'data': exposure_dose_data,
                    'name': custom_name,
                    'setId': set_id
                })
                thicknesses.append({
                    'data': thickness_data,
                    'name': custom_name,
                    'setId': set_id
                })
        
        result_data = {
            'x': x,
            'exposure_doses': exposure_doses,
            'thicknesses': thicknesses,
            'colors': ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'][:len(parameter_sets)]
        }
        
        return jsonify(format_response(True, data=result_data))
        
    except Exception as e:
        error_msg = f"æ¯”è¾ƒæ•°æ®è®¡ç®—é”™è¯¯: {str(e)}"
        print(f"Error: {error_msg}")
        import traceback
        traceback.print_exc()
        return jsonify(format_response(False, message=error_msg)), 500

def generate_comparison_plots_with_enhanced(parameter_sets):
    x = np.linspace(0, 10, 1000)
    fig1 = plt.figure(figsize=(12, 7))
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
    legend_labels = []
    
    # åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„æ¨¡å‹å®ä¾‹
    dill_model = None
    enhanced_model = None
    car_model = None
    
    # ç¬¬ä¸€ä¸ªå›¾ï¼šæ›å…‰å‰‚é‡åˆ†å¸ƒæ¯”è¾ƒ
    for i, params in enumerate(parameter_sets):
        if any(k in params for k in ['acid_gen_efficiency', 'diffusion_length', 'reaction_rate']):
            if car_model is None:
                from backend.models import CARModel
                car_model = CARModel()
            I_avg = float(params['I_avg'])
            V = float(params['V'])
            K = float(params.get('K', 2.0))
            t_exp = float(params['t_exp'])
            acid_gen_efficiency = float(params['acid_gen_efficiency'])
            diffusion_length = float(params['diffusion_length'])
            reaction_rate = float(params['reaction_rate'])
            amplification = float(params['amplification'])
            contrast = float(params['contrast'])
            car_data = car_model.generate_data(I_avg, V, K, t_exp, acid_gen_efficiency, diffusion_length, reaction_rate, amplification, contrast)
            exposure_dose = car_data['initial_acid']
            label = f"Set {i+1}: CARæ¨¡å‹ (K={K}, t_exp={t_exp}, acid_eff={acid_gen_efficiency})"
        elif any(k in params for k in ['z_h', 'I0', 'M0']):
            if enhanced_model is None:
                from ..models import EnhancedDillModel
                enhanced_model = EnhancedDillModel()
            z_h = float(params['z_h'])
            T = float(params['T'])
            t_B = float(params['t_B'])
            I0 = float(params.get('I0', 1.0))
            M0 = float(params.get('M0', 1.0))
            t_exp = float(params['t_exp'])
            K = float(params.get('K_enhanced', 2.0))
            V = float(params.get('V', 0.8))
            
            # è®¡ç®—è¡¨é¢ç©ºé—´åˆ†å¸ƒ
            exposure_dose_data = []
            
            for pos in x:
                local_I0 = I0 * (1 + V * np.cos(K * pos))
                enhanced_data = enhanced_model.generate_data(z_h, T, t_B, local_I0, M0, t_exp)
                
                # å–è¡¨é¢æ›å…‰å‰‚é‡
                if isinstance(enhanced_data['I'], (list, np.ndarray)) and len(enhanced_data['I']) > 0:
                    surface_I = enhanced_data['I'][0] if hasattr(enhanced_data['I'], '__getitem__') else enhanced_data['I']
                    exposure_dose_data.append(float(surface_I) * t_exp)
                else:
                    exposure_dose_data.append(float(enhanced_data['I']) * t_exp)
            
            exposure_dose = exposure_dose_data
            label = f"Set {i+1}: åšèƒ¶æ¨¡å‹ (z_h={z_h}, T={T}, t_B={t_B}, K={K})"
        else:
            # Dillæ¨¡å‹ - ä¿®æ­£ï¼šæ·»åŠ æ¨¡å‹åˆå§‹åŒ–
            if dill_model is None:
                from backend.models import DillModel
                dill_model = DillModel()
                
            I_avg = float(params['I_avg'])
            V = float(params['V'])
            K = float(params['K'])
            t_exp = float(params['t_exp'])
            intensity = dill_model.calculate_intensity_distribution(x, I_avg, V, K)
            exposure_dose = intensity * t_exp
            label = f"Set {i+1}: è–„èƒ¶æ¨¡å‹ (I_avg={I_avg}, V={V}, K={K}, t_exp={t_exp})"
        color = colors[i % len(colors)]
        plt.plot(x, exposure_dose, color=color, linewidth=2)
        legend_labels.append(label)
    plt.title('Exposure Dose Distribution Comparison', fontsize=16)
    plt.xlabel('Position (Î¼m)', fontsize=14)
    plt.ylabel('Exposure Dose (mJ/cmÂ²)', fontsize=14)
    plt.grid(True, alpha=0.3)
    plt.legend(legend_labels, loc='best', fontsize=10)
    plt.tight_layout()
    buffer1 = BytesIO()
    fig1.savefig(buffer1, format='png', dpi=100)
    buffer1.seek(0)
    exposure_comparison_plot = base64.b64encode(buffer1.getvalue()).decode()
    plt.close(fig1)
    
    # ç¬¬äºŒä¸ªå›¾ï¼šåšåº¦åˆ†å¸ƒæ¯”è¾ƒ
    fig2 = plt.figure(figsize=(12, 7))
    legend_labels = []
    for i, params in enumerate(parameter_sets):
        if any(k in params for k in ['acid_gen_efficiency', 'diffusion_length', 'reaction_rate']):
            if car_model is None:
                from backend.models import CARModel
                car_model = CARModel()
            I_avg = float(params['I_avg'])
            V = float(params['V'])
            K = float(params.get('K', 2.0))
            t_exp = float(params['t_exp'])
            acid_gen_efficiency = float(params['acid_gen_efficiency'])
            diffusion_length = float(params['diffusion_length'])
            reaction_rate = float(params['reaction_rate'])
            amplification = float(params['amplification'])
            contrast = float(params['contrast'])
            car_data = car_model.generate_data(I_avg, V, K, t_exp, acid_gen_efficiency, diffusion_length, reaction_rate, amplification, contrast)
            thickness = car_data['thickness']
            label = f"Set {i+1}: CARæ¨¡å‹ (K={K}, diffusion={diffusion_length}, contrast={contrast})"
        elif any(k in params for k in ['z_h', 'I0', 'M0']):
            if enhanced_model is None:
                from ..models import EnhancedDillModel
                enhanced_model = EnhancedDillModel()
            z_h = float(params['z_h'])
            T = float(params['T'])
            t_B = float(params['t_B'])
            I0 = float(params.get('I0', 1.0))
            M0 = float(params.get('M0', 1.0))
            t_exp = float(params['t_exp'])
            K = float(params.get('K_enhanced', 2.0))
            V = float(params.get('V', 0.8))
            
            # è®¡ç®—è¡¨é¢ç©ºé—´åˆ†å¸ƒ
            thickness_data = []
            
            for pos in x:
                local_I0 = I0 * (1 + V * np.cos(K * pos))
                enhanced_data = enhanced_model.generate_data(z_h, T, t_B, local_I0, M0, t_exp)
                
                # å–è¡¨é¢åšåº¦
                if isinstance(enhanced_data['M'], (list, np.ndarray)) and len(enhanced_data['M']) > 0:
                    surface_M = enhanced_data['M'][0] if hasattr(enhanced_data['M'], '__getitem__') else enhanced_data['M']
                    thickness_data.append(float(surface_M))
                else:
                    thickness_data.append(float(enhanced_data['M']))
            
            thickness = thickness_data
            label = f"Set {i+1}: åšèƒ¶æ¨¡å‹ (z_h={z_h}, T={T}, t_B={t_B}, t_exp={t_exp})"
        else:
            # Dillæ¨¡å‹ - ä¿®æ­£ï¼šæ·»åŠ æ¨¡å‹åˆå§‹åŒ–
            if dill_model is None:
                from backend.models import DillModel
                dill_model = DillModel()
                
            I_avg = float(params['I_avg'])
            V = float(params['V'])
            K = float(params['K'])
            t_exp = float(params['t_exp'])
            C = float(params['C'])
            intensity = dill_model.calculate_intensity_distribution(x, I_avg, V, K)
            exposure_dose = intensity * t_exp
            thickness = np.exp(-C * exposure_dose)
            label = f"Set {i+1}: è–„èƒ¶æ¨¡å‹ (I_avg={I_avg}, V={V}, K={K}, C={C})"
        color = colors[i % len(colors)]
        plt.plot(x, thickness, color=color, linewidth=2)
        legend_labels.append(label)
    plt.title('Photoresist Thickness Distribution Comparison', fontsize=16)
    plt.xlabel('Position (Î¼m)', fontsize=14)
    plt.ylabel('Relative Thickness', fontsize=14)
    plt.grid(True, alpha=0.3)
    plt.legend(legend_labels, loc='best', fontsize=10)
    plt.tight_layout()
    buffer2 = BytesIO()
    fig2.savefig(buffer2, format='png', dpi=100)
    buffer2.seek(0)
    thickness_comparison_plot = base64.b64encode(buffer2.getvalue()).decode()
    plt.close(fig2)
    return {'exposure_comparison_plot': exposure_comparison_plot, 'thickness_comparison_plot': thickness_comparison_plot, 'colors': colors}

@api_bp.route('/health', methods=['GET'])
def health_check():
    """
    APIå¥åº·æ£€æŸ¥ç«¯ç‚¹
    """
    return jsonify({"status": "healthy"}), 200 

@api_bp.route('/logs', methods=['GET'])
def get_logs():
    """è·å–ç³»ç»ŸåŒ–è®¡ç®—æ—¥å¿—"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        model_type = request.args.get('model_type')  # è¿‡æ»¤ç‰¹å®šæ¨¡å‹
        page = request.args.get('page', 'index')  # é¡µé¢ç±»å‹ï¼šindex æˆ– compare
        category = request.args.get('category', '')  # å­åˆ†ç±»ï¼š1d, 2d, 3d æˆ– dill, enhanced_dill, car
        log_type = request.args.get('type', '')  # æ—¥å¿—ç±»å‹ï¼šinfo, progress, success, warning, error
        limit = request.args.get('limit', 100)  # é»˜è®¤è¿”å›æœ€è¿‘100æ¡
        
        try:
            limit = int(limit)
        except:
            limit = 100
            
        # è¿‡æ»¤æ—¥å¿—
        filtered_logs = calculation_logs
        
        # æŒ‰æ¨¡å‹ç±»å‹è¿‡æ»¤
        if model_type:
            filtered_logs = [log for log in filtered_logs if log.get('model') == model_type]
        
        # æŒ‰é¡µé¢ç±»å‹è¿‡æ»¤
        if page == 'compare':
            # æ¯”è¾ƒé¡µé¢æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹çš„æ—¥å¿—
            pass
        else:
            # å•ä¸€è®¡ç®—é¡µé¢ï¼Œæ ¹æ®categoryè¿‡æ»¤
            if category and category in ['1d', '2d', '3d']:
                # æ ¹æ®æ¶ˆæ¯å†…å®¹æ¨æ–­ç»´åº¦
                dimension_keywords = {
                    '1d': ['1d', 'ä¸€ç»´', '1D'],
                    '2d': ['2d', 'äºŒç»´', '2D'],
                    '3d': ['3d', 'ä¸‰ç»´', '3D']
                }
                if category in dimension_keywords:
                    keywords = dimension_keywords[category]
                    filtered_logs = [
                        log for log in filtered_logs 
                        if any(keyword in log.get('message', '').lower() for keyword in [k.lower() for k in keywords])
                    ]
        
        # æŒ‰æ—¥å¿—ç±»å‹è¿‡æ»¤
        if log_type:
            filtered_logs = [log for log in filtered_logs if log.get('type') == log_type]
        
        # ä¸ºæ¯ä¸ªæ—¥å¿—æ·»åŠ IDå’Œå¢å¼ºä¿¡æ¯
        enhanced_logs = []
        for i, log in enumerate(filtered_logs):
            enhanced_log = {
                'id': f"{log.get('timestamp', '')}-{i}",
                'timestamp': log.get('timestamp'),
                'type': log.get('type', 'info'),
                'message': log.get('message', ''),
                'model': log.get('model', 'unknown'),
                'details': '',
                'category': detect_log_category(log, page),
                'subcategory': detect_log_subcategory(log, page),
                'dimension': detect_log_dimension(log)
            }
            enhanced_logs.append(enhanced_log)
        
        # è¿”å›æœ€è¿‘çš„Næ¡æ—¥å¿—ï¼ˆå€’åºï¼‰
        recent_logs = enhanced_logs[-limit:] if limit > 0 else enhanced_logs
        recent_logs.reverse()  # æœ€æ–°çš„åœ¨å‰é¢
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_logs': len(calculation_logs),
            'filtered_logs': len(filtered_logs),
            'error_count': len([log for log in filtered_logs if log.get('type') == 'error']),
            'warning_count': len([log for log in filtered_logs if log.get('type') == 'warning']),
            'progress': 'ç­‰å¾…è®¡ç®—...'
        }
        
        return jsonify(format_response(True, data={
            'logs': recent_logs,
            'stats': stats,
            'total_count': len(calculation_logs),
            'filtered_count': len(filtered_logs)
        }))
        
    except Exception as e:
        error_msg = f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        return jsonify(format_response(False, message=error_msg)), 500

def detect_log_category(log, page):
    """æ£€æµ‹æ—¥å¿—åˆ†ç±»"""
    if page == 'compare':
        return 'compare'
    return 'single'

def detect_log_subcategory(log, page):
    """æ£€æµ‹æ—¥å¿—å­åˆ†ç±»"""
    message = log.get('message', '').lower()
    model = log.get('model', '').lower()
    
    if page == 'compare':
        if 'dill' in model and 'enhanced' not in model:
            return 'dill'
        elif 'enhanced' in model or 'åšèƒ¶' in message:
            return 'enhanced_dill'
        elif 'car' in model:
            return 'car'
    else:
        if any(keyword in message for keyword in ['1d', 'ä¸€ç»´']):
            return '1d'
        elif any(keyword in message for keyword in ['2d', 'äºŒç»´']):
            return '2d'
        elif any(keyword in message for keyword in ['3d', 'ä¸‰ç»´']):
            return '3d'
    
    return 'unknown'

def detect_log_dimension(log):
    """æ£€æµ‹æ—¥å¿—ç»´åº¦"""
    message = log.get('message', '').lower()
    if '1d' in message or 'ä¸€ç»´' in message:
        return '1d'
    elif '2d' in message or 'äºŒç»´' in message:
        return '2d'
    elif '3d' in message or 'ä¸‰ç»´' in message:
        return '3d'
    return 'unknown'

@api_bp.route('/logs/clear', methods=['POST'])
def clear_calculation_logs():
    """æ¸…ç©ºè®¡ç®—æ—¥å¿—"""
    try:
        clear_logs()
        add_log_entry('info', 'system', 'æ—¥å¿—å·²æ¸…ç©º')
        return jsonify(format_response(True, message="æ—¥å¿—å·²æ¸…ç©º"))
    except Exception as e:
        error_msg = f"æ¸…ç©ºæ—¥å¿—å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        return jsonify(format_response(False, message=error_msg)), 500


# ===============================
# ç¤ºä¾‹æ–‡ä»¶ç®¡ç†APIæ¥å£
# ===============================

import os
import pathlib

# ç¤ºä¾‹æ–‡ä»¶æ ¹ç›®å½•è·¯å¾„ - æ”¯æŒå¤šç§éƒ¨ç½²ç¯å¢ƒ
def get_example_files_dir():
    """è·å–ç¤ºä¾‹æ–‡ä»¶ç›®å½•è·¯å¾„ï¼Œæ”¯æŒå¤šç§éƒ¨ç½²ç¯å¢ƒ"""
    current_file = os.path.abspath(__file__)
    
    # å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
    possible_paths = [
        # ç›¸å¯¹äºå½“å‰æ–‡ä»¶çš„è·¯å¾„ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file)))), 'test_data'),
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file)))), 'TEST_DATA'),
        
        # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼ˆéƒ¨ç½²ç¯å¢ƒï¼‰
        os.path.join(os.getcwd(), 'test_data'),
        os.path.join(os.getcwd(), 'TEST_DATA'),
        
        # RENDERç­‰äº‘å¹³å°éƒ¨ç½²ç¯å¢ƒ
        os.path.join('/opt/render/project/src', 'test_data'),
        os.path.join('/opt/render/project/src', 'TEST_DATA'),
        
        # Herokuç­‰éƒ¨ç½²ç¯å¢ƒ
        os.path.join('/app', 'test_data'),
        os.path.join('/app', 'TEST_DATA'),
        
        # é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šçš„è·¯å¾„
        os.path.join(os.environ.get('DILL_DATA_DIR', ''), 'test_data') if os.environ.get('DILL_DATA_DIR') else None,
        os.path.join(os.environ.get('DILL_DATA_DIR', ''), 'TEST_DATA') if os.environ.get('DILL_DATA_DIR') else None,
        
        # ç›¸å¯¹äºdill_modelç›®å½•
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(current_file))), '..', 'test_data'),
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(current_file))), '..', 'TEST_DATA'),
        
        # åœ¨åŒçº§ç›®å½•ä¸‹æŸ¥æ‰¾
        os.path.join(os.path.dirname(current_file), '..', '..', '..', '..', 'test_data'),
        os.path.join(os.path.dirname(current_file), '..', '..', '..', '..', 'TEST_DATA'),
        
        # å°è¯•æŸ¥æ‰¾å¸¸è§çš„éƒ¨ç½²ä½ç½®
        os.path.join('/var/www', 'test_data'),
        os.path.join('/var/www', 'TEST_DATA'),
        os.path.join('/home/app', 'test_data'),
        os.path.join('/home/app', 'TEST_DATA'),
    ]
    
    # è¿‡æ»¤æ‰Noneå€¼
    possible_paths = [path for path in possible_paths if path is not None]
    
    for path in possible_paths:
        abs_path = os.path.abspath(path)
        if os.path.exists(abs_path) and os.path.isdir(abs_path):
            print(f"Found example files directory: {abs_path}")
            return abs_path
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªè·¯å¾„å¹¶æ‰“å°è°ƒè¯•ä¿¡æ¯
    print(f"Warning: Could not find example files directory. Tried paths:")
    for i, path in enumerate(possible_paths):
        abs_path = os.path.abspath(path)
        print(f"  {i+1}. {abs_path} - {'EXISTS' if os.path.exists(abs_path) else 'NOT FOUND'}")
    
    return os.path.abspath(possible_paths[0])

EXAMPLE_FILES_DIR = get_example_files_dir()

@api_bp.route('/example-files', methods=['GET'])
def get_example_files():
    """è·å–ç¤ºä¾‹æ–‡ä»¶åˆ—è¡¨"""
    try:
        # é‡æ–°è·å–ç›®å½•è·¯å¾„ä»¥ç¡®ä¿æœ€æ–°
        example_dir = get_example_files_dir()
        
        if not os.path.exists(example_dir):
            error_msg = f"ç¤ºä¾‹æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {example_dir}"
            print(f"Error: {error_msg}")
            add_log_entry('error', 'system', error_msg)
            return jsonify(format_response(False, message=error_msg)), 404
        
        if not os.path.isdir(example_dir):
            error_msg = f"è·¯å¾„ä¸æ˜¯ç›®å½•: {example_dir}"
            print(f"Error: {error_msg}")
            add_log_entry('error', 'system', error_msg)
            return jsonify(format_response(False, message="æŒ‡å®šè·¯å¾„ä¸æ˜¯ç›®å½•")), 400
        
        files = []
        print(f"Scanning directory: {example_dir}")
        
        try:
            file_list = os.listdir(example_dir)
            print(f"Found {len(file_list)} items in directory")
        except PermissionError:
            error_msg = f"æ²¡æœ‰æƒé™è®¿é—®ç›®å½•: {example_dir}"
            print(f"Error: {error_msg}")
            add_log_entry('error', 'system', error_msg)
            return jsonify(format_response(False, message="æ²¡æœ‰æƒé™è®¿é—®ç¤ºä¾‹æ–‡ä»¶ç›®å½•")), 403
        
        for filename in file_list:
            if filename.startswith('.') or filename.lower() == 'readme.md':
                continue
                
            file_path = os.path.join(example_dir, filename)
            if os.path.isfile(file_path):
                try:
                    file_stat = os.stat(file_path)
                    file_ext = pathlib.Path(filename).suffix.lstrip('.')
                    
                    file_info = {
                        'name': filename,
                        'extension': file_ext,
                        'size': file_stat.st_size,
                        'modified': file_stat.st_mtime,
                        'description': get_file_description(filename, file_ext)
                    }
                    files.append(file_info)
                except (OSError, IOError) as e:
                    print(f"Error reading file {filename}: {e}")
                    continue
        
        # æŒ‰æ–‡ä»¶åæ’åº
        files.sort(key=lambda x: x['name'])
        
        print(f"Successfully found {len(files)} example files")
        add_log_entry('info', 'system', f'åŠ è½½äº† {len(files)} ä¸ªç¤ºä¾‹æ–‡ä»¶')
        
        return jsonify(format_response(True, data=files))
        
    except Exception as e:
        error_msg = f"è·å–ç¤ºä¾‹æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        return jsonify(format_response(False, message=error_msg)), 500

@api_bp.route('/example-files/<filename>', methods=['GET'])
def get_example_file_content(filename):
    """è·å–ç¤ºä¾‹æ–‡ä»¶å†…å®¹"""
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify(format_response(False, message="æ— æ•ˆçš„æ–‡ä»¶å")), 400
        
        example_dir = get_example_files_dir()
        file_path = os.path.join(example_dir, filename)
        
        if not os.path.exists(file_path) or not os.path.isfile(file_path):
            return jsonify(format_response(False, message="æ–‡ä»¶ä¸å­˜åœ¨")), 404
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            # å¦‚æœUTF-8è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
            except UnicodeDecodeError:
                with open(file_path, 'r', encoding='latin-1') as f:
                    content = f.read()
        
        file_stat = os.stat(file_path)
        file_ext = pathlib.Path(filename).suffix.lstrip('.')
        
        file_data = {
            'name': filename,
            'content': content,
            'size': file_stat.st_size,
            'format': file_ext.upper() if file_ext else 'æœªçŸ¥',
            'modified': file_stat.st_mtime,
            'description': get_file_description(filename, file_ext)
        }
        
        return jsonify(format_response(True, data=file_data))
        
    except Exception as e:
        error_msg = f"è¯»å–æ–‡ä»¶å†…å®¹å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        return jsonify(format_response(False, message=error_msg)), 500

@api_bp.route('/example-files/<filename>', methods=['PUT'])
def update_example_file_content(filename):
    """æ›´æ–°ç¤ºä¾‹æ–‡ä»¶å†…å®¹"""
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify(format_response(False, message="æ— æ•ˆçš„æ–‡ä»¶å")), 400
        
        example_dir = get_example_files_dir()
        file_path = os.path.join(example_dir, filename)
        
        if not os.path.exists(file_path) or not os.path.isfile(file_path):
            return jsonify(format_response(False, message="æ–‡ä»¶ä¸å­˜åœ¨")), 404
        
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'content' not in data:
            return jsonify(format_response(False, message="è¯·æ±‚æ•°æ®æ ¼å¼é”™è¯¯")), 400
        
        content = data['content']
        
        # å¤‡ä»½åŸæ–‡ä»¶
        backup_path = file_path + '.backup'
        try:
            import shutil
            shutil.copy2(file_path, backup_path)
        except Exception as backup_error:
            print(f"Warning: åˆ›å»ºå¤‡ä»½æ–‡ä»¶å¤±è´¥: {backup_error}")
        
        # å†™å…¥æ–°å†…å®¹
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # æ·»åŠ æ—¥å¿—
        add_log_entry('info', 'system', f'ç¤ºä¾‹æ–‡ä»¶å·²æ›´æ–°: {filename}')
        
        return jsonify(format_response(True, message="æ–‡ä»¶æ›´æ–°æˆåŠŸ"))
        
    except Exception as e:
        error_msg = f"æ›´æ–°æ–‡ä»¶å†…å®¹å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'system', f'æ›´æ–°ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {filename} - {error_msg}')
        return jsonify(format_response(False, message=error_msg)), 500

@api_bp.route('/example-files/<filename>', methods=['DELETE'])
def delete_example_file(filename):
    """åˆ é™¤ç¤ºä¾‹æ–‡ä»¶"""
    print(f"æ¥æ”¶åˆ°åˆ é™¤æ–‡ä»¶è¯·æ±‚: {filename}")
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify(format_response(False, message="æ— æ•ˆçš„æ–‡ä»¶å")), 400
        
        example_dir = get_example_files_dir()
        file_path = os.path.join(example_dir, filename)
        print(f"å°è¯•åˆ é™¤æ–‡ä»¶: {file_path}")
        
        if not os.path.exists(file_path) or not os.path.isfile(file_path):
            return jsonify(format_response(False, message="æ–‡ä»¶ä¸å­˜åœ¨")), 404
            
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            backup_dir = os.path.join(example_dir, '.deleted_backups')
            try:
                if not os.path.exists(backup_dir):
                    os.makedirs(backup_dir)
                    
                # å°†æ–‡ä»¶ç§»åŠ¨åˆ°å¤‡ä»½ç›®å½•ï¼Œæ–‡ä»¶ååŠ ä¸Šæ—¶é—´æˆ³
                import shutil
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                backup_filename = f"{filename}.{timestamp}.bak"
                backup_path = os.path.join(backup_dir, backup_filename)
                shutil.copy2(file_path, backup_path)
                print(f"å¤‡ä»½æ–‡ä»¶å·²åˆ›å»º: {backup_path}")
            except Exception as backup_error:
                print(f"Warning: åˆ›å»ºå¤‡ä»½å¤±è´¥: {str(backup_error)}ï¼Œå°†ç›´æ¥åˆ é™¤æ–‡ä»¶")
                
            # åˆ é™¤åŸæ–‡ä»¶ - å³ä½¿å¤‡ä»½å¤±è´¥ä¹Ÿè¦åˆ é™¤
            os.remove(file_path)
            print(f"æ–‡ä»¶å·²åˆ é™¤: {file_path}")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦ç¡®å®è¢«åˆ é™¤
            if not os.path.exists(file_path):
                # æ·»åŠ æ—¥å¿—
                add_log_entry('info', 'system', f'ç¤ºä¾‹æ–‡ä»¶å·²åˆ é™¤: {filename}')
                return jsonify(format_response(True, message="æ–‡ä»¶åˆ é™¤æˆåŠŸ"))
            else:
                error_msg = "æ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨"
                print(f"Error: {error_msg}")
                add_log_entry('error', 'system', error_msg)
                return jsonify(format_response(False, message=error_msg)), 500
            
        except Exception as e:
            error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}"
            print(f"Error: {error_msg}")
            add_log_entry('error', 'system', f'åˆ é™¤ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {filename} - {error_msg}')
            return jsonify(format_response(False, message=error_msg)), 500
            
    except Exception as e:
        error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'system', f'åˆ é™¤ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {filename} - {error_msg}')
        return jsonify(format_response(False, message=error_msg)), 500

@api_bp.route('/example-files/delete/<filename>', methods=['POST'])
def delete_example_file_by_post(filename):
    """ä½¿ç”¨POSTæ–¹æ³•åˆ é™¤ç¤ºä¾‹æ–‡ä»¶"""
    print(f"æ¥æ”¶åˆ°é€šè¿‡POSTåˆ é™¤æ–‡ä»¶è¯·æ±‚: {filename}")
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify(format_response(False, message="æ— æ•ˆçš„æ–‡ä»¶å")), 400
        
        example_dir = get_example_files_dir()
        file_path = os.path.join(example_dir, filename)
        print(f"å°è¯•åˆ é™¤æ–‡ä»¶: {file_path}")
        
        if not os.path.exists(file_path) or not os.path.isfile(file_path):
            return jsonify(format_response(False, message="æ–‡ä»¶ä¸å­˜åœ¨")), 404
            
        try:
            # ç›´æ¥åˆ é™¤æ–‡ä»¶ï¼Œä¸å†åˆ›å»ºå¤‡ä»½
            os.remove(file_path)
            print(f"æ–‡ä»¶å·²åˆ é™¤: {file_path}")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦ç¡®å®è¢«åˆ é™¤
            if not os.path.exists(file_path):
                # æ·»åŠ æ—¥å¿—
                add_log_entry('info', 'system', f'ç¤ºä¾‹æ–‡ä»¶å·²åˆ é™¤: {filename}')
                return jsonify(format_response(True, message="æ–‡ä»¶åˆ é™¤æˆåŠŸ"))
            else:
                error_msg = "æ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨"
                print(f"Error: {error_msg}")
                add_log_entry('error', 'system', error_msg)
                return jsonify(format_response(False, message=error_msg)), 500
            
        except Exception as e:
            error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}"
            print(f"Error: {error_msg}")
            add_log_entry('error', 'system', f'åˆ é™¤ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {filename} - {error_msg}')
            return jsonify(format_response(False, message=error_msg)), 500
            
    except Exception as e:
        error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'system', f'åˆ é™¤ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {filename} - {error_msg}')
        return jsonify(format_response(False, message=error_msg)), 500

@api_bp.route('/example-files', methods=['POST'])
def create_example_file():
    """åˆ›å»ºæ–°çš„ç¤ºä¾‹æ–‡ä»¶"""
    try:
        data = request.get_json()
        if not data or 'filename' not in data or 'content' not in data or 'type' not in data:
            return jsonify(format_response(False, message="è¯·æ±‚æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦filenameã€contentå’Œtypeå­—æ®µ")), 400
        
        filename = data['filename']
        content = data['content']
        file_type = data['type']  # æ–‡ä»¶ç±»å‹ï¼Œå¦‚'txt', 'json', 'asc'ç­‰
        
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify(format_response(False, message="æ— æ•ˆçš„æ–‡ä»¶å")), 400
        
        # ç¡®ä¿æ–‡ä»¶åæœ‰æ­£ç¡®çš„æ‰©å±•å
        if not filename.lower().endswith('.' + file_type.lower()):
            filename = f"{filename}.{file_type.lower()}"
        
        example_dir = get_example_files_dir()
        file_path = os.path.join(example_dir, filename)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(file_path):
            return jsonify(format_response(False, message="æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–æ–‡ä»¶å")), 409
        
        # å†™å…¥æ–°æ–‡ä»¶å†…å®¹
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_stat = os.stat(file_path)
        file_ext = pathlib.Path(filename).suffix.lstrip('.')
        
        file_data = {
            'name': filename,
            'extension': file_ext,
            'size': file_stat.st_size,
            'modified': file_stat.st_mtime,
            'description': get_file_description(filename, file_ext),
            'content': content
        }
        
        # æ·»åŠ æ—¥å¿—
        add_log_entry('info', 'system', f'æ–°çš„ç¤ºä¾‹æ–‡ä»¶å·²åˆ›å»º: {filename}')
        
        return jsonify(format_response(True, message="æ–‡ä»¶åˆ›å»ºæˆåŠŸ", data=file_data))
        
    except Exception as e:
        error_msg = f"åˆ›å»ºæ–°æ–‡ä»¶å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'system', f'åˆ›å»ºç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {error_msg}')
        return jsonify(format_response(False, message=error_msg)), 500

def get_file_description(filename, extension):
    """æ ¹æ®æ–‡ä»¶åå’Œæ‰©å±•åè·å–æ–‡ä»¶æè¿°"""
    descriptions = {
        'txt': 'æ–‡æœ¬æ ¼å¼æ•°æ®æ–‡ä»¶',
        'csv': 'é€—å·åˆ†éš”å€¼è¡¨æ ¼æ–‡ä»¶',
        'json': 'JSONæ ¼å¼æ•°æ®æ–‡ä»¶',
        'dat': 'æ•°æ®æ–‡ä»¶',
        'tab': 'åˆ¶è¡¨ç¬¦åˆ†éš”æ•°æ®æ–‡ä»¶',
        'xlsx': 'Excelè¡¨æ ¼æ–‡ä»¶',
        'xls': 'Excelè¡¨æ ¼æ–‡ä»¶',
        'mat': 'MATLABæ•°æ®æ–‡ä»¶',
        'pli': 'PROLITHæ ¼å¼æ–‡ä»¶',
        'ldf': 'Lithographyæ•°æ®æ–‡ä»¶',
        'msk': 'æ©æ¨¡æ–‡ä»¶',
        'int': 'å¼ºåº¦æ•°æ®æ–‡ä»¶',
        'pro': 'å·¥è‰ºå‚æ•°æ–‡ä»¶',
        'sim': 'ä»¿çœŸç»“æœæ–‡ä»¶',
        'asc': 'ASCIIæ ¼å¼æ–‡ä»¶',
        'log': 'æ—¥å¿—æ–‡ä»¶'
    }
    
    # ç‰¹æ®Šæ–‡ä»¶åæè¿°
    if 'gaussian' in filename.lower():
        return 'é«˜æ–¯åˆ†å¸ƒå…‰å¼ºç¤ºä¾‹'
    elif 'sinusoidal' in filename.lower():
        return 'æ­£å¼¦æ³¢å…‰å¼ºç¤ºä¾‹'
    elif 'speckle' in filename.lower():
        return 'æ–‘ç‚¹å›¾æ¡ˆå…‰å¼ºç¤ºä¾‹'
    elif 'complex' in filename.lower():
        return 'å¤æ‚å…‰å¼ºåˆ†å¸ƒç¤ºä¾‹'
    elif 'formula' in filename.lower():
        return 'å…¬å¼è®¡ç®—å…‰å¼ºç¤ºä¾‹'
    
    return descriptions.get(extension.lower(), 'ç¤ºä¾‹æ•°æ®æ–‡ä»¶')

@api_bp.route('/example-files/upload', methods=['POST'])
def upload_example_files():
    """ä¸Šä¼ æ–‡ä»¶åˆ°ç¤ºä¾‹æ–‡ä»¶ç›®å½•"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ 
        if 'files' not in request.files:
            return jsonify(format_response(False, message="æ²¡æœ‰é€‰æ‹©æ–‡ä»¶")), 400
        
        files = request.files.getlist('files')
        if not files or all(file.filename == '' for file in files):
            return jsonify(format_response(False, message="æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆæ–‡ä»¶")), 400
        
        example_dir = get_example_files_dir()
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(example_dir):
            os.makedirs(example_dir)
        
        uploaded_files = []
        failed_files = []
        
        for file in files:
            if file.filename == '':
                continue
                
            filename = file.filename
            
            # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
            if '..' in filename or '/' in filename or '\\' in filename:
                failed_files.append({'filename': filename, 'error': 'æ— æ•ˆçš„æ–‡ä»¶å'})
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            allowed_extensions = ['.txt', '.csv', '.json', '.dat', '.xls', '.xlsx', '.mat', '.pli', '.ldf', '.msk', '.int', '.pro', '.sim', '.tab', '.tsv', '.asc', '.lis', '.log', '.out', '.fdt', '.slf']
            file_ext = os.path.splitext(filename)[1].lower()
            if file_ext not in allowed_extensions:
                failed_files.append({'filename': filename, 'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}'})
                continue
            
            file_path = os.path.join(example_dir, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(file_path):
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                name, ext = os.path.splitext(filename)
                counter = 1
                while os.path.exists(file_path):
                    new_filename = f"{name}_{counter}{ext}"
                    file_path = os.path.join(example_dir, new_filename)
                    counter += 1
                filename = os.path.basename(file_path)
            
            try:
                # ä¿å­˜æ–‡ä»¶
                file.save(file_path)
                
                # è·å–æ–‡ä»¶ä¿¡æ¯
                file_size = os.path.getsize(file_path)
                file_ext = os.path.splitext(filename)[1][1:]  # å»æ‰ç‚¹
                
                uploaded_files.append({
                    'filename': filename,
                    'size': file_size,
                    'extension': file_ext,
                    'description': get_file_description(filename, file_ext)
                })
                
                # æ·»åŠ æ—¥å¿—
                add_log_entry('info', 'system', f'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {filename}')
                
            except Exception as e:
                failed_files.append({'filename': filename, 'error': f'ä¿å­˜å¤±è´¥: {str(e)}'})
                # æ·»åŠ é”™è¯¯æ—¥å¿—
                add_log_entry('error', 'system', f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {filename} - {str(e)}')
        
        # æ„å»ºå“åº”
        response_data = {
            'uploaded': uploaded_files,
            'failed': failed_files,
            'total_uploaded': len(uploaded_files),
            'total_failed': len(failed_files)
        }
        
        if uploaded_files:
            message = f"æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶"
            if failed_files:
                message += f"ï¼Œ{len(failed_files)} ä¸ªæ–‡ä»¶å¤±è´¥"
            return jsonify(format_response(True, message=message, data=response_data))
        else:
            return jsonify(format_response(False, message="æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å¤±è´¥", data=response_data)), 400
        
    except Exception as e:
        error_msg = f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'system', f'æ–‡ä»¶ä¸Šä¼ å¼‚å¸¸: {error_msg}')
        return jsonify(format_response(False, message=error_msg)), 500

@api_bp.route('/example-files/action', methods=['GET'])
def file_action():
    """é€šç”¨æ–‡ä»¶æ“ä½œç«¯ç‚¹ - ä½¿ç”¨GETæ–¹æ³•å’ŒæŸ¥è¯¢å‚æ•°"""
    try:
        action = request.args.get('action')
        filename = request.args.get('filename')
        
        if not action or not filename:
            return jsonify(format_response(False, message="ç¼ºå°‘å¿…è¦çš„å‚æ•°")), 400
        
        print(f"æ¥æ”¶åˆ°æ–‡ä»¶æ“ä½œè¯·æ±‚: action={action}, filename={filename}")
        
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify(format_response(False, message="æ— æ•ˆçš„æ–‡ä»¶å")), 400
        
        example_dir = get_example_files_dir()
        file_path = os.path.join(example_dir, filename)
        
        # åˆ é™¤æ–‡ä»¶æ“ä½œ
        if action == 'delete':
            if not os.path.exists(file_path) or not os.path.isfile(file_path):
                return jsonify(format_response(False, message="æ–‡ä»¶ä¸å­˜åœ¨")), 404
                
            try:
                # ç›´æ¥åˆ é™¤æ–‡ä»¶
                os.remove(file_path)
                print(f"æ–‡ä»¶å·²åˆ é™¤: {file_path}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦ç¡®å®è¢«åˆ é™¤
                if not os.path.exists(file_path):
                    add_log_entry('info', 'system', f'ç¤ºä¾‹æ–‡ä»¶å·²åˆ é™¤: {filename}')
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é€šè¿‡æµè§ˆå™¨ç›´æ¥è®¿é—®çš„ï¼ˆéAJAXè¯·æ±‚ï¼‰
                    is_ajax = request.headers.get('X-Requested-With') == 'XMLHttpRequest'
                    accepts_html = 'text/html' in request.headers.get('Accept', '')
                    
                    # å¦‚æœæ˜¯ç›´æ¥è®¿é—®ï¼Œè¿”å›HTMLé‡å®šå‘
                    if not is_ajax and accepts_html:
                        return """
                        <html>
                        <head>
                            <meta http-equiv="refresh" content="1;url=/">
                            <title>æ–‡ä»¶å·²åˆ é™¤</title>
                            <style>
                                body { font-family: Arial, sans-serif; text-align: center; margin-top: 50px; }
                                .message { padding: 20px; background-color: #d4edda; color: #155724; border-radius: 5px; }
                            </style>
                        </head>
                        <body>
                            <div class="message">æ–‡ä»¶ """ + filename + """ å·²æˆåŠŸåˆ é™¤ï¼æ­£åœ¨è¿”å›...</div>
                            <script>
                                setTimeout(function() {
                                    window.location.href = "/";
                                }, 1000);
                            </script>
                        </body>
                        </html>
                        """
                    
                    # å¯¹äºAJAXè¯·æ±‚è¿”å›JSONå“åº”
                    return jsonify(format_response(True, message="æ–‡ä»¶åˆ é™¤æˆåŠŸ"))
                else:
                    error_msg = "æ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨"
                    print(f"Error: {error_msg}")
                    add_log_entry('error', 'system', error_msg)
                    return jsonify(format_response(False, message=error_msg)), 500
                
            except Exception as e:
                error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}"
                print(f"Error: {error_msg}")
                add_log_entry('error', 'system', f'åˆ é™¤ç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {filename} - {error_msg}')
                return jsonify(format_response(False, message=error_msg)), 500
        else:
            return jsonify(format_response(False, message="ä¸æ”¯æŒçš„æ“ä½œç±»å‹")), 400
            
    except Exception as e:
        error_msg = f"æ–‡ä»¶æ“ä½œå¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'system', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


# === ç»“æœéªŒè¯ç›¸å…³API ===

@api_bp.route('/latest_calculation', methods=['GET'])
def get_latest_calculation():
    """è·å–æœ€è¿‘çš„è®¡ç®—ç»“æœï¼Œä¾›éªŒè¯é¡µé¢ä½¿ç”¨"""
    try:
        global latest_calculation_result
        
        if latest_calculation_result['timestamp'] is None:
            return jsonify(format_response(False, message="æš‚æ— è®¡ç®—ç»“æœï¼Œè¯·å…ˆåœ¨å•ä¸€è®¡ç®—é¡µé¢å®Œæˆè®¡ç®—")), 404
        
        # è¿”å›æœ€è¿‘çš„è®¡ç®—ç»“æœ
        result_data = {
            'timestamp': latest_calculation_result['timestamp'],
            'parameters': latest_calculation_result['parameters'],
            'results': latest_calculation_result['results'],
            'model_type': latest_calculation_result['model_type']
        }
        
        print(f"âœ… éªŒè¯é¡µé¢è¯·æ±‚æœ€è¿‘è®¡ç®—ç»“æœï¼Œæ¨¡å‹ç±»å‹: {result_data['model_type']}")
        return jsonify(format_response(True, data=result_data))
        
    except Exception as e:
        error_msg = f"è·å–æœ€è¿‘è®¡ç®—ç»“æœå¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/save_validation_data', methods=['POST'])
def save_validation_data():
    """ä¿å­˜éªŒè¯æ•°æ®åˆ°Excelæ–‡ä»¶"""
    try:
        # æ£€æŸ¥Excelæ”¯æŒ
        try:
            import openpyxl
        except ImportError:
            return jsonify(format_response(False, message="Excelæ”¯æŒåº“(openpyxl)æœªå®‰è£…ï¼Œæ— æ³•ä¿å­˜æ•°æ®ã€‚è¯·è¿è¡Œ: pip install openpyxl")), 500
            
        data = request.get_json()
        if not data:
            return jsonify(format_response(False, message="æ— æ•ˆçš„è¯·æ±‚æ•°æ®")), 400
        
        timestamp = data.get('timestamp')
        parameters = data.get('parameters', {})
        annotations = data.get('annotations', [])
        
        if not annotations:
            return jsonify(format_response(False, message="ç¼ºå°‘æ ‡æ³¨æ•°æ®")), 400
        
        # å¯¼å…¥Excelå¤„ç†åº“
        import pandas as pd
        import os
        
        # å®šä¹‰Excelæ–‡ä»¶è·¯å¾„
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        
        # å‡†å¤‡æ•°æ®è¡Œåˆ—è¡¨
        rows_data = []
        for annotation in annotations:
            row_data = {
                'timestamp': timestamp,
                'model_type': parameters.get('model_type', ''),
                'sine_type': parameters.get('sine_type', ''),
                'I_avg': parameters.get('I_avg', ''),
                'V': parameters.get('V', ''),
                'K': parameters.get('K', ''),
                't_exp': parameters.get('t_exp', ''),
                'acid_gen_efficiency': parameters.get('acid_gen_efficiency', ''),
                'diffusion_length': parameters.get('diffusion_length', ''),
                'reaction_rate': parameters.get('reaction_rate', ''),
                'amplification': parameters.get('amplification', ''),
                'contrast': parameters.get('contrast', ''),
                'Kx': parameters.get('Kx', ''),
                'Ky': parameters.get('Ky', ''),
                'Kz': parameters.get('Kz', ''),
                'phi_expr': parameters.get('phi_expr', ''),
                'exposure_calculation_method': parameters.get('exposure_calculation_method', ''),
                'annotation_x': annotation.get('x', ''),
                'annotation_y': annotation.get('y', ''),
                'simulated_value': annotation.get('simulatedValue', ''),
                'actual_value': annotation.get('actualValue', ''),
                'annotation_timestamp': annotation.get('timestamp', '')
            }
            rows_data.append(row_data)
        
        # è¯»å–æˆ–åˆ›å»ºExcelæ–‡ä»¶
        if os.path.exists(excel_file):
            try:
                df = pd.read_excel(excel_file)
                new_df = pd.DataFrame(rows_data)
                df = pd.concat([df, new_df], ignore_index=True)
            except Exception as e:
                print(f"è¯»å–ç°æœ‰Excelæ–‡ä»¶å¤±è´¥: {e}")
                df = pd.DataFrame(rows_data)
        else:
            df = pd.DataFrame(rows_data)
        
        # ä¿å­˜åˆ°Excelæ–‡ä»¶
        try:
            df.to_excel(excel_file, index=False)
            print(f"Excelæ–‡ä»¶ä¿å­˜æˆåŠŸ: {excel_file}")
            print(f"æ–‡ä»¶è·¯å¾„: {os.path.abspath(excel_file)}")
        except Exception as e:
            print(f"ä¿å­˜Excelæ–‡ä»¶å¤±è´¥: {e}")
            raise
        
        # è·å–æ€»è®°å½•æ•°
        total_records = len(df) if 'df' in locals() else 0
        
        add_log_entry('success', 'validation', f'ä¿å­˜éªŒè¯æ•°æ®æˆåŠŸï¼Œå…±{len(annotations)}ä¸ªæ ‡æ³¨ç‚¹')
        return jsonify(format_response(True, 
                                       message=f"éªŒè¯æ•°æ®ä¿å­˜æˆåŠŸ",
                                       data={'total_records': total_records}))
        
    except Exception as e:
        error_msg = f"ä¿å­˜éªŒè¯æ•°æ®å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/train_model', methods=['POST'])
def train_model():
    """è®­ç»ƒå‚æ•°é¢„æµ‹æ¨¡å‹ - æ”¯æŒè®­ç»ƒå‚æ•°é…ç½®"""
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json() or {}
        
        # æå–è®­ç»ƒå‚æ•°ï¼Œè®¾ç½®é»˜è®¤å€¼
        epochs = data.get('epochs', 100)
        test_size = data.get('test_size', 0.2)
        model_type = data.get('model_type', 'random_forest')
        enable_cross_validation = data.get('enable_cross_validation', True)
        
        print(f"ğŸ”§ æ”¶åˆ°è®­ç»ƒå‚æ•°: epochs={epochs}, test_size={test_size}, model_type={model_type}, cross_validation={enable_cross_validation}")
        
        # æ£€æŸ¥Excelæ”¯æŒ
        try:
            import openpyxl
        except ImportError:
            return jsonify(format_response(False, message="Excelæ”¯æŒåº“(openpyxl)æœªå®‰è£…ï¼Œæ— æ³•è¯»å–è®­ç»ƒæ•°æ®ã€‚è¯·è¿è¡Œ: pip install openpyxl")), 500
            
        import pandas as pd
        import os
        import numpy as np
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.linear_model import LinearRegression
        from sklearn.svm import SVR
        from sklearn.model_selection import train_test_split, cross_val_score
        from sklearn.metrics import mean_squared_error, r2_score
        import joblib
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        if not os.path.exists(excel_file):
            return jsonify(format_response(False, message="æ²¡æœ‰æ‰¾åˆ°éªŒè¯æ•°æ®æ–‡ä»¶")), 404
        
        # è¯»å–æ•°æ®
        df = pd.read_excel(excel_file)
        
        if len(df) < 5:
            return jsonify(format_response(False, message=f"æ•°æ®é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦5æ¡æ•°æ®ï¼Œå½“å‰ä»…æœ‰{len(df)}æ¡")), 400
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        # ç‰¹å¾ï¼šä½ç½®åæ ‡å’Œå®é™…æµ‹é‡å€¼
        feature_columns = ['annotation_x', 'annotation_y', 'actual_value']
        
        # æ ¹æ®æ•°æ®ä¸­çš„æ¨¡å‹ç±»å‹ç¡®å®šç›®æ ‡åˆ—
        # æ£€æŸ¥æ•°æ®ä¸­ä¸»è¦ä½¿ç”¨çš„æ¨¡å‹ç±»å‹
        model_types = df['model_type'].value_counts()
        primary_model = model_types.index[0] if not model_types.empty else 'dill'
        
        print(f"ğŸ” æ£€æµ‹åˆ°ä¸»è¦æ¨¡å‹ç±»å‹: {primary_model}")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ç›¸åº”çš„ç›®æ ‡åˆ—
        if 'car' in primary_model.lower():
            # CARæ¨¡å‹å‚æ•°
            target_columns = ['I_avg', 'V', 'K', 't_exp', 'acid_gen_efficiency', 
                             'diffusion_length', 'reaction_rate', 'amplification', 'contrast']
        else:
            # Dillæ¨¡å‹å‚æ•°ï¼ˆé»˜è®¤ï¼‰
            target_columns = ['I_avg', 'V', 'K', 't_exp']
        
        print(f"ğŸ¯ ä½¿ç”¨çš„ç›®æ ‡åˆ—: {target_columns}")
        
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        missing_feature_cols = [col for col in feature_columns if col not in df.columns]
        missing_target_cols = [col for col in target_columns if col not in df.columns]
        
        if missing_feature_cols:
            return jsonify(format_response(False, message=f"ç¼ºå°‘å¿…éœ€çš„ç‰¹å¾åˆ—: {missing_feature_cols}")), 400
        if missing_target_cols:
            return jsonify(format_response(False, message=f"ç¼ºå°‘å¿…éœ€çš„ç›®æ ‡åˆ—: {missing_target_cols}")), 400
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®ï¼ˆåªæ£€æŸ¥éç©ºçš„å¿…éœ€åˆ—ï¼‰
        valid_rows = df.dropna(subset=feature_columns + target_columns)
        
        print(f"ğŸ“Š åŸå§‹æ•°æ®é‡: {len(df)}, æœ‰æ•ˆæ•°æ®é‡: {len(valid_rows)}")
        
        if len(valid_rows) < 3:
            return jsonify(format_response(False, message=f"æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹ã€‚åŸå§‹æ•°æ®: {len(df)}æ¡ï¼Œæœ‰æ•ˆæ•°æ®: {len(valid_rows)}æ¡ï¼Œè‡³å°‘éœ€è¦3æ¡æœ‰æ•ˆæ•°æ®")), 400
        
        X = valid_rows[feature_columns].values
        y = valid_rows[target_columns].values
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•é›†
        if len(valid_rows) >= 10:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        elif len(valid_rows) >= 5:
            # å°æ•°æ®é›†ï¼šè‡³å°‘ä¿ç•™1ä¸ªæ ·æœ¬ä½œä¸ºæµ‹è¯•é›†
            test_samples = max(1, int(len(valid_rows) * test_size))
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_samples, random_state=42)
            print(f"âš ï¸  å°æ•°æ®é›†æ£€æµ‹ï¼Œå¼ºåˆ¶ä¿ç•™{test_samples}ä¸ªæµ‹è¯•æ ·æœ¬ä»¥é¿å…æ•°æ®æ³„éœ²")
        else:
            # æ•°æ®è¿‡å°‘ï¼Œä»…ä½¿ç”¨äº¤å‰éªŒè¯
            X_train, y_train = X, y
            X_test, y_test = X, y
            print(f"âš ï¸  æ•°æ®é‡è¿‡å°‘({len(valid_rows)}ä¸ª)ï¼Œå°†ä¸»è¦ä¾èµ–äº¤å‰éªŒè¯è¿›è¡Œè¯„ä¼°")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºæ¨¡å‹
        print(f"ğŸ“Š åˆ›å»º{model_type}æ¨¡å‹...")
        if model_type == 'random_forest':
            # éšæœºæ£®æ—ï¼šn_estimatorså¯ä»¥ä½œä¸ºepochsçš„æ›¿ä»£
            n_estimators = min(max(epochs, 10), 300)  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            model = RandomForestRegressor(
                n_estimators=n_estimators, 
                random_state=42, 
                max_depth=min(10, len(valid_rows) // 2),  # æ ¹æ®æ•°æ®é‡è°ƒæ•´æ·±åº¦
                min_samples_split=max(2, len(valid_rows) // 20)
            )
        elif model_type == 'linear_regression':
            model = LinearRegression()
        elif model_type == 'svm':
            model = SVR(kernel='rbf', C=1.0, gamma='scale')
        else:
            # é»˜è®¤ä½¿ç”¨éšæœºæ£®æ—
            model = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=5)
        
        print(f"ğŸ“ˆ å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒé›†å¤§å°: {X_train.shape}, æµ‹è¯•é›†å¤§å°: {X_test.shape}")
        
        # è®°å½•è®­ç»ƒè¿‡ç¨‹æ›²çº¿æ•°æ®
        training_curves = {'epochs': [], 'train_loss': [], 'val_loss': [], 'train_r2': [], 'val_r2': []}
        
        if model_type == 'random_forest':
            # å¯¹äºéšæœºæ£®æ—ï¼Œè®°å½•ä¸åŒæ ‘æ•°é‡ä¸‹çš„æ€§èƒ½
            n_estimators_total = min(max(epochs, 10), 300)
            step_size = max(1, n_estimators_total // 20)  # æœ€å¤šè®°å½•20ä¸ªç‚¹
            
            # ä¸ºå°æ•°æ®é›†ä¼˜åŒ–å‚æ•°
            max_depth = min(10, max(3, len(valid_rows) // 2)) if len(valid_rows) >= 5 else 3
            min_samples_split = max(2, len(valid_rows) // 10) if len(valid_rows) >= 10 else 2
            
            for n_trees in range(step_size, n_estimators_total + 1, step_size):
                # åˆ›å»ºä¸´æ—¶æ¨¡å‹
                temp_model = RandomForestRegressor(
                    n_estimators=n_trees,
                    random_state=42,
                    max_depth=max_depth,
                    min_samples_split=min_samples_split
                )
                temp_model.fit(X_train, y_train)
                
                # è®¡ç®—è®­ç»ƒå’ŒéªŒè¯æ€§èƒ½
                train_pred = temp_model.predict(X_train)
                val_pred = temp_model.predict(X_test)
                
                train_mse = mean_squared_error(y_train, train_pred)
                val_mse = mean_squared_error(y_test, val_pred)
                train_r2 = r2_score(y_train, train_pred)
                val_r2 = r2_score(y_test, val_pred)
                
                # å®‰å…¨å¤„ç†å¯èƒ½çš„NaNå€¼
                import math
                def safe_float_temp(value, default=0.0):
                    if value is None or math.isnan(value) or math.isinf(value):
                        return default
                    return float(value)
                
                training_curves['epochs'].append(n_trees)
                training_curves['train_loss'].append(safe_float_temp(train_mse))
                training_curves['val_loss'].append(safe_float_temp(val_mse))
                training_curves['train_r2'].append(safe_float_temp(train_r2))
                training_curves['val_r2'].append(safe_float_temp(val_r2))
                
                if n_trees % (step_size * 5) == 0:
                    print(f"   æ ‘æ•°é‡: {n_trees}, è®­ç»ƒMSE: {train_mse:.6f}, éªŒè¯MSE: {val_mse:.6f}, éªŒè¯RÂ²: {val_r2:.4f}")
            
            # ä½¿ç”¨æœ€ç»ˆæ¨¡å‹
            model.fit(X_train, y_train)
            
        elif model_type == 'linear_regression':
            # çº¿æ€§å›å½’æ²¡æœ‰è¿­ä»£è¿‡ç¨‹ï¼Œåˆ›å»ºå•ç‚¹æ•°æ®
            model.fit(X_train, y_train)
            train_pred = model.predict(X_train)
            val_pred = model.predict(X_test)
            
            train_mse = mean_squared_error(y_train, train_pred)
            val_mse = mean_squared_error(y_test, val_pred)
            train_r2 = r2_score(y_train, train_pred)
            val_r2 = r2_score(y_test, val_pred)
            
            # å®‰å…¨å¤„ç†å¯èƒ½çš„NaNå€¼
            import math
            def safe_float_lr(value, default=0.0):
                if value is None or math.isnan(value) or math.isinf(value):
                    return default
                return float(value)
            
            training_curves['epochs'] = [1]
            training_curves['train_loss'] = [safe_float_lr(train_mse)]
            training_curves['val_loss'] = [safe_float_lr(val_mse)]
            training_curves['train_r2'] = [safe_float_lr(train_r2)]
            training_curves['val_r2'] = [safe_float_lr(val_r2)]
            
        else:  # SVMæˆ–å…¶ä»–æ¨¡å‹
            # å¯¹äºSVMï¼Œæµ‹è¯•ä¸åŒçš„Cå€¼
            C_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0][:min(10, epochs // 10 + 3)]
            
            for i, C_val in enumerate(C_values):
                temp_model = SVR(kernel='rbf', C=C_val, gamma='scale')
                temp_model.fit(X_train, y_train)
                
                train_pred = temp_model.predict(X_train)
                val_pred = temp_model.predict(X_test)
                
                train_mse = mean_squared_error(y_train, train_pred)
                val_mse = mean_squared_error(y_test, val_pred)
                train_r2 = r2_score(y_train, train_pred)
                val_r2 = r2_score(y_test, val_pred)
                
                # å®‰å…¨å¤„ç†å¯èƒ½çš„NaNå€¼
                import math
                def safe_float_svm(value, default=0.0):
                    if value is None or math.isnan(value) or math.isinf(value):
                        return default
                    return float(value)
                
                training_curves['epochs'].append(i + 1)
                training_curves['train_loss'].append(safe_float_svm(train_mse))
                training_curves['val_loss'].append(safe_float_svm(val_mse))
                training_curves['train_r2'].append(safe_float_svm(train_r2))
                training_curves['val_r2'].append(safe_float_svm(val_r2))
            
            # ä½¿ç”¨æœ€ä½³Cå€¼é‡æ–°è®­ç»ƒ
            model.fit(X_train, y_train)
        
        # æœ€ç»ˆè¯„ä¼°
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # å¤„ç†å¯èƒ½çš„NaNå€¼
        import math
        def safe_float(value, default=0.0):
            """å®‰å…¨è½¬æ¢æµ®ç‚¹æ•°ï¼Œå¤„ç†NaNå’Œæ— é™å€¼"""
            if value is None or math.isnan(value) or math.isinf(value):
                return default
            return float(value)
        
        mse = safe_float(mse, 0.0)
        r2 = safe_float(r2, 0.0)
        
        print(f"ğŸ“Š è®­ç»ƒæ›²çº¿è®°å½•å®Œæˆï¼Œå…±{len(training_curves['epochs'])}ä¸ªæ•°æ®ç‚¹")
        
        # äº¤å‰éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        cv_scores = None
        cv_mean = None
        cv_std = None
        if enable_cross_validation and len(valid_rows) >= 5:
            print("ğŸ”„ æ‰§è¡Œäº¤å‰éªŒè¯...")
            cv_scores = cross_val_score(model, X, y, cv=min(5, len(valid_rows) // 2), scoring='r2')
            cv_mean = safe_float(cv_scores.mean(), 0.0)
            cv_std = safe_float(cv_scores.std(), 0.0)
            print(f"   äº¤å‰éªŒè¯ RÂ² åˆ†æ•°: {cv_mean:.4f} (+/- {cv_std * 2:.4f})")
        
        print(f"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:")
        print(f"   MSE: {mse:.6f}")
        print(f"   RÂ² åˆ†æ•°: {r2:.4f}")
        if cv_mean is not None:
            print(f"   äº¤å‰éªŒè¯ RÂ²: {cv_mean:.4f}")
        
        # å¦‚æœRÂ²ä¸ºè´Ÿæ•°æˆ–è¿‡ä½ï¼Œç»™å‡ºè­¦å‘Š
        if r2 < 0:
            print("âš ï¸  è­¦å‘Š: RÂ²åˆ†æ•°ä¸ºè´Ÿæ•°ï¼Œæ¨¡å‹å¯èƒ½è¡¨ç°ä¸ä½³")
        elif r2 < 0.3:
            print("âš ï¸  è­¦å‘Š: RÂ²åˆ†æ•°è¾ƒä½ï¼Œå»ºè®®å¢åŠ æ›´å¤šè®­ç»ƒæ•°æ®")
        
        # ä¿å­˜æ¨¡å‹å’Œç›®æ ‡åˆ—ä¿¡æ¯
        model_file = os.path.join(os.getcwd(), 'validation_model.pkl')
        model_info = {
            'model': model,
            'target_columns': target_columns,
            'feature_columns': feature_columns,
            'training_params': {
                'epochs': epochs,
                'test_size': test_size,
                'model_type': model_type,
                'enable_cross_validation': enable_cross_validation
            }
        }
        joblib.dump(model_info, model_file)
        
        # è®¡ç®—å‡†ç¡®ç‡ï¼ˆè¿™é‡Œç”¨RÂ²åˆ†æ•°ä½œä¸ºå‡†ç¡®ç‡æŒ‡æ ‡ï¼‰
        accuracy = max(0, r2)  # RÂ²å¯èƒ½ä¸ºè´Ÿæ•°ï¼Œè¿™é‡Œé™åˆ¶æœ€å°å€¼ä¸º0
        
        # ä½¿ç”¨äº¤å‰éªŒè¯ç»“æœä½œä¸ºæ›´å¯é çš„å‡†ç¡®ç‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        final_accuracy = cv_mean if cv_mean is not None and cv_mean > 0 else accuracy
        
        add_log_entry('success', 'validation', f'æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œç±»å‹: {model_type}, å‡†ç¡®ç‡: {final_accuracy:.3f}')
        
        # æ„å»ºè¿”å›æ•°æ®
        result_data = {
            'accuracy': final_accuracy,
            'mse': mse,
            'r2_score': r2,
            'training_samples': len(X_train),
            'test_samples': len(X_test),
            'model_type': model_type,
            'training_params': {
                'epochs': epochs,
                'test_size': test_size,
                'model_type': model_type,
                'enable_cross_validation': enable_cross_validation
            },
            'training_curves': training_curves  # æ·»åŠ è®­ç»ƒæ›²çº¿æ•°æ®
        }
        
        # æ·»åŠ äº¤å‰éªŒè¯ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if cv_mean is not None:
            # æ¸…ç†cv_scoresä¸­çš„NaNå€¼
            clean_cv_scores = [safe_float(score, 0.0) for score in cv_scores] if cv_scores is not None else []
            result_data.update({
                'cross_validation': {
                    'cv_mean': cv_mean,
                    'cv_std': cv_std,
                    'cv_scores': clean_cv_scores
                }
            })
        
        return jsonify(format_response(True, 
                                       message="æ¨¡å‹è®­ç»ƒå®Œæˆ",
                                       data=result_data))
        
    except Exception as e:
        error_msg = f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/predict_parameters', methods=['POST'])
def predict_parameters():
    """é¢„æµ‹æœ€ä¼˜å‚æ•° - æ”¯æŒé¢„æµ‹æ‰€æœ‰Dillæ¨¡å‹å‚æ•°"""
    try:
        data = request.get_json()
        if not data:
            return jsonify(format_response(False, message="æ— æ•ˆçš„è¯·æ±‚æ•°æ®")), 400
        
        # è·å–è¾“å…¥æ•°æ®
        x = data.get('x', 0)
        y = data.get('y', 0)
        target_thickness = data.get('target_thickness', 1.0)
        
        print(f"ğŸ¯ æ”¶åˆ°å‚æ•°é¢„æµ‹è¯·æ±‚: ä½ç½®({x}, {y}), ç›®æ ‡åšåº¦: {target_thickness}")
        
        import os
        import joblib
        import numpy as np
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_file = os.path.join(os.getcwd(), 'validation_model.pkl')
        if not os.path.exists(model_file):
            return jsonify(format_response(False, message="é¢„æµ‹æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")), 404
        
        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        model_info = joblib.load(model_file)
        
        # å…¼å®¹æ—§ç‰ˆæœ¬æ¨¡å‹æ–‡ä»¶
        if isinstance(model_info, dict) and 'model' in model_info:
            model = model_info['model']
            target_columns = model_info.get('target_columns', ['I_avg', 'V', 'K', 't_exp'])
            feature_columns = model_info.get('feature_columns', ['annotation_x', 'annotation_y', 'actual_value'])
        else:
            # æ—§ç‰ˆæœ¬æ¨¡å‹æ–‡ä»¶ï¼Œç›´æ¥æ˜¯æ¨¡å‹å¯¹è±¡
            model = model_info
            target_columns = ['I_avg', 'V', 'K', 't_exp']  # é»˜è®¤Dillå‚æ•°
            feature_columns = ['annotation_x', 'annotation_y', 'actual_value']
        
        print(f"ğŸ” åŠ è½½çš„æ¨¡å‹ç›®æ ‡åˆ—: {target_columns}")
        
        # å‡†å¤‡é¢„æµ‹æ•°æ®
        X_pred = np.array([[x, y, target_thickness]])
        
        # è¿›è¡Œé¢„æµ‹
        predictions = model.predict(X_pred)[0]
        
        print(f"ğŸ“Š é¢„æµ‹ç»“æœ: {predictions}")
        
        # å®šä¹‰å®‰å…¨æµ®ç‚¹æ•°è½¬æ¢å‡½æ•°
        import math
        def safe_float_predict(value, default=0.0):
            """å®‰å…¨è½¬æ¢æµ®ç‚¹æ•°ï¼Œå¤„ç†NaNå’Œæ— é™å€¼"""
            if value is None or math.isnan(value) or math.isinf(value):
                return default
            return float(value)
        
        # æ„å»ºåŸºç¡€é¢„æµ‹å‚æ•°ï¼ˆæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹çš„å‚æ•°ï¼‰
        ml_predicted_params = {}
        for i, param_name in enumerate(target_columns):
            if i < len(predictions):
                ml_predicted_params[param_name] = safe_float_predict(float(predictions[i]), 0.0)
        
        # æ ¹æ®é¢„æµ‹çš„åŸºç¡€å‚æ•°ï¼Œæ¨å¯¼å‡ºå®Œæ•´çš„Dillæ¨¡å‹å‚æ•°é›†
        def derive_complete_dill_parameters(ml_params, target_thickness):
            """æ ¹æ®æœºå™¨å­¦ä¹ é¢„æµ‹çš„åŸºç¡€å‚æ•°ï¼Œæ¨å¯¼å‡ºå®Œæ•´çš„Dillæ¨¡å‹å‚æ•°é›†"""
            import math
            
            # è·å–åŸºç¡€é¢„æµ‹å‚æ•°
            I_avg = ml_params.get('I_avg', 0.5)
            V = ml_params.get('V', 0.8)
            K = ml_params.get('K', 0.1)
            t_exp = ml_params.get('t_exp', 100.0)
            C = ml_params.get('C', 0.022)
            
            # æ¨å¯¼å…¶ä»–ç›¸å…³å‚æ•°
            # åŸºäºDillæ¨¡å‹çš„ç‰©ç†å…³ç³»æ¨å¯¼
            angle_a = 11.7  # æ ‡å‡†è¡å°„è§’åº¦
            wavelength = 405.0  # æ ‡å‡†æ³¢é•¿ (nm)
            
            # æ ¹æ®ç©ºé—´é¢‘ç‡Kæ¨å¯¼ç‰©ç†å‚æ•°
            # K = 4Ï€ sin(Î¸) / Î»
            if K > 0:
                sin_theta = K * wavelength / (4 * math.pi)
                sin_theta = min(abs(sin_theta), 1.0)  # é™åˆ¶åœ¨ç‰©ç†èŒƒå›´å†…
                theta_rad = math.asin(sin_theta)
                angle_a = math.degrees(theta_rad)
            
            # æ ¹æ®ç›®æ ‡åšåº¦è°ƒæ•´æ›å…‰å‚æ•°
            exposure_threshold = 20.0
            if target_thickness < 0.5:
                exposure_threshold = 15.0
            elif target_thickness > 1.5:
                exposure_threshold = 25.0
            
            # æ„å»ºå®Œæ•´å‚æ•°å­—å…¸
            complete_params = {
                # å…‰å­¦å‚æ•°
                'I_avg': round(I_avg, 3),
                'V': round(V, 3),
                'K': round(K, 3),
                'wavelength': wavelength,
                'angle_a': round(angle_a, 3),
                
                # æ›å…‰å‚æ•°
                't_exp': round(t_exp, 3),
                'C': round(C, 4),
                'exposure_threshold': round(exposure_threshold, 1),
                
                # æ¨å¯¼å‚æ•°
                'target_thickness': round(target_thickness, 3),
                'contrast_ratio': round(V * 100, 1),  # å¯¹æ¯”åº¦ç™¾åˆ†æ¯”
                'spatial_frequency': round(K, 3),
                'exposure_dose': round(I_avg * t_exp, 1),  # æ€»æ›å…‰å‰‚é‡
                
                # è®¡ç®—æ¨¡å¼å‚æ•°
                'sine_type': '1Dæ›å…‰å›¾æ¡ˆ',
                'model_type': 'Dillæ¨¡å‹',
                'optimization_method': 'æœºå™¨å­¦ä¹ é¢„æµ‹'
            }
            
            return complete_params
        
        complete_params = derive_complete_dill_parameters(ml_predicted_params, target_thickness)
        
        print(f"ğŸ¯ æœºå™¨å­¦ä¹ é¢„æµ‹å‚æ•°: {ml_predicted_params}")
        print(f"ğŸ¯ å®Œæ•´æ¨å¯¼å‚æ•°: {complete_params}")
        
        add_log_entry('info', 'validation', f'å‚æ•°é¢„æµ‹å®Œæˆï¼Œç›®æ ‡ä½ç½®: ({x}, {y}), ç›®æ ‡åšåº¦: {target_thickness}')
        return jsonify(format_response(True, 
                                       message="å‚æ•°é¢„æµ‹å®Œæˆ",
                                       data={
                                           'predicted_parameters': complete_params,
                                           'ml_predictions': ml_predicted_params,
                                           'target_position': {'x': x, 'y': y},
                                           'target_thickness': target_thickness
                                       }))
        
    except Exception as e:
        error_msg = f"å‚æ•°é¢„æµ‹å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/validation_stats', methods=['GET'])
def get_validation_stats():
    """è·å–éªŒè¯æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # æ£€æŸ¥Excelæ”¯æŒï¼ˆå¦‚æœæ–‡ä»¶å­˜åœ¨çš„è¯ï¼‰
        try:
            import openpyxl
        except ImportError:
            # å¯¹äºç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚æœExcelåº“ä¸å­˜åœ¨ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯å³å¯
            return jsonify(format_response(True, data={
                'data_file_exists': False,
                'model_file_exists': False,
                'total_records': 0,
                'unique_sessions': 0,
                'excel_support': False,
                'message': 'Excelæ”¯æŒåº“(openpyxl)æœªå®‰è£…'
            }))
            
        import pandas as pd
        import os
        
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        model_file = os.path.join(os.getcwd(), 'validation_model.pkl')
        
        stats = {
            'data_file_exists': os.path.exists(excel_file),
            'model_file_exists': os.path.exists(model_file),
            'total_records': 0,
            'unique_sessions': 0
        }
        
        if stats['data_file_exists']:
            df = pd.read_excel(excel_file)
            stats['total_records'] = len(df)
            stats['unique_sessions'] = df['timestamp'].nunique() if 'timestamp' in df.columns else 0
        
        return jsonify(format_response(True, data=stats))
        
    except Exception as e:
        error_msg = f"è·å–éªŒè¯ç»Ÿè®¡å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/get_validation_records', methods=['GET'])
def get_validation_records():
    """è·å–Excelæ–‡ä»¶ä¸­çš„éªŒè¯è®°å½•"""
    try:
        # æ£€æŸ¥Excelæ”¯æŒ
        try:
            import openpyxl
        except ImportError:
            return jsonify(format_response(False, message="Excelæ”¯æŒåº“(openpyxl)æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openpyxl")), 500
            
        import pandas as pd
        import os
        
        # è·å–è¯·æ±‚å‚æ•°
        page = request.args.get('page', 1, type=int)
        page_size = request.args.get('page_size', 50, type=int)
        search_term = request.args.get('search', '', type=str)
        sort_by = request.args.get('sort_by', 'timestamp', type=str)
        sort_order = request.args.get('sort_order', 'desc', type=str)
        
        # æ£€æŸ¥Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        if not os.path.exists(excel_file):
            return jsonify(format_response(False, message="éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡Œä¸€äº›éªŒè¯æ“ä½œ")), 404
        
        # è¯»å–Excelæ•°æ®
        df = pd.read_excel(excel_file)
        
        if df.empty:
            return jsonify(format_response(True, data={
                'records': [],
                'total_count': 0,
                'page': page,
                'page_size': page_size,
                'total_pages': 0,
                'statistics': {
                    'total_records': 0,
                    'avg_accuracy': 0,
                    'model_types': [],
                    'date_range': None
                }
            }))
        
        # æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
        df = df.fillna('')  # å¡«å……ç©ºå€¼
        
        # å¦‚æœæœ‰æœç´¢æ¡ä»¶ï¼Œè¿›è¡Œè¿‡æ»¤
        if search_term:
            search_cols = ['model_type', 'x_coord', 'simulated_value', 'actual_value']
            search_condition = False
            for col in search_cols:
                if col in df.columns:
                    search_condition |= df[col].astype(str).str.contains(search_term, case=False, na=False)
            df = df[search_condition]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_count = len(df)
        
        # æ’åº
        if sort_by in df.columns:
            ascending = (sort_order == 'asc')
            df = df.sort_values(by=sort_by, ascending=ascending)
        
        # åˆ†é¡µ
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        paginated_df = df.iloc[start_idx:end_idx]
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        records = []
        for index, row in paginated_df.iterrows():
            record = {}
            for col in df.columns:
                value = row[col]
                # å¤„ç†NaNå’Œç‰¹æ®Šæ•°å€¼
                if pd.isna(value):
                    record[col] = ''
                elif isinstance(value, (int, float)):
                    if pd.isna(value):
                        record[col] = ''
                    else:
                        record[col] = float(value) if value != int(value) else int(value)
                else:
                    record[col] = str(value)
            records.append(record)
        
        # è®¡ç®—æ€»é¡µæ•°
        total_pages = (total_count + page_size - 1) // page_size
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        statistics = {}
        if total_count > 0:
            # åŸºæœ¬ç»Ÿè®¡
            statistics['total_records'] = total_count
            
            # å‡†ç¡®æ€§ç»Ÿè®¡
            if 'simulated_value' in df.columns and 'actual_value' in df.columns:
                sim_vals = pd.to_numeric(df['simulated_value'], errors='coerce').dropna()
                act_vals = pd.to_numeric(df['actual_value'], errors='coerce').dropna()
                if len(sim_vals) > 0 and len(act_vals) > 0:
                    # è®¡ç®—å¹³å‡ç›¸å¯¹è¯¯å·®
                    relative_errors = abs((sim_vals - act_vals) / act_vals) * 100
                    avg_accuracy = max(0, 100 - relative_errors.mean())
                    statistics['avg_accuracy'] = round(avg_accuracy, 2)
                    statistics['avg_error'] = round(relative_errors.mean(), 2)
                    statistics['max_error'] = round(relative_errors.max(), 2)
                    statistics['min_error'] = round(relative_errors.min(), 2)
                else:
                    statistics['avg_accuracy'] = 0
                    statistics['avg_error'] = 0
                    statistics['max_error'] = 0
                    statistics['min_error'] = 0
            
            # æ¨¡å‹ç±»å‹ç»Ÿè®¡
            if 'model_type' in df.columns:
                model_counts = df['model_type'].value_counts().to_dict()
                statistics['model_types'] = [{'type': k, 'count': v} for k, v in model_counts.items()]
            
            # æ—¥æœŸèŒƒå›´ç»Ÿè®¡
            if 'timestamp' in df.columns:
                timestamps = pd.to_datetime(df['timestamp'], errors='coerce').dropna()
                if len(timestamps) > 0:
                    statistics['date_range'] = {
                        'earliest': timestamps.min().strftime('%Y-%m-%d %H:%M:%S'),
                        'latest': timestamps.max().strftime('%Y-%m-%d %H:%M:%S')
                    }
        
        result_data = {
            'records': records,
            'total_count': total_count,
            'page': page,
            'page_size': page_size,
            'total_pages': total_pages,
            'statistics': statistics,
            'columns': list(df.columns)
        }
        
        add_log_entry('info', 'validation', f"æˆåŠŸè·å–éªŒè¯è®°å½•ï¼Œå…±{total_count}æ¡è®°å½•ï¼Œç¬¬{page}é¡µ")
        return jsonify(format_response(True, data=result_data))
        
    except Exception as e:
        error_msg = f"è·å–éªŒè¯è®°å½•å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        print(f"Traceback: {traceback.format_exc()}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/delete_validation_record', methods=['POST'])
def delete_validation_record():
    """åˆ é™¤æŒ‡å®šçš„éªŒè¯è®°å½•"""
    try:
        # æ£€æŸ¥Excelæ”¯æŒ
        try:
            import openpyxl
        except ImportError:
            return jsonify(format_response(False, message="Excelæ”¯æŒåº“(openpyxl)æœªå®‰è£…ï¼Œæ— æ³•åˆ é™¤è®°å½•ã€‚è¯·è¿è¡Œ: pip install openpyxl")), 500
            
        import pandas as pd
        import os
        
        data = request.get_json()
        if not data or 'record_index' not in data:
            return jsonify(format_response(False, message="ç¼ºå°‘è®°å½•ç´¢å¼•å‚æ•°")), 400
        
        record_index = data['record_index']
        
        # æ£€æŸ¥Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        if not os.path.exists(excel_file):
            return jsonify(format_response(False, message="éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")), 404
        
        # è¯»å–Excelæ•°æ®
        df = pd.read_excel(excel_file)
        
        if df.empty or record_index < 0 or record_index >= len(df):
            return jsonify(format_response(False, message="æ— æ•ˆçš„è®°å½•ç´¢å¼•")), 400
        
        # åˆ é™¤æŒ‡å®šè¡Œ
        df = df.drop(df.index[record_index])
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        df.to_excel(excel_file, index=False)
        
        add_log_entry('info', 'validation', f"æˆåŠŸåˆ é™¤ç¬¬{record_index}æ¡éªŒè¯è®°å½•")
        return jsonify(format_response(True, message=f"æˆåŠŸåˆ é™¤è®°å½•ï¼Œå‰©ä½™{len(df)}æ¡è®°å½•"))
        
    except Exception as e:
        error_msg = f"åˆ é™¤éªŒè¯è®°å½•å¤±è´¥: {str(e)}"
        print(f"Error: {error_msg}")
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


@api_bp.route('/smart_optimize_exposure', methods=['POST'])
def smart_optimize_exposure():
    """åŸºäºéªŒè¯æ•°æ®çš„æ™ºèƒ½ä¼˜åŒ–æ›å…‰æ—¶é—´ç®—æ³•"""
    try:
        print("ğŸ”§ æ”¶åˆ°åŸºäºéªŒè¯æ•°æ®çš„æ™ºèƒ½ä¼˜åŒ–è¯·æ±‚")
        
        data = request.get_json()
        print(f"ğŸ“¥ è¯·æ±‚æ•°æ®: {data}")
        
        if not data:
            error_msg = "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"
            print(f"âŒ {error_msg}")
            return jsonify(format_response(False, message=error_msg)), 400
        
        # è·å–è¾“å…¥å‚æ•°
        try:
            target_x = float(data.get('target_x', 0))
            target_y = float(data.get('target_y', 0))
            target_thickness = float(data.get('target_thickness', 1.0))
            selected_record_indices = data.get('selected_records', [])  # ç”¨æˆ·é€‰æ‹©çš„éªŒè¯è®°å½•ç´¢å¼•
            optimization_type = data.get('optimization_type', 'quick')  # 'quick' æˆ– 'custom'
            
            # è‡ªå®šä¹‰å‚æ•°
            custom_params = {
                'sensitivity': float(data.get('sensitivity', 2.0)),
                'confidence_threshold': float(data.get('confidence_threshold', 0.5)),
                'strategy_count': int(data.get('strategy_count', 3))
            }
            
            print(f"ğŸ“Š è§£æå‚æ•°: target_x={target_x}, target_y={target_y}, target_thickness={target_thickness}")
            print(f"ğŸ“‹ é€‰æ‹©çš„è®°å½•ç´¢å¼•: {selected_record_indices}")
            print(f"ğŸ”§ è‡ªå®šä¹‰å‚æ•°: {custom_params}")
        except (ValueError, TypeError) as e:
            error_msg = f"å‚æ•°æ ¼å¼é”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return jsonify(format_response(False, message=error_msg)), 400
        
        # è·å–å½“å‰å‚æ•°é…ç½®
        current_params = get_latest_parameters()
        print(f"ğŸ” è·å–åˆ°çš„å½“å‰å‚æ•°: {current_params is not None}")
        
        if not current_params:
            error_msg = "æ— å½“å‰å‚æ•°é…ç½®ï¼Œè¯·å…ˆè¿›è¡Œä¸€æ¬¡è®¡ç®—"
            print(f"âŒ {error_msg}")
            return jsonify(format_response(False, message=error_msg)), 400
        
        print(f"ğŸ¯ å¼€å§‹åŸºäºéªŒè¯æ•°æ®çš„æ™ºèƒ½ä¼˜åŒ–")
        
        # åŸºäºéªŒè¯æ•°æ®çš„æ™ºèƒ½ä¼˜åŒ–ç®—æ³•
        optimized_exposures = calculate_experience_based_exposure_times(
            target_x, target_y, target_thickness, current_params, 
            selected_record_indices, optimization_type, custom_params
        )
        
        print(f"âœ… æ™ºèƒ½ä¼˜åŒ–å®Œæˆï¼Œç”Ÿæˆäº† {len(optimized_exposures)} ä¸ªé€‰é¡¹")
        
        add_log_entry('info', 'validation', f'åŸºäºéªŒè¯æ•°æ®çš„æ™ºèƒ½ä¼˜åŒ–å®Œæˆï¼Œç›®æ ‡ä½ç½®: ({target_x}, {target_y}), ç›®æ ‡åšåº¦: {target_thickness}, åŸºäº{len(selected_record_indices)}æ¡è®°å½•')
        return jsonify(format_response(True, 
                                       message="åŸºäºéªŒè¯æ•°æ®çš„æ™ºèƒ½ä¼˜åŒ–å®Œæˆ",
                                       data={'exposure_options': optimized_exposures}))
        
    except Exception as e:
        error_msg = f"æ™ºèƒ½ä¼˜åŒ–å¤±è´¥: {str(e)}"
        print(f"ğŸ’¥ Error: {error_msg}")
        import traceback
        traceback.print_exc()
        add_log_entry('error', 'validation', error_msg)
        return jsonify(format_response(False, message=error_msg)), 500


def get_latest_parameters():
    """è·å–æœ€æ–°çš„è®¡ç®—å‚æ•°"""
    global latest_calculation_result
    try:
        if latest_calculation_result and latest_calculation_result.get('parameters'):
            return latest_calculation_result.get('parameters')
        return None
    except:
        return None


def calculate_optimal_exposure_times(target_x, target_y, target_thickness, current_params):
    """
    åŸºäºDillæ¨¡å‹è®¡ç®—æœ€ä¼˜æ›å…‰æ—¶é—´
    ä½¿ç”¨æ•°å€¼æ–¹æ³•æ±‚è§£æ›å…‰æ—¶é—´ï¼Œä½¿å¾—æŒ‡å®šä½ç½®çš„åšåº¦è¾¾åˆ°ç›®æ ‡å€¼
    """
    import numpy as np
    try:
        from scipy.optimize import minimize_scalar
    except ImportError:
        # å¦‚æœscipyä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•çš„ç½‘æ ¼æœç´¢
        return calculate_exposure_times_simple(target_x, target_y, target_thickness, current_params)
    
    # æå–å½“å‰å‚æ•°
    I_avg = current_params.get('I_avg', 0.5)
    V = current_params.get('V', 0.8)  
    K = current_params.get('K', 0.1)
    C = current_params.get('C', 0.01)
    base_t_exp = current_params.get('t_exp', 10.0)
    
    # å…‰å¼ºè®¡ç®—ï¼ˆåŸºäºDillæ¨¡å‹ï¼‰
    def calculate_intensity_at_position(x, y):
        """è®¡ç®—æŒ‡å®šä½ç½®çš„å…‰å¼ºåˆ†å¸ƒ"""
        # ç®€åŒ–çš„1D/2Då…‰å¼ºåˆ†å¸ƒæ¨¡å‹
        if current_params.get('sine_type') == '2d':
            # 2Dæƒ…å†µ
            I_xy = I_avg * (1 + V * np.cos(K * x) * np.cos(K * y))
        else:
            # 1Dæƒ…å†µ
            I_xy = I_avg * (1 + V * np.cos(K * x))
        return max(I_xy, 0.01)  # é¿å…è´Ÿå€¼
    
    def dill_thickness_model(t_exp, x, y):
        """
        ç®€åŒ–çš„Dillæ¨¡å‹åšåº¦è®¡ç®—
        åŸºäºæ›å…‰å‰‚é‡å’ŒåŒ–å­¦æ”¾å¤§è¿‡ç¨‹
        """
        I_xy = calculate_intensity_at_position(x, y)
        
        # æ›å…‰å‰‚é‡
        dose = I_xy * t_exp
        
        # åŸºäºDillæ¨¡å‹çš„åšåº¦è®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
        # H(x,y) = H0 * exp(-alpha * dose * C)
        H0 = 1.0  # åˆå§‹åšåº¦ï¼Œå‡è®¾ä¸º1Î¼m
        alpha = 1.0  # å¸æ”¶ç³»æ•°
        
        thickness = H0 * np.exp(-alpha * dose * C)
        return thickness
    
    def thickness_error(t_exp):
        """ç›®æ ‡å‡½æ•°ï¼šåšåº¦è¯¯å·®"""
        calculated_thickness = dill_thickness_model(t_exp, target_x, target_y)
        return abs(calculated_thickness - target_thickness)
    
    # æ•°å€¼ä¼˜åŒ–æ±‚è§£æœ€ä¼˜æ›å…‰æ—¶é—´
    try:
        # ä½¿ç”¨æ ‡é‡æœ€å°åŒ–æ±‚è§£
        result = minimize_scalar(thickness_error, bounds=(0.1, 100.0), method='bounded')
        optimal_t_exp = result.x
        
        # ç”Ÿæˆä¸‰ä¸ªä¸åŒç­–ç•¥çš„æ›å…‰æ—¶é—´é€‰é¡¹
        conservative_factor = 0.85  # ä¿å®ˆç­–ç•¥ï¼šå‡å°‘15%
        aggressive_factor = 1.15    # æ¿€è¿›ç­–ç•¥ï¼šå¢åŠ 15%
        
        options = [
            {
                "type": "conservative",
                "label": "ä¿å®ˆç­–ç•¥",
                "exposure_time": round(optimal_t_exp * conservative_factor, 3),
                "description": "åä¿å®ˆçš„æ›å…‰ï¼Œé™ä½è¿‡æ›é£é™©",
                "confidence": "é«˜"
            },
            {
                "type": "optimal", 
                "label": "æ ‡å‡†ç­–ç•¥",
                "exposure_time": round(optimal_t_exp, 3),
                "description": "æ•°å€¼ä¼˜åŒ–çš„æœ€ä¼˜æ›å…‰æ—¶é—´",
                "confidence": "æœ€é«˜"
            },
            {
                "type": "aggressive",
                "label": "æ¿€è¿›ç­–ç•¥", 
                "exposure_time": round(optimal_t_exp * aggressive_factor, 3),
                "description": "åæ¿€è¿›çš„æ›å…‰ï¼Œè·å¾—æ›´å¼ºæ•ˆæœ",
                "confidence": "ä¸­ç­‰"
            }
        ]
        
        # è®¡ç®—é¢„æœŸåšåº¦
        for option in options:
            t_exp = option["exposure_time"]
            predicted_thickness = dill_thickness_model(t_exp, target_x, target_y)
            option["predicted_thickness"] = round(predicted_thickness, 4)
            option["thickness_error"] = round(abs(predicted_thickness - target_thickness), 4)
        
        return options
        
    except Exception as e:
        print(f"ä¼˜åŒ–ç®—æ³•é”™è¯¯: {str(e)}")
        return calculate_exposure_times_simple(target_x, target_y, target_thickness, current_params)


def calculate_exposure_times_simple(target_x, target_y, target_thickness, current_params):
    """
    ç®€å•çš„æ›å…‰æ—¶é—´ä¼°ç®—ï¼ˆå½“scipyä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
    """
    import numpy as np
    base_t_exp = current_params.get('t_exp', 10.0)
    
    # åŸºäºç›®æ ‡åšåº¦çš„ç®€å•ä¼°ç®—
    thickness_ratio = target_thickness / 1.0  # å‡è®¾åŸºå‡†åšåº¦ä¸º1Î¼m
    
    # è€ƒè™‘ä½ç½®å› ç´ çš„ä¿®æ­£
    I_avg = current_params.get('I_avg', 0.5)
    V = current_params.get('V', 0.8)
    K = current_params.get('K', 0.1)
    
    # è®¡ç®—ä½ç½®ä¿®æ­£å› å­
    if current_params.get('sine_type') == '2d':
        position_factor = 1 + V * np.cos(K * target_x) * np.cos(K * target_y)
    else:
        position_factor = 1 + V * np.cos(K * target_x)
    
    # åŸºç¡€æ›å…‰æ—¶é—´ä¼°ç®—
    estimated_t_exp = base_t_exp * thickness_ratio / max(position_factor, 0.1)
    
    return [
        {
            "type": "conservative",
            "label": "ä¿å®ˆç­–ç•¥",
            "exposure_time": round(estimated_t_exp * 0.8, 3),
            "description": "åŸºäºç»éªŒçš„ä¿å®ˆä¼°è®¡",
            "confidence": "ä¸­ç­‰",
            "predicted_thickness": round(target_thickness * 0.9, 4),
            "thickness_error": round(abs(target_thickness * 0.1), 4)
        },
        {
            "type": "optimal",
            "label": "æ ‡å‡†ç­–ç•¥", 
            "exposure_time": round(estimated_t_exp, 3),
            "description": "åŸºäºç‰©ç†æ¨¡å‹çš„ä¼°è®¡",
            "confidence": "é«˜",
            "predicted_thickness": round(target_thickness, 4),
            "thickness_error": 0.0
        },
        {
            "type": "aggressive",
            "label": "æ¿€è¿›ç­–ç•¥",
            "exposure_time": round(estimated_t_exp * 1.2, 3), 
            "description": "åŸºäºç»éªŒçš„æ¿€è¿›ä¼°è®¡",
            "confidence": "ä¸­ç­‰",
            "predicted_thickness": round(target_thickness * 1.1, 4),
            "thickness_error": round(abs(target_thickness * 0.1), 4)
        }
    ]


@api_bp.route('/get_validation_data_for_optimization', methods=['GET'])
def get_validation_data_for_optimization():
    """è·å–éªŒè¯æ•°æ®ä¾›ä¼˜åŒ–é€‰æ‹©ä½¿ç”¨"""
    try:
        import pandas as pd
        import os
        
        # æ£€æŸ¥Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        if not os.path.exists(excel_file):
            return jsonify(format_response(False, message="éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")), 404
        
        # è¯»å–éªŒè¯æ•°æ®
        df = pd.read_excel(excel_file)
        
        if df.empty:
            return jsonify(format_response(False, message="éªŒè¯æ•°æ®ä¸ºç©º")), 404
        
        # æ ¼å¼åŒ–æ•°æ®ä¾›å‰ç«¯ä½¿ç”¨
        validation_records = []
        for index, row in df.iterrows():
            try:
                simulated_val = float(row.get('simulated_value', 0))
                actual_val = float(row.get('actual_value', 0))
                deviation = actual_val - simulated_val
                
                record = {
                    'index': index,
                    'position_x': float(row.get('annotation_x', 0)),
                    'position_y': float(row.get('annotation_y', 0)),
                    'simulated_value': round(simulated_val, 4),
                    'actual_value': round(actual_val, 4),
                    'deviation': round(deviation, 4),
                    'deviation_percentage': round((deviation / simulated_val * 100) if simulated_val != 0 else 0, 1),
                    'timestamp': str(row.get('annotation_timestamp', '')),
                    'analysis': get_deviation_analysis(deviation)
                }
                validation_records.append(record)
            except (ValueError, TypeError) as e:
                print(f"è·³è¿‡æ— æ•ˆè®°å½• {index}: {e}")
                continue
        
        print(f"ğŸ“Š è¿”å›{len(validation_records)}æ¡éªŒè¯è®°å½•ä¾›é€‰æ‹©")
        return jsonify(format_response(True, data={'records': validation_records}))
        
    except Exception as e:
        error_msg = f"è·å–éªŒè¯æ•°æ®å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return jsonify(format_response(False, message=error_msg)), 500


def get_deviation_analysis(deviation):
    """åˆ†æåå·®å¹¶ç»™å‡ºå»ºè®®"""
    if abs(deviation) < 0.05:
        return {"type": "accurate", "message": "é¢„æµ‹å‡†ç¡®", "adjustment": "æ— éœ€è°ƒæ•´"}
    elif deviation > 0.1:
        return {"type": "under_predicted", "message": "é¢„æµ‹åè–„", "adjustment": "å»ºè®®å‡å°‘æ›å…‰æ—¶é—´"}
    elif deviation < -0.1:
        return {"type": "over_predicted", "message": "é¢„æµ‹ååš", "adjustment": "å»ºè®®å¢åŠ æ›å…‰æ—¶é—´"}
    elif deviation > 0:
        return {"type": "slightly_under", "message": "ç•¥å¾®åè–„", "adjustment": "å¯é€‚å½“å‡å°‘æ›å…‰æ—¶é—´"}
    else:
        return {"type": "slightly_over", "message": "ç•¥å¾®ååš", "adjustment": "å¯é€‚å½“å¢åŠ æ›å…‰æ—¶é—´"}


def calculate_experience_based_exposure_times(target_x, target_y, target_thickness, current_params, selected_indices, optimization_type, custom_params=None):
    """
    åŸºäºç”¨æˆ·é€‰æ‹©çš„éªŒè¯æ•°æ®è¿›è¡Œç»éªŒä¼˜åŒ–
    """
    import pandas as pd
    import numpy as np
    import os
    
    # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•è®°å½•ï¼Œä½¿ç”¨ä¼ ç»Ÿç®—æ³•
    if not selected_indices:
        print("âš ï¸ æœªé€‰æ‹©éªŒè¯è®°å½•ï¼Œä½¿ç”¨ä¼ ç»Ÿä¼˜åŒ–ç®—æ³•")
        return calculate_optimal_exposure_times(target_x, target_y, target_thickness, current_params)
    
    try:
        # è¯»å–éªŒè¯æ•°æ®
        excel_file = os.path.join(os.getcwd(), 'validation_data.xlsx')
        df = pd.read_excel(excel_file)
        
        # è·å–é€‰ä¸­çš„è®°å½•
        selected_records = []
        for idx in selected_indices:
            if 0 <= idx < len(df):
                row = df.iloc[idx]
                try:
                    simulated_val = float(row.get('simulated_value', 0))
                    actual_val = float(row.get('actual_value', 0))
                    if simulated_val > 0:  # ç¡®ä¿æœ‰æ•ˆæ•°æ®
                        selected_records.append({
                            'simulated': simulated_val,
                            'actual': actual_val,
                            'deviation': actual_val - simulated_val,
                            'position_x': float(row.get('annotation_x', 0)),
                            'position_y': float(row.get('annotation_y', 0))
                        })
                except (ValueError, TypeError):
                    continue
        
        if not selected_records:
            print("âš ï¸ é€‰æ‹©çš„è®°å½•æ— æ•ˆï¼Œä½¿ç”¨ä¼ ç»Ÿä¼˜åŒ–ç®—æ³•")
            return calculate_optimal_exposure_times(target_x, target_y, target_thickness, current_params)
        
        print(f"ğŸ“Š åŸºäº{len(selected_records)}æ¡éªŒè¯è®°å½•è¿›è¡Œç»éªŒä¼˜åŒ–")
        
        # ç»éªŒåˆ†æç®—æ³•
        deviations = [r['deviation'] for r in selected_records]
        avg_deviation = np.mean(deviations)
        deviation_std = np.std(deviations) if len(deviations) > 1 else 0
        
        # è®¡ç®—ä½ç½®æƒé‡ï¼ˆè·ç¦»ç›®æ ‡ä½ç½®è¶Šè¿‘æƒé‡è¶Šå¤§ï¼‰
        position_weights = []
        for record in selected_records:
            distance = np.sqrt((record['position_x'] - target_x)**2 + (record['position_y'] - target_y)**2)
            weight = 1.0 / (1.0 + distance / 100.0)  # è·ç¦»æƒé‡å‡½æ•°
            position_weights.append(weight)
        
        # åŠ æƒå¹³å‡åå·®
        weighted_deviation = np.average(deviations, weights=position_weights)
        
        print(f"ğŸ“ˆ ç»éªŒåˆ†æç»“æœ:")
        print(f"   - å¹³å‡åå·®: {avg_deviation:.4f}")
        print(f"   - åå·®æ ‡å‡†å·®: {deviation_std:.4f}")
        print(f"   - åŠ æƒåå·®: {weighted_deviation:.4f}")
        
        # è·å–å½“å‰åŸºç¡€æ›å…‰æ—¶é—´
        base_t_exp = current_params.get('t_exp', 10.0)
        
        # è·å–è‡ªå®šä¹‰å‚æ•°
        if custom_params is None:
            custom_params = {'sensitivity': 2.0, 'confidence_threshold': 0.5, 'strategy_count': 3}
        
        sensitivity = custom_params.get('sensitivity', 2.0)
        confidence_threshold = custom_params.get('confidence_threshold', 0.5)
        strategy_count = custom_params.get('strategy_count', 3)
        
        # æ™ºèƒ½è°ƒæ•´ç³»æ•°è®¡ç®—ï¼ˆéçº¿æ€§ï¼‰
        # ä½¿ç”¨sigmoidå‡½æ•°è¿›è¡Œå¹³æ»‘è°ƒæ•´ï¼Œé¿å…æç«¯å€¼
        def sigmoid_adjustment(deviation, sensitivity=sensitivity):
            """ä½¿ç”¨sigmoidå‡½æ•°è®¡ç®—è°ƒæ•´ç³»æ•°"""
            return 1.0 - (2.0 / (1.0 + np.exp(-sensitivity * deviation)) - 1.0) * 0.3
        
        # åŸºäºåŠ æƒåå·®è®¡ç®—ä¸»è¦è°ƒæ•´ç³»æ•°
        primary_adjustment = sigmoid_adjustment(weighted_deviation)
        
        # ç½®ä¿¡åº¦è®¡ç®—
        confidence_score = max(confidence_threshold, 1.0 - deviation_std / 0.5)  # æ ‡å‡†å·®è¶Šå°ç½®ä¿¡åº¦è¶Šé«˜
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        strategies = []
        
        if optimization_type == 'quick':
            # å¿«æ·ä¼˜åŒ–ï¼šä¿å®ˆç­–ç•¥
            conservative_factor = primary_adjustment * 0.9  # æ›´ä¿å®ˆ
            exposure_time = base_t_exp * conservative_factor
            
            strategies.append({
                "type": "conservative",
                "label": "ä¿å®ˆç­–ç•¥",
                "exposure_time": round(exposure_time, 3),
                "description": f"åŸºäº{len(selected_records)}æ¡è®°å½•çš„ä¿å®ˆå»ºè®®",
                "confidence": f"{'é«˜' if confidence_score > 0.7 else 'ä¸­ç­‰' if confidence_score > 0.5 else 'ä½'}",
                "predicted_thickness": round(target_thickness * (2.0 - conservative_factor), 4),
                "adjustment_factor": round(conservative_factor, 4),
                "analysis": {
                    "avg_deviation": round(avg_deviation, 4),
                    "weighted_deviation": round(weighted_deviation, 4),
                    "confidence_score": round(confidence_score, 3),
                    "reference_records": len(selected_records)
                }
            })
        else:
            # è‡ªå®šä¹‰ä¼˜åŒ–ï¼šæ ¹æ®ç­–ç•¥æ•°é‡ç”Ÿæˆä¸åŒç­–ç•¥
            if strategy_count == 1:
                factors = {"optimal": primary_adjustment}
            elif strategy_count == 3:
                factors = {
                    "conservative": primary_adjustment * 0.85,
                    "balanced": primary_adjustment,
                    "aggressive": primary_adjustment * 1.15
                }
            else:  # strategy_count == 5
                factors = {
                    "very_conservative": primary_adjustment * 0.7,
                    "conservative": primary_adjustment * 0.85,
                    "balanced": primary_adjustment,
                    "aggressive": primary_adjustment * 1.15,
                    "very_aggressive": primary_adjustment * 1.3
                }
            
            strategy_labels = {
                "very_conservative": "æä¿å®ˆç­–ç•¥",
                "conservative": "ä¿å®ˆç­–ç•¥", 
                "balanced": "å¹³è¡¡ç­–ç•¥",
                "optimal": "æœ€ä¼˜ç­–ç•¥",
                "aggressive": "æ¿€è¿›ç­–ç•¥",
                "very_aggressive": "ææ¿€è¿›ç­–ç•¥"
            }
            
            for strategy_type, factor in factors.items():
                exposure_time = base_t_exp * factor
                strategies.append({
                    "type": strategy_type,
                    "label": strategy_labels.get(strategy_type, f"{strategy_type}ç­–ç•¥"),
                    "exposure_time": round(exposure_time, 3),
                    "description": f"åŸºäº{len(selected_records)}æ¡è®°å½•çš„{strategy_type}å»ºè®®",
                    "confidence": f"{'é«˜' if confidence_score > 0.7 else 'ä¸­ç­‰' if confidence_score > 0.5 else 'ä½'}",
                    "predicted_thickness": round(target_thickness * (2.0 - factor), 4),
                    "adjustment_factor": round(factor, 4),
                    "analysis": {
                        "avg_deviation": round(avg_deviation, 4),
                        "weighted_deviation": round(weighted_deviation, 4),
                        "confidence_score": round(confidence_score, 3),
                        "reference_records": len(selected_records),
                        "sensitivity": sensitivity,
                        "confidence_threshold": confidence_threshold
                    }
                })
        
        # æ·»åŠ ç»éªŒæ€»ç»“
        experience_summary = generate_experience_summary(selected_records, weighted_deviation)
        for strategy in strategies:
            strategy["experience_summary"] = experience_summary
        
        return strategies
        
    except Exception as e:
        print(f"âŒ ç»éªŒä¼˜åŒ–ç®—æ³•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        # å›é€€åˆ°ä¼ ç»Ÿç®—æ³•
        return calculate_optimal_exposure_times(target_x, target_y, target_thickness, current_params)


def generate_experience_summary(selected_records, weighted_deviation):
    """ç”Ÿæˆç»éªŒæ€»ç»“"""
    total_records = len(selected_records)
    
    under_predicted = sum(1 for r in selected_records if r['deviation'] > 0.05)
    over_predicted = sum(1 for r in selected_records if r['deviation'] < -0.05)
    accurate = total_records - under_predicted - over_predicted
    
    if abs(weighted_deviation) < 0.05:
        trend = "æ¨¡å‹é¢„æµ‹æ€»ä½“å‡†ç¡®"
        recommendation = "ç»´æŒå½“å‰å‚æ•°è®¾ç½®"
    elif weighted_deviation > 0.1:
        trend = "æ¨¡å‹ç³»ç»Ÿæ€§é¢„æµ‹åè–„"
        recommendation = "å»ºè®®å‡å°‘æ›å…‰æ—¶é—´ä»¥è·å¾—æ›´åšçš„å…‰åˆ»èƒ¶"
    elif weighted_deviation < -0.1:
        trend = "æ¨¡å‹ç³»ç»Ÿæ€§é¢„æµ‹ååš"
        recommendation = "å»ºè®®å¢åŠ æ›å…‰æ—¶é—´ä»¥å‡å°‘å…‰åˆ»èƒ¶åšåº¦"
    elif weighted_deviation > 0:
        trend = "æ¨¡å‹ç•¥å¾®åå‘é¢„æµ‹åè–„"
        recommendation = "å¯é€‚å½“å‡å°‘æ›å…‰æ—¶é—´"
    else:
        trend = "æ¨¡å‹ç•¥å¾®åå‘é¢„æµ‹ååš"
        recommendation = "å¯é€‚å½“å¢åŠ æ›å…‰æ—¶é—´"
    
    return {
        "trend": trend,
        "recommendation": recommendation,
        "statistics": {
            "total_records": total_records,
            "under_predicted": under_predicted,
            "over_predicted": over_predicted,
            "accurate": accurate,
            "weighted_deviation": round(weighted_deviation, 4)
        }
    }

